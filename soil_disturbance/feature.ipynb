{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dltime.base.layers import ConvBlock\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from dltime.models.FCN import FCN\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_train = ['zwy', 'zwy2', 'zwy3', 'zwy4', 'zwy5', 'j11', 'j11_2', 'j11_md', 'j11_527', 'yqcc', 'yqcc2', 'syf', 'syf2', 'sky', 'sky2', 'sky3', 'zyq', 'zyq2']\n",
    "param_dict = {}\n",
    "for data_name in tqdm(data_for_train):\n",
    "    param_dict[data_name] = []\n",
    "    named_params = torch.load(f\"./outputs/{data_name}_FCN.pth\")\n",
    "    for n, p in named_params.items():\n",
    "        if 'conv1d.weight' in n:\n",
    "            param_dict[data_name].append(p.detach().clone().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    '''FCN'''\n",
    "    def __init__(self, c_in, c_out, layers=[128, 256, 128], kss=[7, 5, 3], clf=True):\n",
    "        super(FCN, self).__init__()\n",
    "        self.clf = clf  # 是否作为分类器\n",
    "\n",
    "        self.convblock1 = ConvBlock(c_in, layers[0], ks=kss[0])\n",
    "        self.convblock2 = ConvBlock(layers[0], layers[1], ks=kss[1])\n",
    "        self.convblock3 = ConvBlock(layers[1], layers[2], ks=kss[2])\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(layers[-1], c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x1 = self.convblock2(x)\n",
    "        x2 = self.convblock3(x1)\n",
    "        x3 = self.gap(x2).squeeze(-1)\n",
    "        x3 = self.fc(x3)\n",
    "        return F.softmax(x2, dim=-1), torch.cat([x, x1, x2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltime.data.ts_datasets import Soil_Dataset\n",
    "from utils import load_pkl\n",
    "from data_process import handle_dataset_3dims\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_fn(valid_loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    feature_maps = []\n",
    "    for _, item in enumerate(valid_loader):\n",
    "        for k, v in item.items():\n",
    "            item[k] = v.to(device)\n",
    "\n",
    "        labels = item['label']\n",
    "        with torch.no_grad():\n",
    "            y_preds, feature_map = model(item['input'])\n",
    "\n",
    "        preds.append(y_preds.detach().cpu().numpy())\n",
    "        feature_maps.append(feature_map.detach().cpu())\n",
    "\n",
    "    \n",
    "    predictions = np.concatenate(preds)\n",
    "    feature_maps = torch.cat(feature_maps)\n",
    "    feature_list = []\n",
    "    for i in range(feature_maps.size(0)):\n",
    "        map = feature_maps[i].unsqueeze(3)\n",
    "        b, c, _ ,_= map.size()\n",
    "        x_fft = torch.fft.fftshift(map)\n",
    "        y_11 = nn.AdaptiveAvgPool2d(1)(x_fft[:,:,:]).view(b,c,1,1)\n",
    "        y_22=nn.AdaptiveMaxPool2d(1)(abs(x_fft[:,:,:])).view(b,c,1,1)\n",
    "        y_2=y_22/y_11\n",
    "        feature_list.append(y_2)\n",
    "    \n",
    "    return predictions, feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c25dbdc85e63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mlabel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mmap_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-1a4aa9707bdf>\u001b[0m in \u001b[0;36minfer_fn\u001b[1;34m(valid_loader, model, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0my_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# data_for_train = ['zwy', 'zwy2', 'zwy3', 'zwy4', 'zwy5', 'j11', 'j11_2', 'j11_md', 'j11_527', 'yqcc', 'yqcc2', 'syf', 'syf2', 'sky', 'sky2', 'sky3', 'zyq', 'zyq2']\n",
    "# data_for_train = ['sky', 'sky2', 'sky3']\n",
    "data_for_train = ['zwy', 'zwy2', 'zwy3', 'zwy4', 'zwy5']\n",
    "map_dict = {}\n",
    "label_dict = {}\n",
    "# train_data, test_data = [], []\n",
    "for data_name in tqdm(data_for_train):\n",
    "    model = FCN(c_in=5, c_out=3, layers=[64, 128, 64]).to('cuda')\n",
    "    model.load_state_dict(torch.load(f'.\\outputs\\{data_name}_FCN.pth'))\n",
    "    train_data = load_pkl(f'./pickle_data/{data_name}_train_64.pkl')\n",
    "    test_data = load_pkl(f'./pickle_data/{data_name}_test_64.pkl')\n",
    "    total_data = train_data + test_data\n",
    "    total_x, total_label = handle_dataset_3dims(train_data, mode=\"all\")\n",
    "    total_x = np.swapaxes(total_x, 2, 1)\n",
    "    total_dataset = Soil_Dataset(total_x, total_label, normalize=None, channel_first=True)\n",
    "    total_dataloader = DataLoader(total_dataset, batch_size=16, shuffle=False, drop_last=False)\n",
    "\n",
    "    label_dict[data_name] = total_label[:] \n",
    "    pred, maps = infer_fn(total_dataloader, model, 'cuda')\n",
    "    map_dict[data_name] = maps[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bc8095bcdbac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmap_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'zwy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "map_dict['zwy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2cc5f3fd0677345b2da76744e7e4ae77c20d68485bc79ae6cfb88e0ece58c04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

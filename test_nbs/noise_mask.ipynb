{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dltime.data.ts_datasets import get_max_seq_len, tsMinMaxNormlizer, dataframe2ndarray, uniform_scaling\n",
    "from sklearn.utils import shuffle\n",
    "from sktime.datasets import load_UCR_UEA_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_mask(X, masking_ratio, lm=3, mode='separate', distribution='geometric', exclude_feats=None):\n",
    "    \"\"\"\n",
    "    Creates a random boolean mask of the same shape as X, with 0s at places where a feature should be masked.\n",
    "    Args:\n",
    "        X: (seq_length, feat_dim) numpy array of features corresponding to a single sample\n",
    "        masking_ratio: proportion of seq_length to be masked. At each time step, will also be the proportion of\n",
    "            feat_dim that will be masked on average\n",
    "        lm: average length of masking subsequences (streaks of 0s). Used only when `distribution` is 'geometric'.\n",
    "        mode: whether each variable should be masked separately ('separate'), or all variables at a certain positions\n",
    "            should be masked concurrently ('concurrent')\n",
    "        distribution: whether each mask sequence element is sampled independently at random, or whether\n",
    "            sampling follows a markov chain (and thus is stateful), resulting in geometric distributions of\n",
    "            masked squences of a desired mean length `lm`\n",
    "        exclude_feats: iterable of indices corresponding to features to be excluded from masking (i.e. to remain all 1s)\n",
    "\n",
    "    Returns:\n",
    "        boolean numpy array with the same shape as X, with 0s at places where a feature should be masked\n",
    "    \"\"\"\n",
    "    if exclude_feats is not None:\n",
    "        exclude_feats = set(exclude_feats)\n",
    "\n",
    "    if distribution == 'geometric':  # stateful (Markov chain)\n",
    "        if mode == 'separate':  # each variable (feature) is independent\n",
    "            mask = np.ones(X.shape, dtype=bool)\n",
    "            for m in range(X.shape[1]):  # feature dimension\n",
    "                if exclude_feats is None or m not in exclude_feats:\n",
    "                    mask[:, m] = geom_noise_mask_single(X.shape[0], lm, masking_ratio)  # time dimension\n",
    "        else:  # replicate across feature dimension (mask all variables at the same positions concurrently)\n",
    "            mask = np.tile(np.expand_dims(geom_noise_mask_single(X.shape[0], lm, masking_ratio), 1), X.shape[1])\n",
    "    else:  # each position is independent Bernoulli with p = 1 - masking_ratio\n",
    "        if mode == 'separate':\n",
    "            mask = np.random.choice(np.array([True, False]), size=X.shape, replace=True,\n",
    "                                    p=(1 - masking_ratio, masking_ratio))\n",
    "        else:\n",
    "            mask = np.tile(np.random.choice(np.array([True, False]), size=(X.shape[0], 1), replace=True,\n",
    "                                            p=(1 - masking_ratio, masking_ratio)), X.shape[1])\n",
    "\n",
    "    return mask\n",
    "\n",
    "def geom_noise_mask_single(L, lm, masking_ratio):\n",
    "    \"\"\"\n",
    "    Randomly create a boolean mask of length `L`, consisting of subsequences of average length lm, masking with 0s a `masking_ratio`\n",
    "    proportion of the sequence L. The length of masking subsequences and intervals follow a geometric distribution.\n",
    "    Args:\n",
    "        L: length of mask and sequence to be masked\n",
    "        lm: average length of masking subsequences (streaks of 0s)\n",
    "        masking_ratio: proportion of L to be masked\n",
    "\n",
    "    Returns:\n",
    "        (L,) boolean numpy array intended to mask ('drop') with 0s a sequence of length L\n",
    "    \"\"\"\n",
    "    keep_mask = np.ones(L, dtype=bool)\n",
    "    p_m = 1 / lm  # probability of each masking sequence stopping. parameter of geometric distribution.\n",
    "    p_u = p_m * masking_ratio / (1 - masking_ratio)  # probability of each unmasked sequence stopping. parameter of geometric distribution.\n",
    "    p = [p_m, p_u]\n",
    "\n",
    "    # Start in state 0 with masking_ratio probability\n",
    "    state = int(np.random.rand() > masking_ratio)  # state 0 means masking, 1 means not masking\n",
    "    for i in range(L):\n",
    "        keep_mask[i] = state  # here it happens that state and masking value corresponding to state are identical\n",
    "        if np.random.rand() < p[state]:\n",
    "            state = 1 - state\n",
    "\n",
    "    return keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_mask_len(seq):\n",
    "    return np.sum(~seq)\n",
    "\n",
    "def get_each_mask_len(seq):\n",
    "    s_len = 0\n",
    "    ans = []\n",
    "    for i, s in enumerate(seq):\n",
    "        if not s and not s_len:\n",
    "            s_len = 1\n",
    "        elif not s and s_len:\n",
    "            s_len += 1\n",
    "            if i == len(seq) -1:\n",
    "                ans.append(s_len)\n",
    "        elif s and s_len:\n",
    "            ans.append(s_len)\n",
    "            s_len = 0\n",
    "        else:\n",
    "            s_len = 0\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = []\n",
    "for _ in range(10000):\n",
    "    test_mask.append(geom_noise_mask_single(64, 5, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = [get_total_mask_len(i) for i in test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.7911"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sep_len = []\n",
    "for m in test_mask:\n",
    "    total_sep_len += get_each_mask_len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.77951486521951"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(total_sep_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLM Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(256, 144)\n",
    "lm_mask = torch.from_numpy(noise_mask(X, 0.2))\n",
    "X_tensor = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  ..., False,  True,  True],\n",
       "        [False, False,  True,  ..., False,  True,  True],\n",
       "        [ True, False,  True,  ..., False,  True,  True],\n",
       "        ...,\n",
       "        [ True, False,  True,  ...,  True,  True,  True],\n",
       "        [ True, False,  True,  ..., False,  True, False],\n",
       "        [False,  True,  True,  ..., False,  True,  True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000,  0.1825,  ..., -1.0000,  0.2916,  0.8913],\n",
       "        [-1.0000, -1.0000, -0.1287,  ..., -1.0000,  0.5978,  0.6555],\n",
       "        [-1.2103, -1.0000, -0.7047,  ..., -1.0000, -0.0790, -0.0375],\n",
       "        ...,\n",
       "        [-0.4750, -1.0000, -0.1126,  ..., -1.3651,  0.1387,  0.7237],\n",
       "        [-0.6511, -1.0000, -2.0006,  ..., -1.0000, -0.6534, -1.0000],\n",
       "        [-1.0000,  1.7302, -2.5641,  ..., -1.0000,  0.3111, -0.3192]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.masked_fill(~lm_mask, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2ndarray(X):\n",
    "    \"X 是具体某一条数据, 而非整个数据集\"\n",
    "    # 1. 统计各维度的数据长度\n",
    "    all_len = [len(x) for x in X]\n",
    "    # print(all_len)\n",
    "    max_len = max(all_len)\n",
    "\n",
    "    # 2. 统一每一维度的数据长度\n",
    "    _X = []\n",
    "    for x in X:\n",
    "        # print(x)\n",
    "        # 2.1 如果有缺失值, 进行插补\n",
    "        if x.isnull().any():\n",
    "            x = x.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # 2.2. 如果有维度间的数据长度不相等, 则填充到一致\n",
    "        if len(x) < max_len:\n",
    "            x = uniform_scaling(x, max_len)\n",
    "        _X.append(x)\n",
    "    _X = np.array(np.transpose(_X))\n",
    "\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLM_UCR_UEADataset(Dataset):\n",
    "    \"Torch Datasets for UCR/UEA archive\"\n",
    "\n",
    "    def __init__(self, name, split=None, pt_ratio=0.5, extract_path=\"ucr_uea_archive\", \\\n",
    "        max_len=256, normalize=None, masking_ratio=0.2, lm=5, mode='separate', distribution='geometric'):\n",
    "\n",
    "        assert split in [\"train\", \"test\", None]\n",
    "        assert normalize in [\"standard\", \"minmax\", None]\n",
    "\n",
    "        super().__init__()\n",
    "        self.pt_ratio = pt_ratio\n",
    "        self.normalize = normalize\n",
    "        self.masking_ratio = masking_ratio\n",
    "        self.lm = lm\n",
    "        self.mode = mode\n",
    "        self.distribution = distribution\n",
    "\n",
    "        self.data, _ = load_UCR_UEA_dataset(name, split=split, return_X_y=True, \\\n",
    "            extract_path=extract_path) # x, y => Dataframe\n",
    "        \n",
    "        self.data = shuffle(self.data).reset_index(drop=True)\n",
    "        self.data = self.data.iloc[: int(len(self.data)*self.pt_ratio)]\n",
    "\n",
    "        self.max_len = max(max_len, get_max_seq_len(self.data) + 1) # 获取最大序列长度\n",
    "        self.normalizer = tsMinMaxNormlizer(scale=(0.05, 0.95))\n",
    "        self.normalizer.fit(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data.iloc[idx].copy(deep=True)\n",
    "        # print(X)\n",
    "        X = dataframe2ndarray(X)    # dataframe 转 numpy 数组\n",
    "\n",
    "        # 数据归一化, 均按维度进行归一化\n",
    "        X = self.normalizer.transform(X)\n",
    "        lm_mask = ~noise_mask(X, self.masking_ratio, self.lm, self.mode, self.distribution)\n",
    "\n",
    "        cls = np.ones((1, X.shape[-1])) # [CLS]\n",
    "        pad = np.zeros((self.max_len - X.shape[0] - 1, X.shape[-1])) # [PAD]\n",
    "        X = np.concatenate([cls, X, pad], axis=0)\n",
    "\n",
    "        # padding mask\n",
    "        padding_mask = [0] + [0] * X.shape[0] + [1] * (self.max_len - X.shape[0] - 1)\n",
    "        \n",
    "        # lm_mask\n",
    "        cls_mask = np.zeros((1, X.shape[-1]), dtype=np.bool) # [CLS]\n",
    "        pad_mask = pad[:]\n",
    "        lm_mask = torch.from_numpy(np.concatenate([cls_mask, lm_mask, pad_mask], axis=0)).bool()\n",
    "\n",
    "        item = {\"input\": torch.from_numpy(X[:]).masked_fill(lm_mask, -1).float(), \\\n",
    "            \"padding_mask\": torch.tensor(padding_mask).bool(), \n",
    "            \"output\": torch.from_numpy(X[:]).float(), \n",
    "            \"lm_mask\": lm_mask}\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MLM_UCR_UEADataset(\"ArticularyWordRecognition\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltime.models.ts_transformer import TSTransformerEncoder, TSTransformerEncoderClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim, max_len, d_model, n_heads, num_layers, dim_feedforward, num_classes = \\\n",
    "    9, 256, 256, 2, 2, 512, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TSTransformerEncoder(feat_dim, max_len, d_model, n_heads, num_layers, dim_feedforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dicts = torch.load(\"D:\\\\github\\dltime-torch\\\\test_program\\\\outputs\\\\ArticularyWordRecognition_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_inp.weight\n",
      "project_inp.bias\n",
      "pos_enc.pe\n",
      "transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.0.linear1.weight\n",
      "transformer_encoder.layers.0.linear1.bias\n",
      "transformer_encoder.layers.0.linear2.weight\n",
      "transformer_encoder.layers.0.linear2.bias\n",
      "transformer_encoder.layers.0.norm1.weight\n",
      "transformer_encoder.layers.0.norm1.bias\n",
      "transformer_encoder.layers.0.norm1.running_mean\n",
      "transformer_encoder.layers.0.norm1.running_var\n",
      "transformer_encoder.layers.0.norm1.num_batches_tracked\n",
      "transformer_encoder.layers.0.norm2.weight\n",
      "transformer_encoder.layers.0.norm2.bias\n",
      "transformer_encoder.layers.0.norm2.running_mean\n",
      "transformer_encoder.layers.0.norm2.running_var\n",
      "transformer_encoder.layers.0.norm2.num_batches_tracked\n",
      "transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.1.linear1.weight\n",
      "transformer_encoder.layers.1.linear1.bias\n",
      "transformer_encoder.layers.1.linear2.weight\n",
      "transformer_encoder.layers.1.linear2.bias\n",
      "transformer_encoder.layers.1.norm1.weight\n",
      "transformer_encoder.layers.1.norm1.bias\n",
      "transformer_encoder.layers.1.norm1.running_mean\n",
      "transformer_encoder.layers.1.norm1.running_var\n",
      "transformer_encoder.layers.1.norm1.num_batches_tracked\n",
      "transformer_encoder.layers.1.norm2.weight\n",
      "transformer_encoder.layers.1.norm2.bias\n",
      "transformer_encoder.layers.1.norm2.running_mean\n",
      "transformer_encoder.layers.1.norm2.running_var\n",
      "transformer_encoder.layers.1.norm2.num_batches_tracked\n",
      "output_layer.weight\n",
      "output_layer.bias\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in state_dicts.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TSTransformerEncoderClassifier(feat_dim, max_len, d_model, n_heads, num_layers, dim_feedforward, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('project_inp.weight',\n",
       "              tensor([[ 0.2143, -0.2024, -0.0681,  ..., -0.2116, -0.2554,  0.0887],\n",
       "                      [-0.2702, -0.2701,  0.2442,  ..., -0.2202, -0.0841,  0.0971],\n",
       "                      [ 0.0418,  0.3299,  0.1042,  ..., -0.2521,  0.1486, -0.1352],\n",
       "                      ...,\n",
       "                      [-0.2112, -0.2896,  0.2867,  ...,  0.3285, -0.2288,  0.0094],\n",
       "                      [ 0.0498, -0.0795, -0.3274,  ...,  0.2357,  0.2213,  0.1863],\n",
       "                      [-0.0176,  0.3166,  0.1792,  ..., -0.2375,  0.0178,  0.1022]])),\n",
       "             ('project_inp.bias',\n",
       "              tensor([ 0.2545, -0.2221, -0.2877,  0.2663, -0.3261,  0.1302,  0.2638,  0.2455,\n",
       "                      -0.2250, -0.2960, -0.0438,  0.2661, -0.3174, -0.0606,  0.1777,  0.1289,\n",
       "                      -0.2315, -0.1064, -0.0415, -0.2213,  0.1464, -0.0947, -0.0763,  0.0291,\n",
       "                       0.0359, -0.0048, -0.2813, -0.0156,  0.3182,  0.2095, -0.1552,  0.2296,\n",
       "                      -0.3081, -0.2633, -0.2246,  0.1836, -0.1856,  0.1304,  0.2166, -0.2137,\n",
       "                       0.0990, -0.1702,  0.3259, -0.2086,  0.0245, -0.0168, -0.1143,  0.0418,\n",
       "                       0.2268,  0.1861, -0.3289,  0.1868, -0.2555, -0.0296,  0.0318, -0.1207,\n",
       "                      -0.0500,  0.2283,  0.2294,  0.2112,  0.2102, -0.2201, -0.2096, -0.2720,\n",
       "                      -0.0954, -0.1919,  0.0647,  0.0326,  0.2132, -0.1001,  0.2713,  0.0630,\n",
       "                      -0.3251, -0.2247,  0.1509, -0.2735, -0.1198,  0.0107, -0.1791,  0.3164,\n",
       "                       0.2469,  0.1680,  0.0421, -0.1816,  0.2416, -0.1357,  0.3129, -0.0640,\n",
       "                      -0.1813,  0.1147,  0.0254, -0.2190, -0.2662, -0.2041,  0.2229,  0.2291,\n",
       "                       0.0388,  0.1399,  0.1977,  0.1882, -0.2992, -0.1787, -0.3111,  0.0234,\n",
       "                       0.3144,  0.2024,  0.1207, -0.0846, -0.1602, -0.0352,  0.2415,  0.1557,\n",
       "                      -0.1996,  0.2653,  0.2416, -0.2085,  0.0255,  0.1577,  0.1544,  0.2097,\n",
       "                      -0.2637, -0.2163, -0.0984, -0.3107, -0.0786,  0.0720,  0.2663, -0.2279,\n",
       "                      -0.0063,  0.1523,  0.1736,  0.0203, -0.1336, -0.0539,  0.1407,  0.1351,\n",
       "                       0.1419, -0.0647, -0.1822, -0.1034, -0.2387, -0.0730, -0.1062, -0.0382,\n",
       "                      -0.3124,  0.0374, -0.1458,  0.2818, -0.0249,  0.3062, -0.2160, -0.0456,\n",
       "                      -0.2799, -0.0978,  0.2803,  0.3231,  0.2290, -0.1050,  0.1999,  0.2243,\n",
       "                       0.1274, -0.1888, -0.0363, -0.1523, -0.2695, -0.1013,  0.1137,  0.0953,\n",
       "                      -0.0794,  0.0418, -0.1532, -0.2030,  0.1569, -0.1641, -0.0787, -0.2815,\n",
       "                      -0.1690,  0.2485, -0.1371, -0.2422, -0.0435, -0.3260,  0.0187, -0.2871,\n",
       "                      -0.1115, -0.2630,  0.2708, -0.0104,  0.1712,  0.1314,  0.2013, -0.2996,\n",
       "                       0.2379, -0.0496,  0.0748,  0.0667,  0.2536,  0.1668,  0.1140,  0.2440,\n",
       "                      -0.1819, -0.3127, -0.3200, -0.2043, -0.1404, -0.0421, -0.1764, -0.2859,\n",
       "                       0.1168,  0.1978, -0.2451,  0.2373, -0.1686, -0.1012,  0.1991,  0.2658,\n",
       "                      -0.2942,  0.0268,  0.0686, -0.3255, -0.1810,  0.0328,  0.1846,  0.0670,\n",
       "                       0.1242,  0.3252,  0.2335,  0.1975,  0.2498, -0.1539, -0.1988, -0.2192,\n",
       "                      -0.0013,  0.2828, -0.2022,  0.1914, -0.3148,  0.2264,  0.2958,  0.2751,\n",
       "                       0.2955, -0.2794, -0.3217, -0.2180,  0.2275,  0.1439,  0.1811, -0.2364,\n",
       "                       0.0514, -0.0705,  0.1973,  0.3300,  0.2039,  0.0756, -0.0575,  0.1495])),\n",
       "             ('pos_enc.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  8.0196e-01,  ...,  1.0000e+00,\n",
       "                         1.0746e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.5814e-01,  ...,  1.0000e+00,\n",
       "                         2.1492e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 9.9482e-01, -1.0162e-01,  1.8368e-01,  ...,  9.9957e-01,\n",
       "                         2.7184e-02,  9.9963e-01]],\n",
       "              \n",
       "                      [[ 4.5200e-01, -8.9202e-01, -6.7859e-01,  ...,  9.9957e-01,\n",
       "                         2.7292e-02,  9.9963e-01]],\n",
       "              \n",
       "                      [[-5.0639e-01, -8.6230e-01, -9.9443e-01,  ...,  9.9957e-01,\n",
       "                         2.7399e-02,  9.9962e-01]]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[-0.0055,  0.0302,  0.0439,  ...,  0.0416, -0.0283, -0.0592],\n",
       "                      [-0.0338, -0.0585, -0.0478,  ..., -0.0374, -0.0738,  0.0715],\n",
       "                      [-0.0518, -0.0656,  0.0707,  ..., -0.0245,  0.0018,  0.0206],\n",
       "                      ...,\n",
       "                      [-0.0393,  0.0030,  0.0505,  ...,  0.0631,  0.0683,  0.0249],\n",
       "                      [-0.0223, -0.0656,  0.0731,  ...,  0.0670, -0.0509,  0.0566],\n",
       "                      [ 0.0060,  0.0372,  0.0645,  ...,  0.0171, -0.0531,  0.0345]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0084,  0.0089, -0.0251,  ..., -0.0228,  0.0550,  0.0261],\n",
       "                      [-0.0416, -0.0167,  0.0186,  ...,  0.0392, -0.0174, -0.0235],\n",
       "                      [-0.0240,  0.0085, -0.0496,  ...,  0.0484,  0.0195,  0.0224],\n",
       "                      ...,\n",
       "                      [-0.0397, -0.0404,  0.0012,  ...,  0.0250,  0.0343,  0.0001],\n",
       "                      [-0.0130,  0.0432,  0.0023,  ...,  0.0049,  0.0581, -0.0091],\n",
       "                      [ 0.0438,  0.0333, -0.0117,  ...,  0.0231,  0.0048,  0.0206]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.linear1.weight',\n",
       "              tensor([[-0.0280, -0.0523,  0.0408,  ..., -0.0030, -0.0317, -0.0151],\n",
       "                      [-0.0515, -0.0006,  0.0450,  ...,  0.0210,  0.0448,  0.0117],\n",
       "                      [ 0.0338, -0.0366, -0.0421,  ...,  0.0162, -0.0535,  0.0349],\n",
       "                      ...,\n",
       "                      [ 0.0460,  0.0506, -0.0133,  ...,  0.0256, -0.0090,  0.0497],\n",
       "                      [ 0.0327, -0.0547,  0.0280,  ..., -0.0526, -0.0365,  0.0522],\n",
       "                      [ 0.0350,  0.0590,  0.0497,  ..., -0.0019, -0.0264,  0.0461]])),\n",
       "             ('transformer_encoder.layers.0.linear1.bias',\n",
       "              tensor([ 0.0483, -0.0323,  0.0369, -0.0219,  0.0088, -0.0292, -0.0253,  0.0312,\n",
       "                       0.0420, -0.0318,  0.0361,  0.0460, -0.0030, -0.0374,  0.0356,  0.0255,\n",
       "                      -0.0082, -0.0480,  0.0042, -0.0380,  0.0358, -0.0413,  0.0261, -0.0337,\n",
       "                      -0.0557,  0.0516,  0.0440,  0.0493, -0.0313, -0.0161, -0.0189,  0.0621,\n",
       "                       0.0414,  0.0442, -0.0020,  0.0431, -0.0066, -0.0479,  0.0221,  0.0056,\n",
       "                      -0.0246,  0.0002,  0.0399,  0.0100, -0.0014, -0.0552,  0.0166, -0.0133,\n",
       "                      -0.0498,  0.0131, -0.0042,  0.0415,  0.0287, -0.0460, -0.0343,  0.0386,\n",
       "                       0.0035,  0.0599,  0.0603,  0.0110, -0.0119, -0.0146,  0.0203, -0.0525,\n",
       "                       0.0219, -0.0382, -0.0411, -0.0483, -0.0385,  0.0384,  0.0482, -0.0445,\n",
       "                       0.0367,  0.0091,  0.0109,  0.0042, -0.0117,  0.0054,  0.0562,  0.0547,\n",
       "                       0.0620, -0.0551, -0.0221, -0.0309, -0.0084,  0.0418, -0.0078,  0.0500,\n",
       "                      -0.0081,  0.0053, -0.0464,  0.0235, -0.0419, -0.0611, -0.0327, -0.0354,\n",
       "                       0.0108,  0.0620, -0.0076, -0.0477,  0.0408,  0.0072, -0.0420,  0.0198,\n",
       "                       0.0522,  0.0555, -0.0153,  0.0193,  0.0072,  0.0055,  0.0182,  0.0130,\n",
       "                       0.0141, -0.0500, -0.0518,  0.0180,  0.0249,  0.0399,  0.0278, -0.0522,\n",
       "                       0.0149,  0.0185,  0.0434,  0.0118, -0.0477, -0.0243, -0.0299,  0.0469,\n",
       "                       0.0397, -0.0450,  0.0603, -0.0565, -0.0225,  0.0025, -0.0210,  0.0279,\n",
       "                      -0.0310, -0.0041, -0.0371,  0.0398, -0.0524, -0.0535, -0.0237,  0.0166,\n",
       "                      -0.0110, -0.0508,  0.0489,  0.0466,  0.0501,  0.0337, -0.0428,  0.0553,\n",
       "                      -0.0226, -0.0617,  0.0414,  0.0440,  0.0176,  0.0202,  0.0528, -0.0006,\n",
       "                      -0.0167,  0.0599, -0.0551,  0.0215, -0.0216,  0.0242,  0.0131, -0.0511,\n",
       "                       0.0268, -0.0495,  0.0040,  0.0355, -0.0555, -0.0565,  0.0329, -0.0371,\n",
       "                       0.0435, -0.0014, -0.0249, -0.0466,  0.0086, -0.0368, -0.0069, -0.0105,\n",
       "                       0.0559,  0.0431,  0.0054, -0.0499,  0.0381, -0.0068,  0.0499,  0.0067,\n",
       "                      -0.0427, -0.0306, -0.0538,  0.0359,  0.0520, -0.0207, -0.0366,  0.0377,\n",
       "                       0.0209,  0.0275,  0.0460,  0.0281,  0.0008, -0.0558,  0.0120,  0.0482,\n",
       "                       0.0301,  0.0194,  0.0220,  0.0027,  0.0119,  0.0496, -0.0221, -0.0122,\n",
       "                       0.0027, -0.0478, -0.0025, -0.0330, -0.0552, -0.0578,  0.0332, -0.0042,\n",
       "                       0.0503,  0.0412,  0.0330,  0.0149,  0.0605, -0.0141,  0.0312,  0.0332,\n",
       "                      -0.0406, -0.0026,  0.0103, -0.0473,  0.0622, -0.0364, -0.0070,  0.0279,\n",
       "                      -0.0280, -0.0287,  0.0350,  0.0489, -0.0310, -0.0592,  0.0390,  0.0081,\n",
       "                       0.0615,  0.0349,  0.0078, -0.0588, -0.0298, -0.0422, -0.0033, -0.0535,\n",
       "                       0.0522,  0.0119,  0.0012,  0.0025,  0.0508,  0.0514,  0.0222,  0.0429,\n",
       "                       0.0583, -0.0369,  0.0617, -0.0572, -0.0128, -0.0085,  0.0072, -0.0221,\n",
       "                      -0.0342,  0.0043, -0.0384,  0.0023,  0.0085,  0.0578,  0.0202,  0.0141,\n",
       "                       0.0049,  0.0443, -0.0054,  0.0141,  0.0473, -0.0076, -0.0572, -0.0368,\n",
       "                      -0.0419, -0.0451, -0.0068,  0.0465, -0.0508,  0.0569,  0.0448,  0.0042,\n",
       "                      -0.0376,  0.0497,  0.0538, -0.0338, -0.0461, -0.0381, -0.0592,  0.0143,\n",
       "                      -0.0373, -0.0341, -0.0335, -0.0023,  0.0363,  0.0179, -0.0273,  0.0229,\n",
       "                      -0.0482,  0.0232, -0.0149, -0.0167,  0.0237,  0.0043, -0.0248, -0.0486,\n",
       "                       0.0465, -0.0343,  0.0045,  0.0580, -0.0545,  0.0447, -0.0031, -0.0172,\n",
       "                       0.0538, -0.0110,  0.0341,  0.0484, -0.0404, -0.0564, -0.0562,  0.0529,\n",
       "                      -0.0558,  0.0599, -0.0551, -0.0354,  0.0366,  0.0204,  0.0621,  0.0049,\n",
       "                       0.0389,  0.0439, -0.0039,  0.0355, -0.0059,  0.0278,  0.0380,  0.0391,\n",
       "                       0.0125,  0.0047,  0.0055, -0.0056, -0.0001, -0.0424,  0.0309, -0.0295,\n",
       "                       0.0283,  0.0057,  0.0557,  0.0397, -0.0542, -0.0205,  0.0604, -0.0251,\n",
       "                       0.0454, -0.0482, -0.0569, -0.0183, -0.0429,  0.0090,  0.0525,  0.0567,\n",
       "                       0.0333, -0.0474,  0.0331, -0.0557, -0.0072,  0.0127, -0.0106,  0.0508,\n",
       "                      -0.0581, -0.0077,  0.0301, -0.0167,  0.0414,  0.0218, -0.0157, -0.0563,\n",
       "                       0.0309, -0.0080,  0.0281,  0.0346, -0.0570,  0.0326, -0.0359,  0.0483,\n",
       "                       0.0576,  0.0454,  0.0156, -0.0191, -0.0196,  0.0027,  0.0358, -0.0529,\n",
       "                       0.0538,  0.0364,  0.0568,  0.0614, -0.0190,  0.0430,  0.0587, -0.0426,\n",
       "                       0.0117,  0.0462, -0.0198, -0.0260, -0.0004,  0.0440,  0.0062,  0.0178,\n",
       "                      -0.0443, -0.0011, -0.0246, -0.0292, -0.0157, -0.0227, -0.0265, -0.0392,\n",
       "                      -0.0135, -0.0132, -0.0618,  0.0155, -0.0158,  0.0598, -0.0425, -0.0182,\n",
       "                       0.0475, -0.0328, -0.0059, -0.0232, -0.0482, -0.0503,  0.0211, -0.0043,\n",
       "                      -0.0444, -0.0620,  0.0219, -0.0517,  0.0506, -0.0543,  0.0262, -0.0488,\n",
       "                      -0.0128, -0.0470, -0.0161, -0.0472,  0.0343,  0.0048,  0.0279, -0.0090,\n",
       "                       0.0481,  0.0519, -0.0141,  0.0363, -0.0490,  0.0620, -0.0437,  0.0611,\n",
       "                       0.0030, -0.0018,  0.0526, -0.0541,  0.0111, -0.0371, -0.0076, -0.0445,\n",
       "                       0.0415, -0.0486,  0.0231, -0.0240, -0.0089,  0.0401,  0.0526, -0.0179,\n",
       "                      -0.0226,  0.0096, -0.0585,  0.0057,  0.0026, -0.0444,  0.0481, -0.0097,\n",
       "                      -0.0107,  0.0603,  0.0180,  0.0051, -0.0174,  0.0573, -0.0484, -0.0170,\n",
       "                       0.0371,  0.0503,  0.0275,  0.0457, -0.0137,  0.0033,  0.0112, -0.0015])),\n",
       "             ('transformer_encoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.0190,  0.0391,  0.0098,  ..., -0.0332, -0.0300,  0.0406],\n",
       "                      [-0.0441,  0.0355, -0.0021,  ...,  0.0175,  0.0032, -0.0275],\n",
       "                      [ 0.0263,  0.0435,  0.0348,  ..., -0.0375,  0.0174,  0.0410],\n",
       "                      ...,\n",
       "                      [-0.0002,  0.0097,  0.0258,  ...,  0.0297, -0.0014,  0.0337],\n",
       "                      [-0.0064, -0.0398,  0.0275,  ...,  0.0248, -0.0074,  0.0428],\n",
       "                      [-0.0235, -0.0273,  0.0030,  ...,  0.0082, -0.0172, -0.0086]])),\n",
       "             ('transformer_encoder.layers.0.linear2.bias',\n",
       "              tensor([-3.5445e-02,  4.2078e-02,  3.7489e-02,  1.5458e-02, -3.1696e-02,\n",
       "                       1.5662e-02, -1.7062e-02, -2.6894e-02,  4.3101e-02,  1.2483e-02,\n",
       "                      -1.5951e-02, -3.8529e-02,  3.6679e-02,  9.4401e-03, -5.6878e-03,\n",
       "                      -8.0187e-04, -1.3012e-02, -3.4817e-02,  3.0071e-02, -4.1941e-02,\n",
       "                       3.7620e-02, -4.4113e-02,  1.8442e-02,  4.0405e-02,  2.1160e-02,\n",
       "                      -2.6937e-02, -1.8263e-02, -3.3392e-02, -1.5833e-02, -8.3444e-03,\n",
       "                      -9.7158e-03,  2.3173e-02, -1.6892e-02, -3.9735e-02,  2.7053e-02,\n",
       "                      -2.0633e-02,  8.1089e-03,  2.4037e-02,  2.3352e-02,  1.9211e-03,\n",
       "                      -4.2487e-02,  2.1164e-02, -4.4013e-02,  3.3830e-02,  3.3298e-02,\n",
       "                      -1.0017e-02,  1.0827e-02,  1.7310e-02, -4.2318e-02, -1.7905e-02,\n",
       "                      -3.2158e-02,  3.2761e-02,  1.0806e-02,  3.2861e-02,  1.2381e-02,\n",
       "                      -4.0578e-02,  1.7268e-02, -3.5420e-03,  1.7186e-02, -3.4806e-02,\n",
       "                      -8.9554e-03, -3.8740e-03,  2.5273e-02,  1.5126e-02,  2.3954e-03,\n",
       "                      -2.0692e-02, -2.0521e-02,  3.7228e-02, -5.3396e-03, -2.3859e-02,\n",
       "                      -3.7715e-04,  3.7184e-02,  1.4404e-02,  1.0404e-02, -3.2184e-02,\n",
       "                       4.0425e-02, -4.1437e-02, -1.3183e-02,  1.7903e-02, -4.1673e-02,\n",
       "                       3.7187e-02,  2.8307e-02, -7.2170e-03, -2.7673e-02, -8.7216e-03,\n",
       "                      -3.5181e-03,  4.1364e-02, -1.2885e-02,  1.2875e-02, -9.8797e-03,\n",
       "                      -4.0175e-03, -4.3612e-02,  1.0932e-02,  2.6114e-02,  4.1196e-03,\n",
       "                      -2.9660e-02, -3.1167e-02, -2.8473e-02,  2.8196e-02,  3.4629e-02,\n",
       "                      -3.2609e-02,  1.2070e-02, -2.6582e-02, -5.6353e-03,  4.2696e-02,\n",
       "                      -4.0232e-02, -3.6069e-02, -3.6540e-03, -9.5815e-03,  2.3308e-02,\n",
       "                       1.7874e-02, -3.8018e-02, -3.1772e-02,  3.6605e-02,  7.1798e-03,\n",
       "                      -2.0097e-02, -2.5350e-02,  3.9716e-02,  2.2675e-02,  2.0065e-02,\n",
       "                      -2.2576e-02, -2.5521e-02, -3.3310e-02, -2.7813e-02, -9.0519e-03,\n",
       "                      -1.5510e-02, -2.0994e-02, -1.1568e-03,  1.3245e-02,  3.0131e-02,\n",
       "                      -3.6274e-02,  1.5285e-02, -1.2761e-02, -2.7521e-02, -1.1160e-02,\n",
       "                      -3.9004e-02, -1.3988e-02, -4.1216e-02,  1.0512e-02,  3.1344e-02,\n",
       "                       2.6314e-02, -2.6237e-02, -3.3147e-03,  6.7774e-03,  2.9130e-02,\n",
       "                      -3.4364e-02,  8.9269e-03, -4.2865e-02,  4.1989e-03,  2.8245e-02,\n",
       "                       2.6055e-02,  1.4195e-02, -3.7617e-02, -2.9922e-02, -4.2516e-03,\n",
       "                       1.1784e-02, -2.1141e-02,  2.2682e-03, -1.2862e-02, -1.7733e-02,\n",
       "                      -3.4552e-02,  4.2237e-02,  2.6805e-02, -2.2115e-02,  1.8101e-02,\n",
       "                       2.6475e-02, -4.3735e-02, -4.0546e-02,  1.2328e-02,  2.2077e-04,\n",
       "                      -8.8190e-03, -1.8792e-02, -1.7790e-02,  1.6613e-02, -3.5486e-02,\n",
       "                      -2.9800e-02,  6.8258e-03,  9.3907e-03,  5.6923e-03,  1.9261e-02,\n",
       "                       3.1624e-02,  4.2791e-02, -3.0905e-02, -4.3155e-02,  1.6017e-02,\n",
       "                       3.5901e-02,  5.4481e-03,  1.7067e-02,  3.5968e-02,  3.3438e-02,\n",
       "                       2.0110e-02,  2.5586e-02, -3.2268e-02, -1.1292e-02,  3.9577e-02,\n",
       "                      -4.0378e-02,  2.8672e-02,  1.7209e-02,  1.8656e-02, -4.3669e-02,\n",
       "                      -1.5511e-02, -2.0712e-02,  1.4926e-02,  2.5555e-02,  2.8251e-02,\n",
       "                      -2.9214e-02,  1.2240e-02,  1.7536e-02,  2.6271e-02,  3.9623e-02,\n",
       "                       3.5714e-02,  1.8136e-02, -2.2940e-03,  1.2711e-02, -2.0913e-02,\n",
       "                       4.1893e-02,  3.6821e-02,  2.4358e-02, -2.7127e-02,  1.1934e-02,\n",
       "                      -2.6728e-02,  2.1124e-02,  2.6714e-02,  1.4910e-02, -1.6203e-02,\n",
       "                       2.5199e-02,  1.2310e-02, -7.8764e-03,  7.3779e-03, -2.8572e-02,\n",
       "                      -2.6836e-02,  2.8334e-02, -2.1867e-02,  2.8608e-02,  1.5258e-02,\n",
       "                       3.3105e-02,  1.2614e-02,  2.4805e-02, -1.2625e-03, -7.9512e-03,\n",
       "                      -1.5556e-02, -2.6654e-05, -4.1708e-02,  2.8784e-02, -4.3870e-02,\n",
       "                      -2.0565e-02,  9.6235e-03, -3.6816e-02,  4.0234e-03,  8.7999e-03,\n",
       "                      -1.7993e-03, -2.2539e-02, -1.1894e-02,  1.2395e-02, -9.4580e-03,\n",
       "                      -3.2794e-02])),\n",
       "             ('transformer_encoder.layers.0.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.0.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[-0.0055,  0.0302,  0.0439,  ...,  0.0416, -0.0283, -0.0592],\n",
       "                      [-0.0338, -0.0585, -0.0478,  ..., -0.0374, -0.0738,  0.0715],\n",
       "                      [-0.0518, -0.0656,  0.0707,  ..., -0.0245,  0.0018,  0.0206],\n",
       "                      ...,\n",
       "                      [-0.0393,  0.0030,  0.0505,  ...,  0.0631,  0.0683,  0.0249],\n",
       "                      [-0.0223, -0.0656,  0.0731,  ...,  0.0670, -0.0509,  0.0566],\n",
       "                      [ 0.0060,  0.0372,  0.0645,  ...,  0.0171, -0.0531,  0.0345]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0084,  0.0089, -0.0251,  ..., -0.0228,  0.0550,  0.0261],\n",
       "                      [-0.0416, -0.0167,  0.0186,  ...,  0.0392, -0.0174, -0.0235],\n",
       "                      [-0.0240,  0.0085, -0.0496,  ...,  0.0484,  0.0195,  0.0224],\n",
       "                      ...,\n",
       "                      [-0.0397, -0.0404,  0.0012,  ...,  0.0250,  0.0343,  0.0001],\n",
       "                      [-0.0130,  0.0432,  0.0023,  ...,  0.0049,  0.0581, -0.0091],\n",
       "                      [ 0.0438,  0.0333, -0.0117,  ...,  0.0231,  0.0048,  0.0206]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.linear1.weight',\n",
       "              tensor([[-0.0280, -0.0523,  0.0408,  ..., -0.0030, -0.0317, -0.0151],\n",
       "                      [-0.0515, -0.0006,  0.0450,  ...,  0.0210,  0.0448,  0.0117],\n",
       "                      [ 0.0338, -0.0366, -0.0421,  ...,  0.0162, -0.0535,  0.0349],\n",
       "                      ...,\n",
       "                      [ 0.0460,  0.0506, -0.0133,  ...,  0.0256, -0.0090,  0.0497],\n",
       "                      [ 0.0327, -0.0547,  0.0280,  ..., -0.0526, -0.0365,  0.0522],\n",
       "                      [ 0.0350,  0.0590,  0.0497,  ..., -0.0019, -0.0264,  0.0461]])),\n",
       "             ('transformer_encoder.layers.1.linear1.bias',\n",
       "              tensor([ 0.0483, -0.0323,  0.0369, -0.0219,  0.0088, -0.0292, -0.0253,  0.0312,\n",
       "                       0.0420, -0.0318,  0.0361,  0.0460, -0.0030, -0.0374,  0.0356,  0.0255,\n",
       "                      -0.0082, -0.0480,  0.0042, -0.0380,  0.0358, -0.0413,  0.0261, -0.0337,\n",
       "                      -0.0557,  0.0516,  0.0440,  0.0493, -0.0313, -0.0161, -0.0189,  0.0621,\n",
       "                       0.0414,  0.0442, -0.0020,  0.0431, -0.0066, -0.0479,  0.0221,  0.0056,\n",
       "                      -0.0246,  0.0002,  0.0399,  0.0100, -0.0014, -0.0552,  0.0166, -0.0133,\n",
       "                      -0.0498,  0.0131, -0.0042,  0.0415,  0.0287, -0.0460, -0.0343,  0.0386,\n",
       "                       0.0035,  0.0599,  0.0603,  0.0110, -0.0119, -0.0146,  0.0203, -0.0525,\n",
       "                       0.0219, -0.0382, -0.0411, -0.0483, -0.0385,  0.0384,  0.0482, -0.0445,\n",
       "                       0.0367,  0.0091,  0.0109,  0.0042, -0.0117,  0.0054,  0.0562,  0.0547,\n",
       "                       0.0620, -0.0551, -0.0221, -0.0309, -0.0084,  0.0418, -0.0078,  0.0500,\n",
       "                      -0.0081,  0.0053, -0.0464,  0.0235, -0.0419, -0.0611, -0.0327, -0.0354,\n",
       "                       0.0108,  0.0620, -0.0076, -0.0477,  0.0408,  0.0072, -0.0420,  0.0198,\n",
       "                       0.0522,  0.0555, -0.0153,  0.0193,  0.0072,  0.0055,  0.0182,  0.0130,\n",
       "                       0.0141, -0.0500, -0.0518,  0.0180,  0.0249,  0.0399,  0.0278, -0.0522,\n",
       "                       0.0149,  0.0185,  0.0434,  0.0118, -0.0477, -0.0243, -0.0299,  0.0469,\n",
       "                       0.0397, -0.0450,  0.0603, -0.0565, -0.0225,  0.0025, -0.0210,  0.0279,\n",
       "                      -0.0310, -0.0041, -0.0371,  0.0398, -0.0524, -0.0535, -0.0237,  0.0166,\n",
       "                      -0.0110, -0.0508,  0.0489,  0.0466,  0.0501,  0.0337, -0.0428,  0.0553,\n",
       "                      -0.0226, -0.0617,  0.0414,  0.0440,  0.0176,  0.0202,  0.0528, -0.0006,\n",
       "                      -0.0167,  0.0599, -0.0551,  0.0215, -0.0216,  0.0242,  0.0131, -0.0511,\n",
       "                       0.0268, -0.0495,  0.0040,  0.0355, -0.0555, -0.0565,  0.0329, -0.0371,\n",
       "                       0.0435, -0.0014, -0.0249, -0.0466,  0.0086, -0.0368, -0.0069, -0.0105,\n",
       "                       0.0559,  0.0431,  0.0054, -0.0499,  0.0381, -0.0068,  0.0499,  0.0067,\n",
       "                      -0.0427, -0.0306, -0.0538,  0.0359,  0.0520, -0.0207, -0.0366,  0.0377,\n",
       "                       0.0209,  0.0275,  0.0460,  0.0281,  0.0008, -0.0558,  0.0120,  0.0482,\n",
       "                       0.0301,  0.0194,  0.0220,  0.0027,  0.0119,  0.0496, -0.0221, -0.0122,\n",
       "                       0.0027, -0.0478, -0.0025, -0.0330, -0.0552, -0.0578,  0.0332, -0.0042,\n",
       "                       0.0503,  0.0412,  0.0330,  0.0149,  0.0605, -0.0141,  0.0312,  0.0332,\n",
       "                      -0.0406, -0.0026,  0.0103, -0.0473,  0.0622, -0.0364, -0.0070,  0.0279,\n",
       "                      -0.0280, -0.0287,  0.0350,  0.0489, -0.0310, -0.0592,  0.0390,  0.0081,\n",
       "                       0.0615,  0.0349,  0.0078, -0.0588, -0.0298, -0.0422, -0.0033, -0.0535,\n",
       "                       0.0522,  0.0119,  0.0012,  0.0025,  0.0508,  0.0514,  0.0222,  0.0429,\n",
       "                       0.0583, -0.0369,  0.0617, -0.0572, -0.0128, -0.0085,  0.0072, -0.0221,\n",
       "                      -0.0342,  0.0043, -0.0384,  0.0023,  0.0085,  0.0578,  0.0202,  0.0141,\n",
       "                       0.0049,  0.0443, -0.0054,  0.0141,  0.0473, -0.0076, -0.0572, -0.0368,\n",
       "                      -0.0419, -0.0451, -0.0068,  0.0465, -0.0508,  0.0569,  0.0448,  0.0042,\n",
       "                      -0.0376,  0.0497,  0.0538, -0.0338, -0.0461, -0.0381, -0.0592,  0.0143,\n",
       "                      -0.0373, -0.0341, -0.0335, -0.0023,  0.0363,  0.0179, -0.0273,  0.0229,\n",
       "                      -0.0482,  0.0232, -0.0149, -0.0167,  0.0237,  0.0043, -0.0248, -0.0486,\n",
       "                       0.0465, -0.0343,  0.0045,  0.0580, -0.0545,  0.0447, -0.0031, -0.0172,\n",
       "                       0.0538, -0.0110,  0.0341,  0.0484, -0.0404, -0.0564, -0.0562,  0.0529,\n",
       "                      -0.0558,  0.0599, -0.0551, -0.0354,  0.0366,  0.0204,  0.0621,  0.0049,\n",
       "                       0.0389,  0.0439, -0.0039,  0.0355, -0.0059,  0.0278,  0.0380,  0.0391,\n",
       "                       0.0125,  0.0047,  0.0055, -0.0056, -0.0001, -0.0424,  0.0309, -0.0295,\n",
       "                       0.0283,  0.0057,  0.0557,  0.0397, -0.0542, -0.0205,  0.0604, -0.0251,\n",
       "                       0.0454, -0.0482, -0.0569, -0.0183, -0.0429,  0.0090,  0.0525,  0.0567,\n",
       "                       0.0333, -0.0474,  0.0331, -0.0557, -0.0072,  0.0127, -0.0106,  0.0508,\n",
       "                      -0.0581, -0.0077,  0.0301, -0.0167,  0.0414,  0.0218, -0.0157, -0.0563,\n",
       "                       0.0309, -0.0080,  0.0281,  0.0346, -0.0570,  0.0326, -0.0359,  0.0483,\n",
       "                       0.0576,  0.0454,  0.0156, -0.0191, -0.0196,  0.0027,  0.0358, -0.0529,\n",
       "                       0.0538,  0.0364,  0.0568,  0.0614, -0.0190,  0.0430,  0.0587, -0.0426,\n",
       "                       0.0117,  0.0462, -0.0198, -0.0260, -0.0004,  0.0440,  0.0062,  0.0178,\n",
       "                      -0.0443, -0.0011, -0.0246, -0.0292, -0.0157, -0.0227, -0.0265, -0.0392,\n",
       "                      -0.0135, -0.0132, -0.0618,  0.0155, -0.0158,  0.0598, -0.0425, -0.0182,\n",
       "                       0.0475, -0.0328, -0.0059, -0.0232, -0.0482, -0.0503,  0.0211, -0.0043,\n",
       "                      -0.0444, -0.0620,  0.0219, -0.0517,  0.0506, -0.0543,  0.0262, -0.0488,\n",
       "                      -0.0128, -0.0470, -0.0161, -0.0472,  0.0343,  0.0048,  0.0279, -0.0090,\n",
       "                       0.0481,  0.0519, -0.0141,  0.0363, -0.0490,  0.0620, -0.0437,  0.0611,\n",
       "                       0.0030, -0.0018,  0.0526, -0.0541,  0.0111, -0.0371, -0.0076, -0.0445,\n",
       "                       0.0415, -0.0486,  0.0231, -0.0240, -0.0089,  0.0401,  0.0526, -0.0179,\n",
       "                      -0.0226,  0.0096, -0.0585,  0.0057,  0.0026, -0.0444,  0.0481, -0.0097,\n",
       "                      -0.0107,  0.0603,  0.0180,  0.0051, -0.0174,  0.0573, -0.0484, -0.0170,\n",
       "                       0.0371,  0.0503,  0.0275,  0.0457, -0.0137,  0.0033,  0.0112, -0.0015])),\n",
       "             ('transformer_encoder.layers.1.linear2.weight',\n",
       "              tensor([[ 0.0190,  0.0391,  0.0098,  ..., -0.0332, -0.0300,  0.0406],\n",
       "                      [-0.0441,  0.0355, -0.0021,  ...,  0.0175,  0.0032, -0.0275],\n",
       "                      [ 0.0263,  0.0435,  0.0348,  ..., -0.0375,  0.0174,  0.0410],\n",
       "                      ...,\n",
       "                      [-0.0002,  0.0097,  0.0258,  ...,  0.0297, -0.0014,  0.0337],\n",
       "                      [-0.0064, -0.0398,  0.0275,  ...,  0.0248, -0.0074,  0.0428],\n",
       "                      [-0.0235, -0.0273,  0.0030,  ...,  0.0082, -0.0172, -0.0086]])),\n",
       "             ('transformer_encoder.layers.1.linear2.bias',\n",
       "              tensor([-3.5445e-02,  4.2078e-02,  3.7489e-02,  1.5458e-02, -3.1696e-02,\n",
       "                       1.5662e-02, -1.7062e-02, -2.6894e-02,  4.3101e-02,  1.2483e-02,\n",
       "                      -1.5951e-02, -3.8529e-02,  3.6679e-02,  9.4401e-03, -5.6878e-03,\n",
       "                      -8.0187e-04, -1.3012e-02, -3.4817e-02,  3.0071e-02, -4.1941e-02,\n",
       "                       3.7620e-02, -4.4113e-02,  1.8442e-02,  4.0405e-02,  2.1160e-02,\n",
       "                      -2.6937e-02, -1.8263e-02, -3.3392e-02, -1.5833e-02, -8.3444e-03,\n",
       "                      -9.7158e-03,  2.3173e-02, -1.6892e-02, -3.9735e-02,  2.7053e-02,\n",
       "                      -2.0633e-02,  8.1089e-03,  2.4037e-02,  2.3352e-02,  1.9211e-03,\n",
       "                      -4.2487e-02,  2.1164e-02, -4.4013e-02,  3.3830e-02,  3.3298e-02,\n",
       "                      -1.0017e-02,  1.0827e-02,  1.7310e-02, -4.2318e-02, -1.7905e-02,\n",
       "                      -3.2158e-02,  3.2761e-02,  1.0806e-02,  3.2861e-02,  1.2381e-02,\n",
       "                      -4.0578e-02,  1.7268e-02, -3.5420e-03,  1.7186e-02, -3.4806e-02,\n",
       "                      -8.9554e-03, -3.8740e-03,  2.5273e-02,  1.5126e-02,  2.3954e-03,\n",
       "                      -2.0692e-02, -2.0521e-02,  3.7228e-02, -5.3396e-03, -2.3859e-02,\n",
       "                      -3.7715e-04,  3.7184e-02,  1.4404e-02,  1.0404e-02, -3.2184e-02,\n",
       "                       4.0425e-02, -4.1437e-02, -1.3183e-02,  1.7903e-02, -4.1673e-02,\n",
       "                       3.7187e-02,  2.8307e-02, -7.2170e-03, -2.7673e-02, -8.7216e-03,\n",
       "                      -3.5181e-03,  4.1364e-02, -1.2885e-02,  1.2875e-02, -9.8797e-03,\n",
       "                      -4.0175e-03, -4.3612e-02,  1.0932e-02,  2.6114e-02,  4.1196e-03,\n",
       "                      -2.9660e-02, -3.1167e-02, -2.8473e-02,  2.8196e-02,  3.4629e-02,\n",
       "                      -3.2609e-02,  1.2070e-02, -2.6582e-02, -5.6353e-03,  4.2696e-02,\n",
       "                      -4.0232e-02, -3.6069e-02, -3.6540e-03, -9.5815e-03,  2.3308e-02,\n",
       "                       1.7874e-02, -3.8018e-02, -3.1772e-02,  3.6605e-02,  7.1798e-03,\n",
       "                      -2.0097e-02, -2.5350e-02,  3.9716e-02,  2.2675e-02,  2.0065e-02,\n",
       "                      -2.2576e-02, -2.5521e-02, -3.3310e-02, -2.7813e-02, -9.0519e-03,\n",
       "                      -1.5510e-02, -2.0994e-02, -1.1568e-03,  1.3245e-02,  3.0131e-02,\n",
       "                      -3.6274e-02,  1.5285e-02, -1.2761e-02, -2.7521e-02, -1.1160e-02,\n",
       "                      -3.9004e-02, -1.3988e-02, -4.1216e-02,  1.0512e-02,  3.1344e-02,\n",
       "                       2.6314e-02, -2.6237e-02, -3.3147e-03,  6.7774e-03,  2.9130e-02,\n",
       "                      -3.4364e-02,  8.9269e-03, -4.2865e-02,  4.1989e-03,  2.8245e-02,\n",
       "                       2.6055e-02,  1.4195e-02, -3.7617e-02, -2.9922e-02, -4.2516e-03,\n",
       "                       1.1784e-02, -2.1141e-02,  2.2682e-03, -1.2862e-02, -1.7733e-02,\n",
       "                      -3.4552e-02,  4.2237e-02,  2.6805e-02, -2.2115e-02,  1.8101e-02,\n",
       "                       2.6475e-02, -4.3735e-02, -4.0546e-02,  1.2328e-02,  2.2077e-04,\n",
       "                      -8.8190e-03, -1.8792e-02, -1.7790e-02,  1.6613e-02, -3.5486e-02,\n",
       "                      -2.9800e-02,  6.8258e-03,  9.3907e-03,  5.6923e-03,  1.9261e-02,\n",
       "                       3.1624e-02,  4.2791e-02, -3.0905e-02, -4.3155e-02,  1.6017e-02,\n",
       "                       3.5901e-02,  5.4481e-03,  1.7067e-02,  3.5968e-02,  3.3438e-02,\n",
       "                       2.0110e-02,  2.5586e-02, -3.2268e-02, -1.1292e-02,  3.9577e-02,\n",
       "                      -4.0378e-02,  2.8672e-02,  1.7209e-02,  1.8656e-02, -4.3669e-02,\n",
       "                      -1.5511e-02, -2.0712e-02,  1.4926e-02,  2.5555e-02,  2.8251e-02,\n",
       "                      -2.9214e-02,  1.2240e-02,  1.7536e-02,  2.6271e-02,  3.9623e-02,\n",
       "                       3.5714e-02,  1.8136e-02, -2.2940e-03,  1.2711e-02, -2.0913e-02,\n",
       "                       4.1893e-02,  3.6821e-02,  2.4358e-02, -2.7127e-02,  1.1934e-02,\n",
       "                      -2.6728e-02,  2.1124e-02,  2.6714e-02,  1.4910e-02, -1.6203e-02,\n",
       "                       2.5199e-02,  1.2310e-02, -7.8764e-03,  7.3779e-03, -2.8572e-02,\n",
       "                      -2.6836e-02,  2.8334e-02, -2.1867e-02,  2.8608e-02,  1.5258e-02,\n",
       "                       3.3105e-02,  1.2614e-02,  2.4805e-02, -1.2625e-03, -7.9512e-03,\n",
       "                      -1.5556e-02, -2.6654e-05, -4.1708e-02,  2.8784e-02, -4.3870e-02,\n",
       "                      -2.0565e-02,  9.6235e-03, -3.6816e-02,  4.0234e-03,  8.7999e-03,\n",
       "                      -1.7993e-03, -2.2539e-02, -1.1894e-02,  1.2395e-02, -9.4580e-03,\n",
       "                      -3.2794e-02])),\n",
       "             ('transformer_encoder.layers.1.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.1.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[ 3.6390e-02,  3.3565e-02, -2.8907e-02,  5.5794e-02,  5.7695e-02,\n",
       "                        3.3934e-02,  4.8760e-02, -3.6511e-02, -5.5915e-02, -4.8975e-02,\n",
       "                       -4.2449e-02,  2.6109e-02,  3.9939e-04, -1.6434e-02,  5.3330e-02,\n",
       "                        4.2798e-03, -6.1304e-02,  4.9841e-02, -8.0172e-03,  2.1261e-02,\n",
       "                        6.0760e-03, -1.3250e-03, -5.7630e-02, -9.4157e-03, -1.4670e-02,\n",
       "                       -3.5872e-02,  5.2482e-02,  4.7976e-02,  4.8501e-02,  2.3841e-02,\n",
       "                        5.9977e-02, -3.9565e-02, -3.9692e-02, -6.5787e-03, -3.2974e-02,\n",
       "                        4.6835e-02, -1.2669e-02,  2.4386e-02, -2.9884e-02, -1.4937e-02,\n",
       "                        4.7716e-02, -2.7020e-02, -3.5098e-03,  4.5605e-02, -1.4857e-02,\n",
       "                        1.6644e-02,  6.1140e-02,  4.9182e-02, -2.3471e-02, -1.7991e-02,\n",
       "                        3.8963e-02, -4.3426e-02,  2.6104e-02, -3.4901e-03,  1.7131e-03,\n",
       "                       -2.3298e-02, -8.8408e-03,  3.4726e-03, -3.6391e-02, -4.4927e-03,\n",
       "                       -4.1232e-02, -9.4604e-03, -5.4497e-02,  4.4146e-02, -3.5349e-02,\n",
       "                        1.2394e-02,  4.5698e-02, -5.9555e-02,  5.2056e-02, -1.4505e-02,\n",
       "                        4.7121e-02, -2.5921e-02,  2.0553e-02, -1.3285e-02,  3.4941e-02,\n",
       "                        1.7577e-02, -7.6969e-03,  4.0621e-02,  5.1439e-02, -6.1547e-02,\n",
       "                       -6.0536e-02,  5.5420e-02,  2.8961e-02, -4.3749e-02, -1.6000e-02,\n",
       "                       -6.1033e-02, -5.2233e-02,  2.1867e-02,  2.7187e-02,  4.1227e-02,\n",
       "                       -4.8992e-02, -3.2737e-02, -4.1396e-02,  4.3783e-02,  2.8257e-02,\n",
       "                       -5.0933e-02,  2.6616e-03, -4.2117e-02, -2.0279e-02, -1.8219e-02,\n",
       "                        2.4727e-02,  5.5105e-02,  1.3001e-02, -4.6067e-02, -9.0131e-03,\n",
       "                        2.1096e-02, -3.0693e-04, -3.9996e-02, -1.0141e-02,  2.6419e-02,\n",
       "                        6.1240e-03, -2.8362e-02, -5.8060e-02,  1.6406e-03, -4.1526e-02,\n",
       "                        4.3200e-02,  2.6851e-02,  3.5219e-02,  5.6889e-02,  6.2358e-02,\n",
       "                        5.0688e-02,  1.3604e-02, -2.2159e-02, -1.9077e-02, -1.9036e-02,\n",
       "                       -3.2925e-02, -3.1537e-02, -4.3364e-02,  1.9144e-02,  1.4659e-02,\n",
       "                       -5.2068e-02,  4.8095e-02, -1.8268e-02,  3.6051e-02, -7.3298e-03,\n",
       "                        6.0484e-02, -5.3302e-02, -2.0519e-02,  4.5191e-02, -4.7325e-02,\n",
       "                        1.5383e-02, -3.0867e-02,  6.4414e-03,  3.0676e-02, -7.1518e-05,\n",
       "                       -4.5283e-02, -5.2831e-03,  1.4936e-02, -5.3005e-02, -2.0888e-02,\n",
       "                       -1.6548e-02,  4.8836e-03, -2.0634e-02, -1.8088e-02,  6.1456e-02,\n",
       "                        1.7188e-02, -4.1008e-03,  4.5333e-02, -9.1618e-03, -2.9709e-02,\n",
       "                       -4.3987e-03,  5.0062e-02, -5.6872e-02, -3.1271e-02, -4.3093e-02,\n",
       "                       -1.1914e-02, -3.7418e-02,  4.6840e-02,  4.1179e-02,  1.8716e-02,\n",
       "                        5.5769e-02, -1.1256e-02,  3.3317e-03,  5.2424e-02, -5.6102e-02,\n",
       "                        9.3402e-04, -4.7904e-02, -4.3337e-02,  9.9740e-04,  1.4748e-02,\n",
       "                       -5.4185e-02,  4.0293e-02,  1.4294e-02, -2.3073e-03,  3.7586e-03,\n",
       "                        2.5008e-02,  7.8843e-03, -2.1291e-02,  3.6123e-02, -2.2958e-02,\n",
       "                       -4.1057e-02, -5.0647e-03,  7.7627e-03, -2.6167e-02,  4.5345e-02,\n",
       "                       -5.9707e-02,  1.7339e-02, -2.0534e-02,  1.2221e-02, -4.4944e-02,\n",
       "                       -3.0235e-02, -5.8192e-02, -5.8173e-02,  3.7852e-02, -2.4250e-02,\n",
       "                       -1.4397e-02, -5.6060e-02, -1.6920e-02, -7.8747e-04,  4.7703e-02,\n",
       "                        5.4713e-02, -4.9424e-02,  3.8213e-04, -3.8227e-02, -3.8205e-02,\n",
       "                       -2.5459e-02, -2.4236e-02,  1.6531e-02,  5.6770e-02,  4.2042e-02,\n",
       "                       -5.9162e-02, -5.9340e-03, -3.3232e-02,  4.1493e-02, -5.4719e-02,\n",
       "                        5.2991e-02, -3.3429e-03,  6.2036e-03, -3.2290e-03, -5.8683e-02,\n",
       "                        2.9605e-02, -2.3903e-02, -9.0078e-03, -4.1711e-02, -1.0760e-02,\n",
       "                       -4.4174e-03, -5.2900e-02, -5.0602e-02, -5.1100e-02,  2.2963e-03,\n",
       "                       -4.0340e-02, -1.9680e-02,  4.5017e-02, -3.3232e-02, -5.3539e-02,\n",
       "                       -2.1462e-02,  6.1971e-02,  3.2039e-02,  2.7012e-03, -8.6626e-03,\n",
       "                       -5.8123e-03,  2.6082e-02, -3.8651e-03,  2.6033e-02,  7.6679e-03,\n",
       "                       -2.2267e-02],\n",
       "                      [ 6.0798e-02,  7.4356e-03, -5.1192e-02,  3.0484e-02,  4.4163e-02,\n",
       "                        5.6955e-02, -1.4710e-02, -9.0187e-03, -2.4686e-02, -3.7365e-02,\n",
       "                       -2.0007e-02,  9.3638e-03, -9.2331e-03,  6.1432e-02, -3.3281e-02,\n",
       "                        4.7713e-02,  2.3634e-02,  4.8923e-02, -6.2059e-02, -1.9129e-03,\n",
       "                       -4.6335e-04,  6.0098e-02, -5.4379e-02,  5.2983e-02,  4.1702e-03,\n",
       "                        1.2891e-02,  1.0460e-02,  3.5920e-02, -1.1014e-02, -2.6697e-02,\n",
       "                       -3.8391e-02, -1.7204e-02,  2.3497e-02, -3.4624e-02, -1.5280e-03,\n",
       "                       -3.9727e-02, -5.0770e-02, -4.3529e-02, -5.3140e-02, -3.7709e-02,\n",
       "                        3.6460e-02, -3.0356e-03, -3.0335e-02, -2.6716e-02, -2.2590e-02,\n",
       "                        5.5354e-02, -4.0180e-02,  1.2031e-02, -5.2240e-02,  3.9573e-02,\n",
       "                       -1.4713e-02, -7.5343e-03, -4.2333e-02, -5.3972e-02,  3.7270e-02,\n",
       "                       -4.6558e-02,  2.6411e-02,  5.3722e-02,  2.5155e-02, -5.9956e-02,\n",
       "                        7.1299e-03, -1.3836e-02, -7.5359e-03,  3.4148e-02,  4.8950e-03,\n",
       "                       -5.0255e-03,  3.8469e-02, -1.5541e-02, -3.4657e-02,  3.2049e-02,\n",
       "                       -3.6627e-02,  3.3461e-03,  2.6522e-03,  5.4039e-02, -4.8073e-02,\n",
       "                        3.3888e-02, -5.8575e-02,  1.4821e-02,  4.3394e-02, -3.5767e-02,\n",
       "                        3.8615e-02, -2.6390e-02, -5.6565e-02, -3.0048e-02,  5.2971e-02,\n",
       "                       -5.9318e-02,  3.8841e-02, -1.7223e-02, -2.9972e-02,  1.8308e-02,\n",
       "                       -5.6554e-02, -1.3694e-02,  5.3459e-02, -2.2869e-02, -1.2475e-02,\n",
       "                       -2.3766e-02, -5.9938e-02,  5.5718e-03,  5.6773e-02,  5.8554e-02,\n",
       "                       -1.1990e-02, -1.5921e-02,  4.5084e-02, -5.8813e-03,  3.9867e-02,\n",
       "                       -2.8450e-02, -1.1058e-02,  1.8988e-02, -4.4520e-03, -5.6425e-02,\n",
       "                        8.8056e-03,  1.0289e-02,  1.3438e-02, -2.3918e-02,  5.0916e-02,\n",
       "                        2.2573e-03,  1.7259e-02,  1.9804e-02, -9.7922e-03, -2.3432e-03,\n",
       "                       -4.8948e-02,  5.9187e-02,  8.6648e-03, -3.9565e-02,  2.9475e-02,\n",
       "                       -5.1680e-02,  2.6708e-02, -2.7035e-02,  4.6314e-02,  3.9774e-02,\n",
       "                        6.2028e-02, -5.0737e-02, -7.4481e-03, -6.1849e-02,  9.2211e-04,\n",
       "                       -5.9907e-02, -1.2468e-02, -1.6521e-02, -8.3097e-04,  5.5041e-02,\n",
       "                       -5.9294e-02, -4.2425e-02, -5.5469e-02, -3.3337e-02, -3.3747e-02,\n",
       "                       -3.7214e-02,  1.8725e-02,  1.8506e-02,  3.8945e-02,  2.7542e-02,\n",
       "                       -2.6793e-02, -1.0628e-02, -6.8983e-04, -4.2545e-02, -7.9103e-03,\n",
       "                        4.7996e-02, -1.3226e-02,  3.7666e-02,  6.1004e-02,  5.8230e-02,\n",
       "                        7.6200e-03,  5.5555e-02, -3.0054e-02,  4.7053e-03,  3.4999e-02,\n",
       "                       -4.3860e-02,  4.4615e-02,  2.5529e-02, -1.4917e-02,  5.5578e-02,\n",
       "                        5.8736e-02,  2.0108e-02,  6.0023e-02, -4.1779e-02,  3.9249e-03,\n",
       "                       -1.3185e-02,  1.1428e-02, -3.9765e-02,  4.2962e-02,  2.7700e-02,\n",
       "                       -1.5152e-02, -5.8274e-02,  5.9573e-02,  6.2385e-02,  3.6674e-02,\n",
       "                       -5.1896e-02, -4.2347e-02,  2.7807e-02, -1.5964e-02, -5.4230e-02,\n",
       "                        1.3452e-02, -5.7508e-02,  6.0239e-02, -3.6042e-02,  4.9070e-02,\n",
       "                        2.5329e-02, -1.7181e-02, -4.6789e-03,  5.2863e-02,  5.4219e-02,\n",
       "                        1.9436e-02, -2.7191e-02,  2.1592e-02,  1.3574e-02, -1.5451e-02,\n",
       "                        4.7688e-02, -2.2568e-02, -2.6833e-02,  1.1235e-02,  5.5764e-02,\n",
       "                       -7.2378e-03,  3.0078e-05, -3.7199e-02, -8.1417e-03, -4.5511e-03,\n",
       "                        3.4316e-02, -3.7112e-02, -3.0947e-02,  2.4201e-04,  4.5997e-02,\n",
       "                        4.0989e-04, -2.1735e-02,  5.3581e-02, -1.3803e-02, -2.6462e-03,\n",
       "                        1.0107e-02,  2.7812e-02, -2.5910e-02, -3.6150e-02, -2.7967e-02,\n",
       "                       -1.2120e-02, -3.0023e-02,  6.2033e-02,  2.9333e-02,  6.0331e-02,\n",
       "                        1.9940e-02,  5.4105e-02, -2.9167e-02,  1.1792e-02,  6.1061e-02,\n",
       "                        3.9806e-02, -4.3444e-02,  1.1702e-04,  3.4234e-03, -1.3763e-02,\n",
       "                       -6.2312e-02,  3.4346e-02, -1.3076e-02,  3.0406e-02, -5.6849e-02,\n",
       "                        6.6962e-03, -4.5077e-03, -1.4393e-02,  4.7921e-04,  4.8201e-02,\n",
       "                       -5.2627e-02],\n",
       "                      [-5.1203e-02,  4.9537e-03, -4.8386e-02,  3.9871e-02,  3.0273e-02,\n",
       "                        5.3120e-02,  3.5787e-02, -1.4950e-02,  2.7185e-02, -4.1291e-03,\n",
       "                        3.5670e-02,  3.5781e-02,  1.0364e-02, -5.8461e-02, -5.5382e-02,\n",
       "                       -4.5502e-02, -4.2759e-02,  6.1316e-02, -5.3104e-02, -5.9871e-02,\n",
       "                       -1.9489e-02, -2.8856e-02, -5.9944e-02, -2.0417e-02, -2.6888e-02,\n",
       "                       -3.5494e-02,  3.6839e-02,  2.4721e-02, -1.3441e-02,  5.0659e-02,\n",
       "                        9.2896e-03, -4.0929e-02, -3.3335e-02,  4.3657e-02, -4.2009e-02,\n",
       "                        2.5272e-02,  2.1249e-02, -1.8978e-02,  6.1073e-02,  4.4038e-02,\n",
       "                        4.1329e-02,  5.6066e-03,  5.7312e-02,  1.7670e-02, -3.7127e-02,\n",
       "                       -3.9671e-03,  4.4357e-02,  5.4791e-02, -2.7304e-02, -6.9438e-03,\n",
       "                       -1.4377e-02,  3.4088e-02, -3.8722e-02,  5.1396e-02, -7.3889e-03,\n",
       "                       -5.4235e-02,  4.8629e-02, -5.1609e-02,  5.8808e-02, -7.1956e-03,\n",
       "                       -6.0257e-03, -3.3295e-02, -4.3048e-02,  2.1567e-02, -2.4812e-02,\n",
       "                        1.2733e-02,  1.7120e-02,  5.0212e-02,  3.7139e-02,  3.6450e-02,\n",
       "                       -4.4669e-02, -1.9670e-03, -2.9331e-02, -2.4051e-02, -4.2529e-03,\n",
       "                        6.0593e-02, -1.3114e-02,  7.0947e-03,  5.4979e-02,  2.2525e-02,\n",
       "                        2.2075e-02, -4.3522e-02, -6.2476e-02, -3.6214e-03,  3.0858e-02,\n",
       "                        4.6012e-02,  6.6941e-04,  3.0357e-02,  2.7873e-02, -7.3430e-03,\n",
       "                       -3.9240e-02,  2.9266e-02,  2.5308e-02, -1.6465e-02,  2.4063e-02,\n",
       "                       -3.7775e-03, -2.8291e-02,  2.1875e-02, -4.8395e-02, -2.5209e-02,\n",
       "                       -1.1592e-02,  3.0388e-02,  3.6798e-03,  1.1155e-02, -2.2988e-02,\n",
       "                        4.8642e-02, -3.9182e-02,  1.0233e-02, -3.5737e-02,  9.0966e-03,\n",
       "                        1.2576e-02, -6.1708e-02, -2.7371e-02, -1.5103e-02, -1.5450e-02,\n",
       "                       -3.6095e-02, -3.9027e-02,  2.5916e-02,  5.7442e-02,  3.1093e-02,\n",
       "                       -4.7266e-02, -7.6149e-04,  1.3684e-02, -4.7954e-02,  2.3833e-02,\n",
       "                        5.0846e-02,  2.2749e-02,  4.8315e-02,  4.8052e-02,  2.1326e-02,\n",
       "                        2.8349e-02,  2.8440e-02,  6.1257e-02,  4.9211e-02, -2.1852e-02,\n",
       "                        3.6635e-03,  5.0336e-02,  3.0283e-02, -7.3435e-04,  1.8830e-02,\n",
       "                       -5.5185e-02,  3.0824e-02,  3.1582e-02,  1.5926e-02, -3.2012e-03,\n",
       "                        1.3631e-02,  2.6801e-02, -2.3814e-02, -1.5705e-02,  3.0578e-02,\n",
       "                       -4.6289e-02,  4.4529e-02,  3.9949e-02, -1.0926e-02,  2.3556e-02,\n",
       "                       -1.3853e-02,  3.8089e-02, -4.0386e-02, -5.7492e-02,  5.3619e-03,\n",
       "                        5.9646e-02, -5.2117e-02, -2.5536e-02,  3.7594e-03, -5.2107e-02,\n",
       "                       -1.3944e-02,  4.9660e-02,  2.0447e-02,  2.4444e-02, -2.2531e-02,\n",
       "                       -2.8382e-02, -1.1770e-02,  3.9607e-02, -5.4657e-02,  1.3017e-02,\n",
       "                        4.6708e-02,  6.0695e-02,  4.2857e-02, -9.3992e-03, -5.8817e-02,\n",
       "                        4.6224e-02,  5.4844e-02, -1.4166e-02, -3.7869e-02, -9.4095e-03,\n",
       "                       -2.4841e-02, -4.2301e-02, -3.0951e-02,  2.3534e-02, -5.4825e-02,\n",
       "                        1.9375e-02, -5.1876e-02,  4.8621e-02,  5.4036e-02, -5.5046e-02,\n",
       "                        2.1808e-03, -8.9041e-03, -4.9282e-02, -7.2701e-03,  2.6658e-02,\n",
       "                       -1.7046e-02, -2.4899e-02,  4.2894e-02,  3.9951e-02,  2.7933e-02,\n",
       "                        4.3976e-02,  6.0728e-02, -3.1327e-02,  6.1736e-02, -1.3050e-02,\n",
       "                        1.5665e-02,  1.2168e-03, -1.2999e-02, -5.1851e-02, -4.6086e-02,\n",
       "                       -1.6614e-02, -3.6659e-02,  1.2494e-02, -4.2966e-02, -8.5906e-03,\n",
       "                        8.0650e-03, -3.5964e-02, -3.0494e-02, -1.8306e-02, -3.1376e-02,\n",
       "                        3.0427e-02, -1.9436e-02,  6.8909e-03,  1.0162e-02,  4.8440e-02,\n",
       "                       -4.1084e-02, -4.1402e-02, -5.0625e-02, -4.3898e-02,  1.5678e-02,\n",
       "                        2.3060e-02,  3.6118e-02, -5.5980e-02, -3.3094e-02,  3.2711e-02,\n",
       "                       -5.9067e-02,  1.1746e-02, -6.3830e-03, -4.4730e-03, -8.1227e-03,\n",
       "                       -4.7038e-02,  3.0085e-02,  4.5849e-02,  3.8183e-02,  7.1345e-03,\n",
       "                        2.7041e-02, -2.7736e-02,  4.1459e-02, -4.5265e-02, -4.5624e-02,\n",
       "                        2.4131e-02]])),\n",
       "             ('output_layer.bias', tensor([ 0.0135, -0.0164,  0.0151]))])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = {k: v for k, v in state_dicts.items() if 'output_layer' not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = clf.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.update(pretrained_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('project_inp.weight',\n",
       "              tensor([[ 0.0095, -0.3316, -0.1782,  ...,  0.2416, -0.0445, -0.2607],\n",
       "                      [ 0.0117,  0.0191,  0.1113,  ..., -0.1261, -0.3249,  0.0184],\n",
       "                      [-0.2678, -0.3241, -0.2310,  ..., -0.3159, -0.1026,  0.2919],\n",
       "                      ...,\n",
       "                      [-0.0139, -0.2165, -0.0465,  ...,  0.1054, -0.3085, -0.0795],\n",
       "                      [-0.0894, -0.0648,  0.2919,  ...,  0.1727,  0.2195,  0.2586],\n",
       "                      [ 0.0978, -0.1104,  0.0179,  ..., -0.1141,  0.0085,  0.0403]])),\n",
       "             ('project_inp.bias',\n",
       "              tensor([ 2.1350e-01,  2.8938e-02,  2.8948e-01, -1.2193e-01,  1.8135e-01,\n",
       "                      -3.2278e-01, -3.1745e-01,  1.3326e-01,  2.4129e-01,  1.8440e-01,\n",
       "                       1.2089e-01,  1.7494e-02, -2.6797e-01, -2.8569e-01, -1.9773e-01,\n",
       "                       3.0811e-01,  1.5666e-01, -2.0352e-01, -1.5753e-01,  2.8303e-01,\n",
       "                       8.4822e-02, -2.3827e-01,  2.6142e-01,  2.5984e-01, -5.2212e-02,\n",
       "                       8.3560e-02, -2.4264e-02,  9.6476e-02,  6.9540e-03,  1.3299e-01,\n",
       "                       2.1923e-01,  3.0521e-01,  2.1244e-01, -1.3023e-01,  2.6877e-02,\n",
       "                       2.8470e-01,  3.1360e-02, -3.0991e-02, -2.9366e-01,  1.1131e-01,\n",
       "                       7.4754e-02, -2.4346e-01,  2.1233e-01, -3.3069e-01,  1.4899e-01,\n",
       "                      -2.6583e-01,  2.5655e-01, -2.8504e-01, -2.7098e-01,  2.5337e-01,\n",
       "                      -3.0961e-01,  2.1478e-01, -2.7384e-01, -2.6803e-01, -5.0077e-02,\n",
       "                       8.4000e-02, -1.2931e-04, -1.1150e-01, -8.6129e-02, -3.1641e-01,\n",
       "                      -2.6941e-01,  1.8093e-01, -5.4680e-02,  6.3983e-02,  1.3107e-01,\n",
       "                       1.5451e-01, -1.7258e-01,  2.3589e-01, -1.6518e-01,  2.4703e-01,\n",
       "                      -2.5399e-01, -6.6563e-02,  2.7003e-01, -2.9310e-01,  9.8720e-02,\n",
       "                      -1.7208e-01,  2.5064e-01,  2.9054e-01,  2.6798e-01, -2.2981e-01,\n",
       "                       1.5977e-01,  2.4064e-01, -2.0478e-01,  3.2880e-01,  8.6954e-02,\n",
       "                      -1.0921e-01,  6.1661e-02, -2.0140e-01, -2.6775e-01,  2.9710e-01,\n",
       "                       2.2136e-01, -1.7754e-01, -1.9917e-01,  1.8384e-01, -1.8070e-02,\n",
       "                       4.6888e-02,  3.5248e-02, -2.2808e-01,  3.0873e-01,  4.6095e-04,\n",
       "                      -2.7516e-01,  7.2586e-02, -1.9688e-01,  1.3354e-01, -1.4330e-01,\n",
       "                       2.5474e-01,  5.3651e-02,  1.1154e-01,  1.9665e-01,  2.9435e-01,\n",
       "                       2.2136e-01,  2.4738e-01, -2.7124e-02, -1.6943e-01, -1.7386e-01,\n",
       "                      -8.0827e-02,  1.6959e-01, -1.5340e-01,  1.8387e-01,  2.6730e-01,\n",
       "                       1.6870e-01, -1.4552e-02, -1.3376e-01,  1.9502e-02,  1.2836e-01,\n",
       "                      -2.5789e-01,  2.7194e-01, -1.5807e-01, -1.4426e-01,  8.4056e-02,\n",
       "                       2.5412e-02, -2.6276e-01, -1.1835e-01, -1.6189e-01, -1.1745e-01,\n",
       "                       1.0986e-01, -4.7713e-02, -1.9400e-01, -1.5803e-01, -2.6408e-01,\n",
       "                       2.2037e-01,  8.8728e-02, -5.5452e-03, -9.0232e-03,  8.6157e-02,\n",
       "                       5.8391e-02, -7.3802e-02,  2.9778e-02,  2.8663e-01,  1.6745e-02,\n",
       "                       1.1114e-01, -1.1463e-01,  2.1173e-01, -2.0328e-01, -3.0078e-01,\n",
       "                      -2.6154e-01,  6.1439e-02,  1.0052e-01, -2.9618e-01,  1.2487e-01,\n",
       "                       3.2187e-01,  9.2101e-02, -1.6464e-01, -2.1949e-01, -2.0202e-01,\n",
       "                       3.0607e-01,  5.8424e-02, -1.6670e-01,  2.0034e-01, -2.4211e-01,\n",
       "                       5.1733e-02, -2.5058e-01,  1.5387e-01, -6.2409e-02, -1.2390e-01,\n",
       "                       4.8759e-02, -2.1627e-01,  1.0911e-01, -1.8003e-01, -2.2926e-01,\n",
       "                      -1.1681e-01, -1.1574e-01, -5.7555e-02,  7.5253e-02, -2.0256e-01,\n",
       "                       2.1330e-02, -1.2863e-01, -2.5223e-02, -5.8394e-02, -2.6579e-01,\n",
       "                       2.6145e-02,  6.3170e-02, -3.9654e-03, -1.1584e-01,  1.5494e-01,\n",
       "                       4.8523e-02, -1.6374e-01,  3.8003e-02,  2.0690e-01, -9.4438e-02,\n",
       "                       2.0005e-01,  2.2332e-01,  2.1496e-01, -8.1340e-03,  1.2125e-01,\n",
       "                       2.3761e-01, -1.4636e-01,  1.3763e-01,  1.8535e-01,  2.8921e-01,\n",
       "                       2.2626e-01,  2.6390e-01,  1.5523e-01, -2.5338e-01, -2.7570e-01,\n",
       "                      -1.3509e-01,  2.7623e-01,  1.5892e-01,  8.3583e-02,  2.9891e-01,\n",
       "                      -1.0217e-01, -6.6856e-02, -2.9765e-01, -2.6923e-01,  2.8064e-01,\n",
       "                      -2.8222e-02, -2.6953e-01,  1.1722e-01,  1.3342e-01,  2.4590e-01,\n",
       "                      -3.4817e-02, -2.2064e-01,  2.4995e-01, -2.2594e-02, -2.9585e-01,\n",
       "                       1.0529e-01,  1.5141e-01,  1.9175e-01, -7.0436e-02,  1.3384e-01,\n",
       "                       1.4826e-01, -2.7857e-02,  2.8901e-01,  1.5189e-01,  3.3124e-01,\n",
       "                       2.7244e-01,  1.5870e-01, -5.8046e-03, -2.5374e-01, -2.3202e-01,\n",
       "                      -4.0057e-04,  3.1197e-01,  6.3211e-02,  2.0430e-01,  6.7755e-03,\n",
       "                      -3.1857e-01])),\n",
       "             ('pos_enc.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  8.0196e-01,  ...,  1.0000e+00,\n",
       "                         1.0746e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.5814e-01,  ...,  1.0000e+00,\n",
       "                         2.1492e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 9.9482e-01, -1.0162e-01,  1.8368e-01,  ...,  9.9957e-01,\n",
       "                         2.7184e-02,  9.9963e-01]],\n",
       "              \n",
       "                      [[ 4.5200e-01, -8.9202e-01, -6.7859e-01,  ...,  9.9957e-01,\n",
       "                         2.7292e-02,  9.9963e-01]],\n",
       "              \n",
       "                      [[-5.0639e-01, -8.6230e-01, -9.9443e-01,  ...,  9.9957e-01,\n",
       "                         2.7399e-02,  9.9962e-01]]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.0276,  0.0536, -0.0131,  ..., -0.0560, -0.0397, -0.0330],\n",
       "                      [ 0.0649,  0.0011, -0.0400,  ...,  0.0704,  0.0129,  0.0431],\n",
       "                      [-0.0238, -0.0449, -0.0402,  ...,  0.0259,  0.0282, -0.0369],\n",
       "                      ...,\n",
       "                      [ 0.0359,  0.0475, -0.0429,  ..., -0.0137,  0.0545,  0.0362],\n",
       "                      [-0.0650, -0.0041,  0.0694,  ..., -0.0683,  0.0578,  0.0595],\n",
       "                      [-0.0641,  0.0287, -0.0660,  ..., -0.0187,  0.0441, -0.0304]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0413, -0.0243, -0.0056,  ..., -0.0466, -0.0594,  0.0008],\n",
       "                      [-0.0611, -0.0195,  0.0535,  ...,  0.0109, -0.0440,  0.0621],\n",
       "                      [ 0.0024, -0.0062,  0.0216,  ...,  0.0307,  0.0338, -0.0294],\n",
       "                      ...,\n",
       "                      [ 0.0118,  0.0324, -0.0038,  ...,  0.0419, -0.0233, -0.0504],\n",
       "                      [-0.0583, -0.0409, -0.0058,  ...,  0.0074,  0.0009,  0.0311],\n",
       "                      [-0.0269,  0.0272, -0.0441,  ..., -0.0021, -0.0365,  0.0314]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.linear1.weight',\n",
       "              tensor([[ 0.0544, -0.0119,  0.0081,  ...,  0.0473, -0.0320,  0.0394],\n",
       "                      [ 0.0251,  0.0533, -0.0346,  ..., -0.0418, -0.0369, -0.0044],\n",
       "                      [ 0.0088, -0.0546,  0.0130,  ...,  0.0009, -0.0603, -0.0337],\n",
       "                      ...,\n",
       "                      [-0.0051, -0.0237,  0.0031,  ..., -0.0072, -0.0567,  0.0122],\n",
       "                      [-0.0326,  0.0285, -0.0415,  ..., -0.0339, -0.0167, -0.0091],\n",
       "                      [-0.0570,  0.0027,  0.0469,  ..., -0.0622, -0.0157,  0.0010]])),\n",
       "             ('transformer_encoder.layers.0.linear1.bias',\n",
       "              tensor([ 0.0010, -0.0557,  0.0428,  0.0305, -0.0428, -0.0278,  0.0567, -0.0504,\n",
       "                      -0.0047,  0.0560,  0.0147,  0.0527, -0.0496,  0.0125,  0.0200, -0.0542,\n",
       "                       0.0313, -0.0454, -0.0530,  0.0446, -0.0082, -0.0370,  0.0062,  0.0314,\n",
       "                      -0.0323, -0.0274, -0.0369,  0.0526, -0.0429, -0.0438,  0.0184,  0.0299,\n",
       "                      -0.0417, -0.0258, -0.0416, -0.0112,  0.0217, -0.0064, -0.0621,  0.0325,\n",
       "                      -0.0382, -0.0525,  0.0573, -0.0113,  0.0375, -0.0491,  0.0621, -0.0087,\n",
       "                       0.0164,  0.0129, -0.0353,  0.0133, -0.0493,  0.0543,  0.0272, -0.0371,\n",
       "                      -0.0563, -0.0158, -0.0588,  0.0452, -0.0158,  0.0492, -0.0051, -0.0400,\n",
       "                      -0.0233, -0.0232, -0.0463,  0.0616, -0.0239, -0.0096,  0.0483, -0.0388,\n",
       "                       0.0604,  0.0570, -0.0273, -0.0496,  0.0021,  0.0460, -0.0019, -0.0550,\n",
       "                      -0.0077,  0.0224,  0.0272, -0.0144,  0.0429,  0.0156, -0.0153, -0.0466,\n",
       "                       0.0013, -0.0138, -0.0608, -0.0588,  0.0022,  0.0574, -0.0326,  0.0230,\n",
       "                      -0.0498, -0.0230, -0.0418, -0.0330, -0.0401, -0.0224,  0.0153, -0.0063,\n",
       "                      -0.0537, -0.0416, -0.0090, -0.0383,  0.0029,  0.0289, -0.0420,  0.0127,\n",
       "                       0.0225,  0.0278, -0.0261,  0.0491,  0.0250, -0.0263, -0.0564,  0.0618,\n",
       "                      -0.0316, -0.0184, -0.0197, -0.0137, -0.0234,  0.0203,  0.0102,  0.0240,\n",
       "                      -0.0278,  0.0505,  0.0187,  0.0478,  0.0106,  0.0010,  0.0066, -0.0602,\n",
       "                      -0.0452,  0.0309,  0.0412, -0.0244,  0.0324,  0.0595,  0.0010,  0.0143,\n",
       "                       0.0270, -0.0180,  0.0102, -0.0099,  0.0270,  0.0568, -0.0559, -0.0098,\n",
       "                      -0.0410,  0.0522, -0.0509, -0.0036,  0.0176, -0.0144,  0.0345, -0.0097,\n",
       "                       0.0606, -0.0383,  0.0047,  0.0129, -0.0551,  0.0096,  0.0534,  0.0515,\n",
       "                      -0.0307,  0.0154, -0.0104, -0.0434, -0.0243,  0.0040,  0.0584, -0.0020,\n",
       "                       0.0484, -0.0326,  0.0547, -0.0258,  0.0261, -0.0339, -0.0201,  0.0202,\n",
       "                      -0.0157, -0.0558,  0.0123, -0.0246,  0.0301,  0.0462, -0.0182,  0.0339,\n",
       "                       0.0142, -0.0070, -0.0284,  0.0524,  0.0543,  0.0611,  0.0484, -0.0425,\n",
       "                       0.0377,  0.0108, -0.0163, -0.0493,  0.0224,  0.0136, -0.0387, -0.0571,\n",
       "                      -0.0250,  0.0324, -0.0411, -0.0061, -0.0419,  0.0114,  0.0078,  0.0575,\n",
       "                       0.0615, -0.0507,  0.0154,  0.0272, -0.0089,  0.0296,  0.0350,  0.0172,\n",
       "                       0.0247,  0.0200, -0.0335,  0.0201, -0.0556,  0.0410, -0.0100, -0.0356,\n",
       "                       0.0438, -0.0398,  0.0386,  0.0170, -0.0097,  0.0275, -0.0428,  0.0165,\n",
       "                      -0.0039,  0.0232,  0.0153,  0.0218,  0.0034,  0.0021, -0.0435,  0.0444,\n",
       "                      -0.0099, -0.0510, -0.0292, -0.0287,  0.0021, -0.0465,  0.0123,  0.0459,\n",
       "                       0.0083, -0.0264,  0.0583, -0.0301, -0.0132, -0.0030,  0.0196, -0.0125,\n",
       "                      -0.0562, -0.0114, -0.0152, -0.0047,  0.0412,  0.0254,  0.0161, -0.0405,\n",
       "                      -0.0070, -0.0133,  0.0297, -0.0551, -0.0155, -0.0104, -0.0307, -0.0531,\n",
       "                      -0.0052, -0.0311, -0.0457, -0.0354, -0.0122, -0.0167,  0.0144,  0.0484,\n",
       "                      -0.0040, -0.0071, -0.0105, -0.0053, -0.0472,  0.0120, -0.0331, -0.0287,\n",
       "                       0.0233,  0.0539, -0.0485, -0.0099,  0.0355,  0.0182,  0.0289,  0.0583,\n",
       "                       0.0045,  0.0222, -0.0568,  0.0592,  0.0462,  0.0219, -0.0280, -0.0077,\n",
       "                       0.0103, -0.0537,  0.0250,  0.0259,  0.0043,  0.0514,  0.0090,  0.0014,\n",
       "                      -0.0559,  0.0042, -0.0280,  0.0472, -0.0596, -0.0538, -0.0101, -0.0086,\n",
       "                      -0.0465,  0.0587, -0.0463,  0.0176, -0.0432, -0.0392,  0.0112, -0.0065,\n",
       "                      -0.0026,  0.0587, -0.0244, -0.0240, -0.0079, -0.0417,  0.0602, -0.0624,\n",
       "                       0.0290, -0.0262,  0.0108,  0.0155, -0.0399,  0.0482, -0.0344,  0.0265,\n",
       "                       0.0263,  0.0312,  0.0226, -0.0110, -0.0622,  0.0329, -0.0101,  0.0568,\n",
       "                      -0.0520, -0.0083, -0.0121,  0.0012,  0.0519, -0.0546, -0.0591,  0.0226,\n",
       "                      -0.0218,  0.0450,  0.0204, -0.0460, -0.0614,  0.0257,  0.0285,  0.0364,\n",
       "                       0.0594, -0.0473,  0.0442, -0.0596,  0.0057, -0.0507, -0.0424,  0.0388,\n",
       "                      -0.0398, -0.0461, -0.0459,  0.0127,  0.0569, -0.0603,  0.0057, -0.0482,\n",
       "                      -0.0108, -0.0166, -0.0214, -0.0131, -0.0385, -0.0176,  0.0221,  0.0494,\n",
       "                       0.0453, -0.0130, -0.0013,  0.0379, -0.0601, -0.0356,  0.0042, -0.0333,\n",
       "                      -0.0250,  0.0447, -0.0547,  0.0561,  0.0584,  0.0313, -0.0550,  0.0479,\n",
       "                       0.0437,  0.0517, -0.0533, -0.0284, -0.0428,  0.0213,  0.0057,  0.0244,\n",
       "                       0.0079, -0.0408,  0.0194,  0.0311,  0.0580,  0.0119,  0.0301,  0.0030,\n",
       "                      -0.0007,  0.0554, -0.0399,  0.0303, -0.0004,  0.0250,  0.0539,  0.0383,\n",
       "                      -0.0392, -0.0108, -0.0566, -0.0420, -0.0433, -0.0154,  0.0460, -0.0504,\n",
       "                       0.0153, -0.0318,  0.0318, -0.0529,  0.0136, -0.0311, -0.0057,  0.0398,\n",
       "                       0.0256, -0.0385,  0.0130, -0.0562, -0.0182,  0.0074,  0.0186,  0.0206,\n",
       "                       0.0501, -0.0596,  0.0399,  0.0460, -0.0096, -0.0443, -0.0610,  0.0534,\n",
       "                       0.0429,  0.0122,  0.0503, -0.0580, -0.0603, -0.0113,  0.0207,  0.0190,\n",
       "                       0.0233,  0.0146, -0.0486, -0.0523, -0.0292, -0.0401, -0.0274,  0.0472,\n",
       "                      -0.0209, -0.0253, -0.0288, -0.0238, -0.0240,  0.0389,  0.0343,  0.0237,\n",
       "                      -0.0319,  0.0540, -0.0493,  0.0371, -0.0251, -0.0009, -0.0222,  0.0330,\n",
       "                      -0.0354,  0.0445, -0.0137, -0.0429, -0.0402, -0.0063,  0.0056,  0.0284])),\n",
       "             ('transformer_encoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.0099,  0.0259,  0.0089,  ..., -0.0242, -0.0382, -0.0375],\n",
       "                      [ 0.0229, -0.0007,  0.0168,  ..., -0.0174,  0.0069,  0.0188],\n",
       "                      [ 0.0072, -0.0004,  0.0330,  ..., -0.0371,  0.0031, -0.0025],\n",
       "                      ...,\n",
       "                      [ 0.0214,  0.0016,  0.0168,  ..., -0.0062,  0.0207,  0.0194],\n",
       "                      [ 0.0381, -0.0320,  0.0302,  ...,  0.0276, -0.0391, -0.0442],\n",
       "                      [ 0.0279, -0.0007, -0.0152,  ...,  0.0297, -0.0130, -0.0091]])),\n",
       "             ('transformer_encoder.layers.0.linear2.bias',\n",
       "              tensor([ 3.8542e-03, -3.2290e-02,  4.2353e-02, -1.2284e-02, -1.7174e-02,\n",
       "                      -8.4651e-04,  2.7133e-03, -1.7278e-02, -1.6432e-02, -1.7907e-02,\n",
       "                       1.9230e-02, -2.7209e-03, -2.4402e-02,  1.9766e-02, -2.5376e-02,\n",
       "                      -2.7071e-02,  3.4596e-02,  4.2030e-02,  2.3776e-02, -3.7232e-02,\n",
       "                       7.6564e-03,  2.9008e-02,  7.1684e-03,  2.5443e-02, -1.5477e-02,\n",
       "                      -1.5501e-02, -3.6943e-02,  3.9461e-02,  3.7019e-02,  2.1596e-02,\n",
       "                       1.2261e-02, -2.9326e-02, -1.9968e-03, -1.8955e-02, -2.9256e-02,\n",
       "                       3.5972e-02, -1.2531e-02, -1.8824e-02, -2.4984e-02,  2.2576e-02,\n",
       "                      -3.5609e-02,  1.0822e-02,  4.0044e-02,  4.9206e-03, -3.9999e-02,\n",
       "                       3.6969e-02,  4.3466e-02, -1.6573e-02,  3.6047e-02, -3.1432e-02,\n",
       "                       8.8252e-03,  3.2204e-02, -4.3233e-02,  4.0485e-02,  3.9697e-02,\n",
       "                      -1.0330e-02, -4.3745e-03,  2.1861e-02,  3.4276e-02, -1.3550e-02,\n",
       "                      -5.9580e-03,  2.6315e-02,  2.3037e-03,  1.5150e-02,  4.3662e-03,\n",
       "                       3.7375e-02, -3.5016e-02,  1.8821e-02, -3.0983e-02,  1.4284e-02,\n",
       "                       1.2242e-02,  3.9996e-02,  1.0117e-02, -3.0114e-04,  1.2365e-02,\n",
       "                       2.8562e-02, -1.8929e-03,  2.3953e-02, -6.7806e-03, -2.1796e-02,\n",
       "                       2.6812e-02, -3.3124e-02, -9.7850e-03, -3.4592e-02,  8.1883e-03,\n",
       "                      -4.0174e-02,  3.1359e-02, -3.6908e-02, -3.5921e-02,  2.9909e-02,\n",
       "                      -8.9635e-03,  4.2269e-03, -2.8048e-02, -3.2694e-02,  2.2036e-03,\n",
       "                       1.0856e-02,  2.2098e-02,  2.7760e-03,  1.4745e-03,  1.2750e-02,\n",
       "                       2.2112e-02, -3.4994e-02, -3.0689e-02, -4.1224e-02,  1.3478e-02,\n",
       "                      -2.9655e-02, -3.6988e-03,  6.7663e-03, -3.9233e-02,  1.9521e-02,\n",
       "                       1.6777e-02, -3.9206e-02, -2.8018e-03,  3.2864e-02, -1.2045e-02,\n",
       "                      -2.2963e-02,  2.3726e-02,  1.8635e-02, -2.0240e-02, -2.0427e-02,\n",
       "                       4.2338e-02, -7.9168e-04,  3.9715e-02, -4.0160e-02, -3.0452e-02,\n",
       "                      -3.0587e-02, -1.6802e-02,  3.8212e-02,  4.2172e-02,  2.3414e-02,\n",
       "                      -3.5016e-02,  4.2209e-02,  2.3553e-02, -6.5596e-03,  2.9466e-04,\n",
       "                      -4.3928e-02,  1.5862e-02,  2.1492e-02, -2.4418e-02, -3.6685e-02,\n",
       "                      -2.1604e-02,  1.9521e-02, -4.0840e-02,  1.5520e-02,  3.0857e-02,\n",
       "                      -3.9760e-02,  2.9695e-02,  1.0696e-02, -4.1729e-02,  5.8867e-03,\n",
       "                      -3.8597e-02, -1.3919e-02,  3.3088e-02, -3.3492e-02, -5.0490e-03,\n",
       "                      -1.8934e-02,  1.7558e-02, -7.8807e-04,  2.6219e-02,  3.0738e-02,\n",
       "                      -2.9230e-02, -1.0037e-02,  7.6080e-03,  4.3780e-03,  1.0750e-02,\n",
       "                       1.6507e-02,  6.2242e-03, -7.0282e-04, -2.2187e-02,  3.7613e-02,\n",
       "                       6.2944e-03,  2.8516e-02, -2.9744e-02,  4.6710e-03, -3.4940e-02,\n",
       "                      -1.6752e-02,  2.4878e-02, -4.1905e-02,  8.5206e-04, -1.6213e-02,\n",
       "                       1.7667e-02, -6.7418e-04,  9.1887e-03,  1.2236e-02, -9.6477e-03,\n",
       "                      -1.5513e-02,  3.8980e-02, -1.9732e-02,  2.6055e-02, -1.7331e-02,\n",
       "                      -4.0266e-02,  1.2438e-02,  3.5243e-02,  3.0296e-02,  2.3596e-02,\n",
       "                       6.3014e-03, -4.2832e-02, -1.7239e-02, -2.4711e-02,  4.2652e-02,\n",
       "                      -1.0987e-02, -2.7430e-02,  3.2060e-02, -7.5551e-03,  3.3510e-02,\n",
       "                      -2.4508e-02, -2.8733e-02,  1.1269e-02, -2.1332e-02,  3.2218e-02,\n",
       "                       2.6870e-03, -1.4892e-02, -2.7051e-02, -3.6994e-02, -4.3881e-02,\n",
       "                       3.1920e-02, -1.1243e-02, -9.5689e-03,  4.1138e-02, -4.1005e-02,\n",
       "                       1.6554e-02,  6.1474e-03,  3.1910e-02, -1.6082e-02,  3.8641e-02,\n",
       "                       1.1303e-02, -2.8987e-02, -2.2235e-02, -2.9952e-02,  5.7207e-03,\n",
       "                      -1.5346e-02,  2.0446e-02, -3.0480e-03,  2.6544e-02,  3.0430e-03,\n",
       "                       2.5275e-02, -3.2085e-02,  1.9367e-03,  7.2412e-05,  2.5582e-02,\n",
       "                      -3.8713e-02,  3.9982e-02, -3.2078e-02, -3.9155e-02,  2.1589e-02,\n",
       "                      -6.2638e-03, -1.6050e-02, -7.5757e-03,  1.3278e-02, -1.4551e-02,\n",
       "                      -2.8155e-02, -3.9969e-02,  3.0027e-02, -2.3635e-02, -2.7101e-02,\n",
       "                       1.8678e-02])),\n",
       "             ('transformer_encoder.layers.0.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.0.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.0276,  0.0536, -0.0131,  ..., -0.0560, -0.0397, -0.0330],\n",
       "                      [ 0.0649,  0.0011, -0.0400,  ...,  0.0704,  0.0129,  0.0431],\n",
       "                      [-0.0238, -0.0449, -0.0402,  ...,  0.0259,  0.0282, -0.0369],\n",
       "                      ...,\n",
       "                      [ 0.0359,  0.0475, -0.0429,  ..., -0.0137,  0.0545,  0.0362],\n",
       "                      [-0.0650, -0.0041,  0.0694,  ..., -0.0683,  0.0578,  0.0595],\n",
       "                      [-0.0641,  0.0287, -0.0660,  ..., -0.0187,  0.0441, -0.0304]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0413, -0.0243, -0.0056,  ..., -0.0466, -0.0594,  0.0008],\n",
       "                      [-0.0611, -0.0195,  0.0535,  ...,  0.0109, -0.0440,  0.0621],\n",
       "                      [ 0.0024, -0.0062,  0.0216,  ...,  0.0307,  0.0338, -0.0294],\n",
       "                      ...,\n",
       "                      [ 0.0118,  0.0324, -0.0038,  ...,  0.0419, -0.0233, -0.0504],\n",
       "                      [-0.0583, -0.0409, -0.0058,  ...,  0.0074,  0.0009,  0.0311],\n",
       "                      [-0.0269,  0.0272, -0.0441,  ..., -0.0021, -0.0365,  0.0314]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.linear1.weight',\n",
       "              tensor([[ 0.0544, -0.0119,  0.0081,  ...,  0.0473, -0.0320,  0.0394],\n",
       "                      [ 0.0251,  0.0533, -0.0346,  ..., -0.0418, -0.0369, -0.0044],\n",
       "                      [ 0.0088, -0.0546,  0.0130,  ...,  0.0009, -0.0603, -0.0337],\n",
       "                      ...,\n",
       "                      [-0.0051, -0.0237,  0.0031,  ..., -0.0072, -0.0567,  0.0122],\n",
       "                      [-0.0326,  0.0285, -0.0415,  ..., -0.0339, -0.0167, -0.0091],\n",
       "                      [-0.0570,  0.0027,  0.0469,  ..., -0.0622, -0.0157,  0.0010]])),\n",
       "             ('transformer_encoder.layers.1.linear1.bias',\n",
       "              tensor([ 0.0010, -0.0557,  0.0428,  0.0305, -0.0428, -0.0278,  0.0567, -0.0504,\n",
       "                      -0.0047,  0.0560,  0.0147,  0.0527, -0.0496,  0.0125,  0.0200, -0.0542,\n",
       "                       0.0313, -0.0454, -0.0530,  0.0446, -0.0082, -0.0370,  0.0062,  0.0314,\n",
       "                      -0.0323, -0.0274, -0.0369,  0.0526, -0.0429, -0.0438,  0.0184,  0.0299,\n",
       "                      -0.0417, -0.0258, -0.0416, -0.0112,  0.0217, -0.0064, -0.0621,  0.0325,\n",
       "                      -0.0382, -0.0525,  0.0573, -0.0113,  0.0375, -0.0491,  0.0621, -0.0087,\n",
       "                       0.0164,  0.0129, -0.0353,  0.0133, -0.0493,  0.0543,  0.0272, -0.0371,\n",
       "                      -0.0563, -0.0158, -0.0588,  0.0452, -0.0158,  0.0492, -0.0051, -0.0400,\n",
       "                      -0.0233, -0.0232, -0.0463,  0.0616, -0.0239, -0.0096,  0.0483, -0.0388,\n",
       "                       0.0604,  0.0570, -0.0273, -0.0496,  0.0021,  0.0460, -0.0019, -0.0550,\n",
       "                      -0.0077,  0.0224,  0.0272, -0.0144,  0.0429,  0.0156, -0.0153, -0.0466,\n",
       "                       0.0013, -0.0138, -0.0608, -0.0588,  0.0022,  0.0574, -0.0326,  0.0230,\n",
       "                      -0.0498, -0.0230, -0.0418, -0.0330, -0.0401, -0.0224,  0.0153, -0.0063,\n",
       "                      -0.0537, -0.0416, -0.0090, -0.0383,  0.0029,  0.0289, -0.0420,  0.0127,\n",
       "                       0.0225,  0.0278, -0.0261,  0.0491,  0.0250, -0.0263, -0.0564,  0.0618,\n",
       "                      -0.0316, -0.0184, -0.0197, -0.0137, -0.0234,  0.0203,  0.0102,  0.0240,\n",
       "                      -0.0278,  0.0505,  0.0187,  0.0478,  0.0106,  0.0010,  0.0066, -0.0602,\n",
       "                      -0.0452,  0.0309,  0.0412, -0.0244,  0.0324,  0.0595,  0.0010,  0.0143,\n",
       "                       0.0270, -0.0180,  0.0102, -0.0099,  0.0270,  0.0568, -0.0559, -0.0098,\n",
       "                      -0.0410,  0.0522, -0.0509, -0.0036,  0.0176, -0.0144,  0.0345, -0.0097,\n",
       "                       0.0606, -0.0383,  0.0047,  0.0129, -0.0551,  0.0096,  0.0534,  0.0515,\n",
       "                      -0.0307,  0.0154, -0.0104, -0.0434, -0.0243,  0.0040,  0.0584, -0.0020,\n",
       "                       0.0484, -0.0326,  0.0547, -0.0258,  0.0261, -0.0339, -0.0201,  0.0202,\n",
       "                      -0.0157, -0.0558,  0.0123, -0.0246,  0.0301,  0.0462, -0.0182,  0.0339,\n",
       "                       0.0142, -0.0070, -0.0284,  0.0524,  0.0543,  0.0611,  0.0484, -0.0425,\n",
       "                       0.0377,  0.0108, -0.0163, -0.0493,  0.0224,  0.0136, -0.0387, -0.0571,\n",
       "                      -0.0250,  0.0324, -0.0411, -0.0061, -0.0419,  0.0114,  0.0078,  0.0575,\n",
       "                       0.0615, -0.0507,  0.0154,  0.0272, -0.0089,  0.0296,  0.0350,  0.0172,\n",
       "                       0.0247,  0.0200, -0.0335,  0.0201, -0.0556,  0.0410, -0.0100, -0.0356,\n",
       "                       0.0438, -0.0398,  0.0386,  0.0170, -0.0097,  0.0275, -0.0428,  0.0165,\n",
       "                      -0.0039,  0.0232,  0.0153,  0.0218,  0.0034,  0.0021, -0.0435,  0.0444,\n",
       "                      -0.0099, -0.0510, -0.0292, -0.0287,  0.0021, -0.0465,  0.0123,  0.0459,\n",
       "                       0.0083, -0.0264,  0.0583, -0.0301, -0.0132, -0.0030,  0.0196, -0.0125,\n",
       "                      -0.0562, -0.0114, -0.0152, -0.0047,  0.0412,  0.0254,  0.0161, -0.0405,\n",
       "                      -0.0070, -0.0133,  0.0297, -0.0551, -0.0155, -0.0104, -0.0307, -0.0531,\n",
       "                      -0.0052, -0.0311, -0.0457, -0.0354, -0.0122, -0.0167,  0.0144,  0.0484,\n",
       "                      -0.0040, -0.0071, -0.0105, -0.0053, -0.0472,  0.0120, -0.0331, -0.0287,\n",
       "                       0.0233,  0.0539, -0.0485, -0.0099,  0.0355,  0.0182,  0.0289,  0.0583,\n",
       "                       0.0045,  0.0222, -0.0568,  0.0592,  0.0462,  0.0219, -0.0280, -0.0077,\n",
       "                       0.0103, -0.0537,  0.0250,  0.0259,  0.0043,  0.0514,  0.0090,  0.0014,\n",
       "                      -0.0559,  0.0042, -0.0280,  0.0472, -0.0596, -0.0538, -0.0101, -0.0086,\n",
       "                      -0.0465,  0.0587, -0.0463,  0.0176, -0.0432, -0.0392,  0.0112, -0.0065,\n",
       "                      -0.0026,  0.0587, -0.0244, -0.0240, -0.0079, -0.0417,  0.0602, -0.0624,\n",
       "                       0.0290, -0.0262,  0.0108,  0.0155, -0.0399,  0.0482, -0.0344,  0.0265,\n",
       "                       0.0263,  0.0312,  0.0226, -0.0110, -0.0622,  0.0329, -0.0101,  0.0568,\n",
       "                      -0.0520, -0.0083, -0.0121,  0.0012,  0.0519, -0.0546, -0.0591,  0.0226,\n",
       "                      -0.0218,  0.0450,  0.0204, -0.0460, -0.0614,  0.0257,  0.0285,  0.0364,\n",
       "                       0.0594, -0.0473,  0.0442, -0.0596,  0.0057, -0.0507, -0.0424,  0.0388,\n",
       "                      -0.0398, -0.0461, -0.0459,  0.0127,  0.0569, -0.0603,  0.0057, -0.0482,\n",
       "                      -0.0108, -0.0166, -0.0214, -0.0131, -0.0385, -0.0176,  0.0221,  0.0494,\n",
       "                       0.0453, -0.0130, -0.0013,  0.0379, -0.0601, -0.0356,  0.0042, -0.0333,\n",
       "                      -0.0250,  0.0447, -0.0547,  0.0561,  0.0584,  0.0313, -0.0550,  0.0479,\n",
       "                       0.0437,  0.0517, -0.0533, -0.0284, -0.0428,  0.0213,  0.0057,  0.0244,\n",
       "                       0.0079, -0.0408,  0.0194,  0.0311,  0.0580,  0.0119,  0.0301,  0.0030,\n",
       "                      -0.0007,  0.0554, -0.0399,  0.0303, -0.0004,  0.0250,  0.0539,  0.0383,\n",
       "                      -0.0392, -0.0108, -0.0566, -0.0420, -0.0433, -0.0154,  0.0460, -0.0504,\n",
       "                       0.0153, -0.0318,  0.0318, -0.0529,  0.0136, -0.0311, -0.0057,  0.0398,\n",
       "                       0.0256, -0.0385,  0.0130, -0.0562, -0.0182,  0.0074,  0.0186,  0.0206,\n",
       "                       0.0501, -0.0596,  0.0399,  0.0460, -0.0096, -0.0443, -0.0610,  0.0534,\n",
       "                       0.0429,  0.0122,  0.0503, -0.0580, -0.0603, -0.0113,  0.0207,  0.0190,\n",
       "                       0.0233,  0.0146, -0.0486, -0.0523, -0.0292, -0.0401, -0.0274,  0.0472,\n",
       "                      -0.0209, -0.0253, -0.0288, -0.0238, -0.0240,  0.0389,  0.0343,  0.0237,\n",
       "                      -0.0319,  0.0540, -0.0493,  0.0371, -0.0251, -0.0009, -0.0222,  0.0330,\n",
       "                      -0.0354,  0.0445, -0.0137, -0.0429, -0.0402, -0.0063,  0.0056,  0.0284])),\n",
       "             ('transformer_encoder.layers.1.linear2.weight',\n",
       "              tensor([[ 0.0099,  0.0259,  0.0089,  ..., -0.0242, -0.0382, -0.0375],\n",
       "                      [ 0.0229, -0.0007,  0.0168,  ..., -0.0174,  0.0069,  0.0188],\n",
       "                      [ 0.0072, -0.0004,  0.0330,  ..., -0.0371,  0.0031, -0.0025],\n",
       "                      ...,\n",
       "                      [ 0.0214,  0.0016,  0.0168,  ..., -0.0062,  0.0207,  0.0194],\n",
       "                      [ 0.0381, -0.0320,  0.0302,  ...,  0.0276, -0.0391, -0.0442],\n",
       "                      [ 0.0279, -0.0007, -0.0152,  ...,  0.0297, -0.0130, -0.0091]])),\n",
       "             ('transformer_encoder.layers.1.linear2.bias',\n",
       "              tensor([ 3.8542e-03, -3.2290e-02,  4.2353e-02, -1.2284e-02, -1.7174e-02,\n",
       "                      -8.4651e-04,  2.7133e-03, -1.7278e-02, -1.6432e-02, -1.7907e-02,\n",
       "                       1.9230e-02, -2.7209e-03, -2.4402e-02,  1.9766e-02, -2.5376e-02,\n",
       "                      -2.7071e-02,  3.4596e-02,  4.2030e-02,  2.3776e-02, -3.7232e-02,\n",
       "                       7.6564e-03,  2.9008e-02,  7.1684e-03,  2.5443e-02, -1.5477e-02,\n",
       "                      -1.5501e-02, -3.6943e-02,  3.9461e-02,  3.7019e-02,  2.1596e-02,\n",
       "                       1.2261e-02, -2.9326e-02, -1.9968e-03, -1.8955e-02, -2.9256e-02,\n",
       "                       3.5972e-02, -1.2531e-02, -1.8824e-02, -2.4984e-02,  2.2576e-02,\n",
       "                      -3.5609e-02,  1.0822e-02,  4.0044e-02,  4.9206e-03, -3.9999e-02,\n",
       "                       3.6969e-02,  4.3466e-02, -1.6573e-02,  3.6047e-02, -3.1432e-02,\n",
       "                       8.8252e-03,  3.2204e-02, -4.3233e-02,  4.0485e-02,  3.9697e-02,\n",
       "                      -1.0330e-02, -4.3745e-03,  2.1861e-02,  3.4276e-02, -1.3550e-02,\n",
       "                      -5.9580e-03,  2.6315e-02,  2.3037e-03,  1.5150e-02,  4.3662e-03,\n",
       "                       3.7375e-02, -3.5016e-02,  1.8821e-02, -3.0983e-02,  1.4284e-02,\n",
       "                       1.2242e-02,  3.9996e-02,  1.0117e-02, -3.0114e-04,  1.2365e-02,\n",
       "                       2.8562e-02, -1.8929e-03,  2.3953e-02, -6.7806e-03, -2.1796e-02,\n",
       "                       2.6812e-02, -3.3124e-02, -9.7850e-03, -3.4592e-02,  8.1883e-03,\n",
       "                      -4.0174e-02,  3.1359e-02, -3.6908e-02, -3.5921e-02,  2.9909e-02,\n",
       "                      -8.9635e-03,  4.2269e-03, -2.8048e-02, -3.2694e-02,  2.2036e-03,\n",
       "                       1.0856e-02,  2.2098e-02,  2.7760e-03,  1.4745e-03,  1.2750e-02,\n",
       "                       2.2112e-02, -3.4994e-02, -3.0689e-02, -4.1224e-02,  1.3478e-02,\n",
       "                      -2.9655e-02, -3.6988e-03,  6.7663e-03, -3.9233e-02,  1.9521e-02,\n",
       "                       1.6777e-02, -3.9206e-02, -2.8018e-03,  3.2864e-02, -1.2045e-02,\n",
       "                      -2.2963e-02,  2.3726e-02,  1.8635e-02, -2.0240e-02, -2.0427e-02,\n",
       "                       4.2338e-02, -7.9168e-04,  3.9715e-02, -4.0160e-02, -3.0452e-02,\n",
       "                      -3.0587e-02, -1.6802e-02,  3.8212e-02,  4.2172e-02,  2.3414e-02,\n",
       "                      -3.5016e-02,  4.2209e-02,  2.3553e-02, -6.5596e-03,  2.9466e-04,\n",
       "                      -4.3928e-02,  1.5862e-02,  2.1492e-02, -2.4418e-02, -3.6685e-02,\n",
       "                      -2.1604e-02,  1.9521e-02, -4.0840e-02,  1.5520e-02,  3.0857e-02,\n",
       "                      -3.9760e-02,  2.9695e-02,  1.0696e-02, -4.1729e-02,  5.8867e-03,\n",
       "                      -3.8597e-02, -1.3919e-02,  3.3088e-02, -3.3492e-02, -5.0490e-03,\n",
       "                      -1.8934e-02,  1.7558e-02, -7.8807e-04,  2.6219e-02,  3.0738e-02,\n",
       "                      -2.9230e-02, -1.0037e-02,  7.6080e-03,  4.3780e-03,  1.0750e-02,\n",
       "                       1.6507e-02,  6.2242e-03, -7.0282e-04, -2.2187e-02,  3.7613e-02,\n",
       "                       6.2944e-03,  2.8516e-02, -2.9744e-02,  4.6710e-03, -3.4940e-02,\n",
       "                      -1.6752e-02,  2.4878e-02, -4.1905e-02,  8.5206e-04, -1.6213e-02,\n",
       "                       1.7667e-02, -6.7418e-04,  9.1887e-03,  1.2236e-02, -9.6477e-03,\n",
       "                      -1.5513e-02,  3.8980e-02, -1.9732e-02,  2.6055e-02, -1.7331e-02,\n",
       "                      -4.0266e-02,  1.2438e-02,  3.5243e-02,  3.0296e-02,  2.3596e-02,\n",
       "                       6.3014e-03, -4.2832e-02, -1.7239e-02, -2.4711e-02,  4.2652e-02,\n",
       "                      -1.0987e-02, -2.7430e-02,  3.2060e-02, -7.5551e-03,  3.3510e-02,\n",
       "                      -2.4508e-02, -2.8733e-02,  1.1269e-02, -2.1332e-02,  3.2218e-02,\n",
       "                       2.6870e-03, -1.4892e-02, -2.7051e-02, -3.6994e-02, -4.3881e-02,\n",
       "                       3.1920e-02, -1.1243e-02, -9.5689e-03,  4.1138e-02, -4.1005e-02,\n",
       "                       1.6554e-02,  6.1474e-03,  3.1910e-02, -1.6082e-02,  3.8641e-02,\n",
       "                       1.1303e-02, -2.8987e-02, -2.2235e-02, -2.9952e-02,  5.7207e-03,\n",
       "                      -1.5346e-02,  2.0446e-02, -3.0480e-03,  2.6544e-02,  3.0430e-03,\n",
       "                       2.5275e-02, -3.2085e-02,  1.9367e-03,  7.2412e-05,  2.5582e-02,\n",
       "                      -3.8713e-02,  3.9982e-02, -3.2078e-02, -3.9155e-02,  2.1589e-02,\n",
       "                      -6.2638e-03, -1.6050e-02, -7.5757e-03,  1.3278e-02, -1.4551e-02,\n",
       "                      -2.8155e-02, -3.9969e-02,  3.0027e-02, -2.3635e-02, -2.7101e-02,\n",
       "                       1.8678e-02])),\n",
       "             ('transformer_encoder.layers.1.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.1.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[ 3.6390e-02,  3.3565e-02, -2.8907e-02,  5.5794e-02,  5.7695e-02,\n",
       "                        3.3934e-02,  4.8760e-02, -3.6511e-02, -5.5915e-02, -4.8975e-02,\n",
       "                       -4.2449e-02,  2.6109e-02,  3.9939e-04, -1.6434e-02,  5.3330e-02,\n",
       "                        4.2798e-03, -6.1304e-02,  4.9841e-02, -8.0172e-03,  2.1261e-02,\n",
       "                        6.0760e-03, -1.3250e-03, -5.7630e-02, -9.4157e-03, -1.4670e-02,\n",
       "                       -3.5872e-02,  5.2482e-02,  4.7976e-02,  4.8501e-02,  2.3841e-02,\n",
       "                        5.9977e-02, -3.9565e-02, -3.9692e-02, -6.5787e-03, -3.2974e-02,\n",
       "                        4.6835e-02, -1.2669e-02,  2.4386e-02, -2.9884e-02, -1.4937e-02,\n",
       "                        4.7716e-02, -2.7020e-02, -3.5098e-03,  4.5605e-02, -1.4857e-02,\n",
       "                        1.6644e-02,  6.1140e-02,  4.9182e-02, -2.3471e-02, -1.7991e-02,\n",
       "                        3.8963e-02, -4.3426e-02,  2.6104e-02, -3.4901e-03,  1.7131e-03,\n",
       "                       -2.3298e-02, -8.8408e-03,  3.4726e-03, -3.6391e-02, -4.4927e-03,\n",
       "                       -4.1232e-02, -9.4604e-03, -5.4497e-02,  4.4146e-02, -3.5349e-02,\n",
       "                        1.2394e-02,  4.5698e-02, -5.9555e-02,  5.2056e-02, -1.4505e-02,\n",
       "                        4.7121e-02, -2.5921e-02,  2.0553e-02, -1.3285e-02,  3.4941e-02,\n",
       "                        1.7577e-02, -7.6969e-03,  4.0621e-02,  5.1439e-02, -6.1547e-02,\n",
       "                       -6.0536e-02,  5.5420e-02,  2.8961e-02, -4.3749e-02, -1.6000e-02,\n",
       "                       -6.1033e-02, -5.2233e-02,  2.1867e-02,  2.7187e-02,  4.1227e-02,\n",
       "                       -4.8992e-02, -3.2737e-02, -4.1396e-02,  4.3783e-02,  2.8257e-02,\n",
       "                       -5.0933e-02,  2.6616e-03, -4.2117e-02, -2.0279e-02, -1.8219e-02,\n",
       "                        2.4727e-02,  5.5105e-02,  1.3001e-02, -4.6067e-02, -9.0131e-03,\n",
       "                        2.1096e-02, -3.0693e-04, -3.9996e-02, -1.0141e-02,  2.6419e-02,\n",
       "                        6.1240e-03, -2.8362e-02, -5.8060e-02,  1.6406e-03, -4.1526e-02,\n",
       "                        4.3200e-02,  2.6851e-02,  3.5219e-02,  5.6889e-02,  6.2358e-02,\n",
       "                        5.0688e-02,  1.3604e-02, -2.2159e-02, -1.9077e-02, -1.9036e-02,\n",
       "                       -3.2925e-02, -3.1537e-02, -4.3364e-02,  1.9144e-02,  1.4659e-02,\n",
       "                       -5.2068e-02,  4.8095e-02, -1.8268e-02,  3.6051e-02, -7.3298e-03,\n",
       "                        6.0484e-02, -5.3302e-02, -2.0519e-02,  4.5191e-02, -4.7325e-02,\n",
       "                        1.5383e-02, -3.0867e-02,  6.4414e-03,  3.0676e-02, -7.1518e-05,\n",
       "                       -4.5283e-02, -5.2831e-03,  1.4936e-02, -5.3005e-02, -2.0888e-02,\n",
       "                       -1.6548e-02,  4.8836e-03, -2.0634e-02, -1.8088e-02,  6.1456e-02,\n",
       "                        1.7188e-02, -4.1008e-03,  4.5333e-02, -9.1618e-03, -2.9709e-02,\n",
       "                       -4.3987e-03,  5.0062e-02, -5.6872e-02, -3.1271e-02, -4.3093e-02,\n",
       "                       -1.1914e-02, -3.7418e-02,  4.6840e-02,  4.1179e-02,  1.8716e-02,\n",
       "                        5.5769e-02, -1.1256e-02,  3.3317e-03,  5.2424e-02, -5.6102e-02,\n",
       "                        9.3402e-04, -4.7904e-02, -4.3337e-02,  9.9740e-04,  1.4748e-02,\n",
       "                       -5.4185e-02,  4.0293e-02,  1.4294e-02, -2.3073e-03,  3.7586e-03,\n",
       "                        2.5008e-02,  7.8843e-03, -2.1291e-02,  3.6123e-02, -2.2958e-02,\n",
       "                       -4.1057e-02, -5.0647e-03,  7.7627e-03, -2.6167e-02,  4.5345e-02,\n",
       "                       -5.9707e-02,  1.7339e-02, -2.0534e-02,  1.2221e-02, -4.4944e-02,\n",
       "                       -3.0235e-02, -5.8192e-02, -5.8173e-02,  3.7852e-02, -2.4250e-02,\n",
       "                       -1.4397e-02, -5.6060e-02, -1.6920e-02, -7.8747e-04,  4.7703e-02,\n",
       "                        5.4713e-02, -4.9424e-02,  3.8213e-04, -3.8227e-02, -3.8205e-02,\n",
       "                       -2.5459e-02, -2.4236e-02,  1.6531e-02,  5.6770e-02,  4.2042e-02,\n",
       "                       -5.9162e-02, -5.9340e-03, -3.3232e-02,  4.1493e-02, -5.4719e-02,\n",
       "                        5.2991e-02, -3.3429e-03,  6.2036e-03, -3.2290e-03, -5.8683e-02,\n",
       "                        2.9605e-02, -2.3903e-02, -9.0078e-03, -4.1711e-02, -1.0760e-02,\n",
       "                       -4.4174e-03, -5.2900e-02, -5.0602e-02, -5.1100e-02,  2.2963e-03,\n",
       "                       -4.0340e-02, -1.9680e-02,  4.5017e-02, -3.3232e-02, -5.3539e-02,\n",
       "                       -2.1462e-02,  6.1971e-02,  3.2039e-02,  2.7012e-03, -8.6626e-03,\n",
       "                       -5.8123e-03,  2.6082e-02, -3.8651e-03,  2.6033e-02,  7.6679e-03,\n",
       "                       -2.2267e-02],\n",
       "                      [ 6.0798e-02,  7.4356e-03, -5.1192e-02,  3.0484e-02,  4.4163e-02,\n",
       "                        5.6955e-02, -1.4710e-02, -9.0187e-03, -2.4686e-02, -3.7365e-02,\n",
       "                       -2.0007e-02,  9.3638e-03, -9.2331e-03,  6.1432e-02, -3.3281e-02,\n",
       "                        4.7713e-02,  2.3634e-02,  4.8923e-02, -6.2059e-02, -1.9129e-03,\n",
       "                       -4.6335e-04,  6.0098e-02, -5.4379e-02,  5.2983e-02,  4.1702e-03,\n",
       "                        1.2891e-02,  1.0460e-02,  3.5920e-02, -1.1014e-02, -2.6697e-02,\n",
       "                       -3.8391e-02, -1.7204e-02,  2.3497e-02, -3.4624e-02, -1.5280e-03,\n",
       "                       -3.9727e-02, -5.0770e-02, -4.3529e-02, -5.3140e-02, -3.7709e-02,\n",
       "                        3.6460e-02, -3.0356e-03, -3.0335e-02, -2.6716e-02, -2.2590e-02,\n",
       "                        5.5354e-02, -4.0180e-02,  1.2031e-02, -5.2240e-02,  3.9573e-02,\n",
       "                       -1.4713e-02, -7.5343e-03, -4.2333e-02, -5.3972e-02,  3.7270e-02,\n",
       "                       -4.6558e-02,  2.6411e-02,  5.3722e-02,  2.5155e-02, -5.9956e-02,\n",
       "                        7.1299e-03, -1.3836e-02, -7.5359e-03,  3.4148e-02,  4.8950e-03,\n",
       "                       -5.0255e-03,  3.8469e-02, -1.5541e-02, -3.4657e-02,  3.2049e-02,\n",
       "                       -3.6627e-02,  3.3461e-03,  2.6522e-03,  5.4039e-02, -4.8073e-02,\n",
       "                        3.3888e-02, -5.8575e-02,  1.4821e-02,  4.3394e-02, -3.5767e-02,\n",
       "                        3.8615e-02, -2.6390e-02, -5.6565e-02, -3.0048e-02,  5.2971e-02,\n",
       "                       -5.9318e-02,  3.8841e-02, -1.7223e-02, -2.9972e-02,  1.8308e-02,\n",
       "                       -5.6554e-02, -1.3694e-02,  5.3459e-02, -2.2869e-02, -1.2475e-02,\n",
       "                       -2.3766e-02, -5.9938e-02,  5.5718e-03,  5.6773e-02,  5.8554e-02,\n",
       "                       -1.1990e-02, -1.5921e-02,  4.5084e-02, -5.8813e-03,  3.9867e-02,\n",
       "                       -2.8450e-02, -1.1058e-02,  1.8988e-02, -4.4520e-03, -5.6425e-02,\n",
       "                        8.8056e-03,  1.0289e-02,  1.3438e-02, -2.3918e-02,  5.0916e-02,\n",
       "                        2.2573e-03,  1.7259e-02,  1.9804e-02, -9.7922e-03, -2.3432e-03,\n",
       "                       -4.8948e-02,  5.9187e-02,  8.6648e-03, -3.9565e-02,  2.9475e-02,\n",
       "                       -5.1680e-02,  2.6708e-02, -2.7035e-02,  4.6314e-02,  3.9774e-02,\n",
       "                        6.2028e-02, -5.0737e-02, -7.4481e-03, -6.1849e-02,  9.2211e-04,\n",
       "                       -5.9907e-02, -1.2468e-02, -1.6521e-02, -8.3097e-04,  5.5041e-02,\n",
       "                       -5.9294e-02, -4.2425e-02, -5.5469e-02, -3.3337e-02, -3.3747e-02,\n",
       "                       -3.7214e-02,  1.8725e-02,  1.8506e-02,  3.8945e-02,  2.7542e-02,\n",
       "                       -2.6793e-02, -1.0628e-02, -6.8983e-04, -4.2545e-02, -7.9103e-03,\n",
       "                        4.7996e-02, -1.3226e-02,  3.7666e-02,  6.1004e-02,  5.8230e-02,\n",
       "                        7.6200e-03,  5.5555e-02, -3.0054e-02,  4.7053e-03,  3.4999e-02,\n",
       "                       -4.3860e-02,  4.4615e-02,  2.5529e-02, -1.4917e-02,  5.5578e-02,\n",
       "                        5.8736e-02,  2.0108e-02,  6.0023e-02, -4.1779e-02,  3.9249e-03,\n",
       "                       -1.3185e-02,  1.1428e-02, -3.9765e-02,  4.2962e-02,  2.7700e-02,\n",
       "                       -1.5152e-02, -5.8274e-02,  5.9573e-02,  6.2385e-02,  3.6674e-02,\n",
       "                       -5.1896e-02, -4.2347e-02,  2.7807e-02, -1.5964e-02, -5.4230e-02,\n",
       "                        1.3452e-02, -5.7508e-02,  6.0239e-02, -3.6042e-02,  4.9070e-02,\n",
       "                        2.5329e-02, -1.7181e-02, -4.6789e-03,  5.2863e-02,  5.4219e-02,\n",
       "                        1.9436e-02, -2.7191e-02,  2.1592e-02,  1.3574e-02, -1.5451e-02,\n",
       "                        4.7688e-02, -2.2568e-02, -2.6833e-02,  1.1235e-02,  5.5764e-02,\n",
       "                       -7.2378e-03,  3.0078e-05, -3.7199e-02, -8.1417e-03, -4.5511e-03,\n",
       "                        3.4316e-02, -3.7112e-02, -3.0947e-02,  2.4201e-04,  4.5997e-02,\n",
       "                        4.0989e-04, -2.1735e-02,  5.3581e-02, -1.3803e-02, -2.6462e-03,\n",
       "                        1.0107e-02,  2.7812e-02, -2.5910e-02, -3.6150e-02, -2.7967e-02,\n",
       "                       -1.2120e-02, -3.0023e-02,  6.2033e-02,  2.9333e-02,  6.0331e-02,\n",
       "                        1.9940e-02,  5.4105e-02, -2.9167e-02,  1.1792e-02,  6.1061e-02,\n",
       "                        3.9806e-02, -4.3444e-02,  1.1702e-04,  3.4234e-03, -1.3763e-02,\n",
       "                       -6.2312e-02,  3.4346e-02, -1.3076e-02,  3.0406e-02, -5.6849e-02,\n",
       "                        6.6962e-03, -4.5077e-03, -1.4393e-02,  4.7921e-04,  4.8201e-02,\n",
       "                       -5.2627e-02],\n",
       "                      [-5.1203e-02,  4.9537e-03, -4.8386e-02,  3.9871e-02,  3.0273e-02,\n",
       "                        5.3120e-02,  3.5787e-02, -1.4950e-02,  2.7185e-02, -4.1291e-03,\n",
       "                        3.5670e-02,  3.5781e-02,  1.0364e-02, -5.8461e-02, -5.5382e-02,\n",
       "                       -4.5502e-02, -4.2759e-02,  6.1316e-02, -5.3104e-02, -5.9871e-02,\n",
       "                       -1.9489e-02, -2.8856e-02, -5.9944e-02, -2.0417e-02, -2.6888e-02,\n",
       "                       -3.5494e-02,  3.6839e-02,  2.4721e-02, -1.3441e-02,  5.0659e-02,\n",
       "                        9.2896e-03, -4.0929e-02, -3.3335e-02,  4.3657e-02, -4.2009e-02,\n",
       "                        2.5272e-02,  2.1249e-02, -1.8978e-02,  6.1073e-02,  4.4038e-02,\n",
       "                        4.1329e-02,  5.6066e-03,  5.7312e-02,  1.7670e-02, -3.7127e-02,\n",
       "                       -3.9671e-03,  4.4357e-02,  5.4791e-02, -2.7304e-02, -6.9438e-03,\n",
       "                       -1.4377e-02,  3.4088e-02, -3.8722e-02,  5.1396e-02, -7.3889e-03,\n",
       "                       -5.4235e-02,  4.8629e-02, -5.1609e-02,  5.8808e-02, -7.1956e-03,\n",
       "                       -6.0257e-03, -3.3295e-02, -4.3048e-02,  2.1567e-02, -2.4812e-02,\n",
       "                        1.2733e-02,  1.7120e-02,  5.0212e-02,  3.7139e-02,  3.6450e-02,\n",
       "                       -4.4669e-02, -1.9670e-03, -2.9331e-02, -2.4051e-02, -4.2529e-03,\n",
       "                        6.0593e-02, -1.3114e-02,  7.0947e-03,  5.4979e-02,  2.2525e-02,\n",
       "                        2.2075e-02, -4.3522e-02, -6.2476e-02, -3.6214e-03,  3.0858e-02,\n",
       "                        4.6012e-02,  6.6941e-04,  3.0357e-02,  2.7873e-02, -7.3430e-03,\n",
       "                       -3.9240e-02,  2.9266e-02,  2.5308e-02, -1.6465e-02,  2.4063e-02,\n",
       "                       -3.7775e-03, -2.8291e-02,  2.1875e-02, -4.8395e-02, -2.5209e-02,\n",
       "                       -1.1592e-02,  3.0388e-02,  3.6798e-03,  1.1155e-02, -2.2988e-02,\n",
       "                        4.8642e-02, -3.9182e-02,  1.0233e-02, -3.5737e-02,  9.0966e-03,\n",
       "                        1.2576e-02, -6.1708e-02, -2.7371e-02, -1.5103e-02, -1.5450e-02,\n",
       "                       -3.6095e-02, -3.9027e-02,  2.5916e-02,  5.7442e-02,  3.1093e-02,\n",
       "                       -4.7266e-02, -7.6149e-04,  1.3684e-02, -4.7954e-02,  2.3833e-02,\n",
       "                        5.0846e-02,  2.2749e-02,  4.8315e-02,  4.8052e-02,  2.1326e-02,\n",
       "                        2.8349e-02,  2.8440e-02,  6.1257e-02,  4.9211e-02, -2.1852e-02,\n",
       "                        3.6635e-03,  5.0336e-02,  3.0283e-02, -7.3435e-04,  1.8830e-02,\n",
       "                       -5.5185e-02,  3.0824e-02,  3.1582e-02,  1.5926e-02, -3.2012e-03,\n",
       "                        1.3631e-02,  2.6801e-02, -2.3814e-02, -1.5705e-02,  3.0578e-02,\n",
       "                       -4.6289e-02,  4.4529e-02,  3.9949e-02, -1.0926e-02,  2.3556e-02,\n",
       "                       -1.3853e-02,  3.8089e-02, -4.0386e-02, -5.7492e-02,  5.3619e-03,\n",
       "                        5.9646e-02, -5.2117e-02, -2.5536e-02,  3.7594e-03, -5.2107e-02,\n",
       "                       -1.3944e-02,  4.9660e-02,  2.0447e-02,  2.4444e-02, -2.2531e-02,\n",
       "                       -2.8382e-02, -1.1770e-02,  3.9607e-02, -5.4657e-02,  1.3017e-02,\n",
       "                        4.6708e-02,  6.0695e-02,  4.2857e-02, -9.3992e-03, -5.8817e-02,\n",
       "                        4.6224e-02,  5.4844e-02, -1.4166e-02, -3.7869e-02, -9.4095e-03,\n",
       "                       -2.4841e-02, -4.2301e-02, -3.0951e-02,  2.3534e-02, -5.4825e-02,\n",
       "                        1.9375e-02, -5.1876e-02,  4.8621e-02,  5.4036e-02, -5.5046e-02,\n",
       "                        2.1808e-03, -8.9041e-03, -4.9282e-02, -7.2701e-03,  2.6658e-02,\n",
       "                       -1.7046e-02, -2.4899e-02,  4.2894e-02,  3.9951e-02,  2.7933e-02,\n",
       "                        4.3976e-02,  6.0728e-02, -3.1327e-02,  6.1736e-02, -1.3050e-02,\n",
       "                        1.5665e-02,  1.2168e-03, -1.2999e-02, -5.1851e-02, -4.6086e-02,\n",
       "                       -1.6614e-02, -3.6659e-02,  1.2494e-02, -4.2966e-02, -8.5906e-03,\n",
       "                        8.0650e-03, -3.5964e-02, -3.0494e-02, -1.8306e-02, -3.1376e-02,\n",
       "                        3.0427e-02, -1.9436e-02,  6.8909e-03,  1.0162e-02,  4.8440e-02,\n",
       "                       -4.1084e-02, -4.1402e-02, -5.0625e-02, -4.3898e-02,  1.5678e-02,\n",
       "                        2.3060e-02,  3.6118e-02, -5.5980e-02, -3.3094e-02,  3.2711e-02,\n",
       "                       -5.9067e-02,  1.1746e-02, -6.3830e-03, -4.4730e-03, -8.1227e-03,\n",
       "                       -4.7038e-02,  3.0085e-02,  4.5849e-02,  3.8183e-02,  7.1345e-03,\n",
       "                        2.7041e-02, -2.7736e-02,  4.1459e-02, -4.5265e-02, -4.5624e-02,\n",
       "                        2.4131e-02]])),\n",
       "             ('output_layer.bias', tensor([ 0.0135, -0.0164,  0.0151]))])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_state_dict(model, pretrained_path):\n",
    "    pretrained_dict = torch.load(pretrained_path)\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"output_layer\" not in k}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('project_inp.weight',\n",
       "              tensor([[ 0.1815, -0.1073,  0.0854,  ..., -0.1529, -0.1937, -0.0024],\n",
       "                      [-0.1686, -0.2337,  0.2132,  ..., -0.1468,  0.0405, -0.0729],\n",
       "                      [ 0.3325,  0.1289,  0.2366,  ..., -0.2703,  0.0776,  0.2900],\n",
       "                      ...,\n",
       "                      [ 0.1362,  0.0593, -0.1576,  ..., -0.1716, -0.1800, -0.2180],\n",
       "                      [ 0.0184, -0.1768,  0.2571,  ..., -0.2737,  0.1111,  0.1320],\n",
       "                      [ 0.2260, -0.1276,  0.2376,  ..., -0.0249,  0.2203,  0.1971]])),\n",
       "             ('project_inp.bias',\n",
       "              tensor([-0.2726, -0.3189,  0.3102, -0.0716, -0.2488,  0.0096,  0.2774,  0.1458,\n",
       "                       0.3149, -0.0868,  0.0448,  0.0731, -0.1720, -0.3274, -0.1242,  0.1232,\n",
       "                      -0.1573,  0.0968, -0.1163, -0.1399, -0.1870, -0.1516, -0.3049,  0.3137,\n",
       "                       0.3029,  0.0676, -0.2516,  0.3013, -0.2154, -0.2729, -0.1616, -0.2224,\n",
       "                       0.1113, -0.0196, -0.3153, -0.1557,  0.0314, -0.0613,  0.1982,  0.3054,\n",
       "                      -0.2027, -0.0206, -0.2640,  0.0406,  0.2045,  0.3240,  0.0153, -0.0214,\n",
       "                      -0.0990, -0.0974, -0.0949,  0.1387,  0.1308,  0.2583,  0.0930,  0.1955,\n",
       "                      -0.3179,  0.1319, -0.3107, -0.1618,  0.1485,  0.0849, -0.0128,  0.1696,\n",
       "                       0.0319, -0.2105, -0.0799, -0.1970, -0.0688, -0.1922,  0.1027,  0.1830,\n",
       "                       0.2628, -0.0479,  0.0265,  0.1790,  0.0356, -0.0251,  0.3114,  0.2510,\n",
       "                      -0.1460,  0.1425,  0.1307,  0.0225,  0.1684, -0.0305, -0.1771, -0.2466,\n",
       "                       0.0813, -0.2566, -0.2187, -0.0118,  0.0564, -0.3300, -0.2861,  0.2893,\n",
       "                       0.3126, -0.2909, -0.0056,  0.1015, -0.2330, -0.0772,  0.1069, -0.0140,\n",
       "                      -0.3301, -0.3046, -0.1947, -0.0331, -0.3108, -0.1190,  0.1239,  0.3176,\n",
       "                       0.1277,  0.1754, -0.0023,  0.0510, -0.0294, -0.2265,  0.1877,  0.0374,\n",
       "                      -0.1424,  0.2841, -0.0060,  0.2745, -0.2917, -0.2735, -0.1383,  0.2187,\n",
       "                       0.2678,  0.0562,  0.2403, -0.0346,  0.2568, -0.0066,  0.1947,  0.0757,\n",
       "                      -0.0093,  0.3210, -0.3188, -0.1598, -0.0440,  0.1966,  0.1814, -0.0049,\n",
       "                      -0.0523,  0.1022, -0.1877, -0.1900, -0.2906, -0.3201, -0.1558, -0.0622,\n",
       "                       0.0118,  0.1659, -0.1585, -0.2855,  0.2404, -0.2525,  0.2814,  0.0621,\n",
       "                      -0.1027,  0.2893, -0.2069, -0.2124,  0.0754,  0.0450, -0.2094, -0.2111,\n",
       "                      -0.0707,  0.1775, -0.1974,  0.0350,  0.3063, -0.1813, -0.1914, -0.2919,\n",
       "                      -0.3038, -0.1050,  0.1970,  0.1501, -0.0519, -0.3287,  0.2908, -0.2048,\n",
       "                       0.2490,  0.1876,  0.1217, -0.2397, -0.1125, -0.0092,  0.0084, -0.2409,\n",
       "                       0.0632,  0.0300,  0.2330,  0.2422, -0.3166,  0.3261,  0.1911, -0.0272,\n",
       "                      -0.1028,  0.2211,  0.2883,  0.3180, -0.2969, -0.2454,  0.2439,  0.1591,\n",
       "                       0.3097, -0.3071,  0.2416,  0.1179, -0.2583,  0.2270, -0.1561, -0.1447,\n",
       "                      -0.0070,  0.0851, -0.2679, -0.3055,  0.2314,  0.0029, -0.0940,  0.0175,\n",
       "                       0.2927, -0.1909,  0.3331, -0.0679,  0.1668,  0.0848,  0.0028,  0.1891,\n",
       "                      -0.0470,  0.0732,  0.1027, -0.0164, -0.2762,  0.0082, -0.2255, -0.2260,\n",
       "                      -0.1172,  0.0411, -0.2557, -0.2317, -0.3132, -0.1128, -0.2818,  0.2465,\n",
       "                      -0.0578,  0.2168, -0.0908, -0.0475, -0.2072,  0.1054,  0.0673,  0.2943])),\n",
       "             ('pos_enc.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  8.0196e-01,  ...,  1.0000e+00,\n",
       "                         1.0746e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.5814e-01,  ...,  1.0000e+00,\n",
       "                         2.1492e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 9.9482e-01, -1.0162e-01,  1.8368e-01,  ...,  9.9957e-01,\n",
       "                         2.7184e-02,  9.9963e-01]],\n",
       "              \n",
       "                      [[ 4.5200e-01, -8.9202e-01, -6.7859e-01,  ...,  9.9957e-01,\n",
       "                         2.7292e-02,  9.9963e-01]],\n",
       "              \n",
       "                      [[-5.0639e-01, -8.6230e-01, -9.9443e-01,  ...,  9.9957e-01,\n",
       "                         2.7399e-02,  9.9962e-01]]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[-0.0643, -0.0276, -0.0595,  ...,  0.0731, -0.0242,  0.0119],\n",
       "                      [ 0.0277, -0.0221, -0.0551,  ...,  0.0554, -0.0635,  0.0429],\n",
       "                      [ 0.0168,  0.0614, -0.0210,  ..., -0.0225,  0.0143, -0.0459],\n",
       "                      ...,\n",
       "                      [ 0.0286,  0.0429, -0.0390,  ..., -0.0174,  0.0306, -0.0509],\n",
       "                      [-0.0076, -0.0025, -0.0651,  ..., -0.0464,  0.0678,  0.0715],\n",
       "                      [-0.0406, -0.0277,  0.0219,  ..., -0.0257,  0.0024, -0.0729]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0214,  0.0569, -0.0060,  ...,  0.0077,  0.0166, -0.0269],\n",
       "                      [-0.0080,  0.0338, -0.0618,  ..., -0.0274,  0.0160,  0.0475],\n",
       "                      [ 0.0051,  0.0237, -0.0268,  ..., -0.0561, -0.0248,  0.0239],\n",
       "                      ...,\n",
       "                      [-0.0186,  0.0534,  0.0506,  ..., -0.0389,  0.0208, -0.0399],\n",
       "                      [-0.0575, -0.0364, -0.0434,  ..., -0.0431, -0.0123,  0.0082],\n",
       "                      [-0.0208,  0.0456,  0.0318,  ..., -0.0536,  0.0361,  0.0346]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.linear1.weight',\n",
       "              tensor([[-0.0609, -0.0208,  0.0555,  ..., -0.0060,  0.0151,  0.0013],\n",
       "                      [ 0.0506,  0.0276, -0.0204,  ...,  0.0048, -0.0030,  0.0299],\n",
       "                      [-0.0493, -0.0339,  0.0586,  ..., -0.0347,  0.0182, -0.0043],\n",
       "                      ...,\n",
       "                      [ 0.0558, -0.0460,  0.0092,  ..., -0.0090, -0.0385,  0.0547],\n",
       "                      [ 0.0315,  0.0346,  0.0377,  ...,  0.0174, -0.0304, -0.0128],\n",
       "                      [-0.0591, -0.0620,  0.0537,  ...,  0.0068,  0.0062,  0.0453]])),\n",
       "             ('transformer_encoder.layers.0.linear1.bias',\n",
       "              tensor([ 1.3475e-02,  4.6143e-02,  3.8564e-02, -5.2027e-03,  1.2239e-02,\n",
       "                       3.4483e-02, -1.0264e-02,  5.6808e-02, -4.1868e-02,  4.2097e-02,\n",
       "                      -3.5464e-02, -1.9108e-02, -2.3645e-02, -1.7866e-02,  3.5044e-02,\n",
       "                      -3.4195e-02,  4.1754e-02,  4.8351e-02,  6.9679e-03, -1.7341e-02,\n",
       "                      -9.6232e-03,  6.0808e-02,  1.9130e-02, -2.2069e-02, -7.4465e-03,\n",
       "                       3.5317e-02, -6.1191e-02, -3.9264e-03, -3.3832e-02, -2.6059e-02,\n",
       "                      -5.3052e-02, -4.0550e-02,  2.3351e-02, -1.1035e-03,  5.6024e-02,\n",
       "                       3.5880e-02,  8.5475e-03, -1.8777e-02, -4.1990e-02, -3.6049e-02,\n",
       "                       1.6289e-02, -8.5052e-03, -5.2961e-02,  1.0763e-02, -4.4186e-02,\n",
       "                      -5.8899e-02,  3.3914e-02,  5.7897e-02,  4.5507e-02, -1.2808e-02,\n",
       "                      -1.4992e-02,  5.0711e-02,  2.2601e-02, -4.1397e-02,  2.0754e-02,\n",
       "                       3.0033e-02,  4.3835e-02,  3.6485e-02, -5.6046e-02,  1.0335e-02,\n",
       "                      -5.0716e-02, -6.1530e-02,  5.0175e-02,  6.0741e-02,  1.5340e-02,\n",
       "                       1.9711e-02,  4.4258e-02, -2.5545e-02, -1.9775e-02, -1.2303e-03,\n",
       "                      -2.8669e-02,  8.9025e-03,  5.3787e-02, -4.3480e-02, -2.0834e-02,\n",
       "                      -4.9502e-03, -6.2638e-03, -4.6733e-02,  1.1706e-02, -1.8855e-02,\n",
       "                      -4.2745e-02,  5.8079e-02, -3.6405e-03,  5.6694e-02, -5.6389e-02,\n",
       "                      -4.7500e-02,  5.6274e-02,  2.3766e-02, -4.2603e-02, -5.6255e-02,\n",
       "                      -2.8441e-02,  4.6402e-02,  1.5506e-02,  3.3005e-02, -5.2568e-02,\n",
       "                       5.1709e-02,  9.6064e-03,  6.2452e-02, -4.8954e-02,  3.0755e-02,\n",
       "                       5.9577e-02,  3.1939e-02,  5.4467e-02, -5.2538e-02, -7.3504e-03,\n",
       "                      -4.4722e-02, -5.4724e-02, -1.0570e-02, -4.5748e-02, -2.7889e-02,\n",
       "                       2.6379e-02,  4.5236e-02,  3.0738e-02,  4.2280e-02, -2.9940e-02,\n",
       "                      -1.9995e-02, -1.7719e-02, -5.2310e-03, -1.0593e-02,  1.6376e-02,\n",
       "                       4.7628e-02,  4.1754e-02,  2.5696e-02, -3.1854e-02,  1.9078e-03,\n",
       "                      -1.8738e-02,  5.6128e-02,  4.3188e-02,  5.4035e-02, -5.7846e-02,\n",
       "                      -3.0774e-02,  4.3899e-02,  2.8966e-04, -1.9796e-02,  2.9189e-02,\n",
       "                      -9.4562e-03,  5.5769e-02, -4.6942e-02, -7.0556e-03, -2.3244e-03,\n",
       "                      -1.0361e-02,  2.4572e-02, -1.5109e-03, -5.4134e-02,  3.2441e-03,\n",
       "                      -8.3535e-03, -1.0071e-02, -1.5050e-02,  3.3209e-02,  3.4609e-02,\n",
       "                       8.3696e-03, -2.8629e-02, -5.9006e-02, -1.7901e-02, -2.0801e-02,\n",
       "                       9.0077e-03, -5.6043e-02,  3.1914e-02,  3.0524e-02, -3.5007e-02,\n",
       "                       2.2997e-02, -5.2491e-02,  5.0775e-02, -1.4250e-02, -4.5633e-02,\n",
       "                       4.4430e-02,  1.6128e-02, -3.4411e-02, -1.3960e-02,  4.1266e-02,\n",
       "                      -6.0748e-02, -5.8572e-02,  3.8092e-02, -5.3636e-02, -3.6449e-02,\n",
       "                      -3.8599e-02,  5.6054e-02,  1.9498e-02, -1.6944e-02, -4.4679e-03,\n",
       "                      -5.6575e-02, -5.4920e-02,  2.3479e-02,  1.3460e-02,  4.7699e-03,\n",
       "                       2.9977e-02,  8.1818e-03,  2.7769e-02,  3.5613e-02, -3.9432e-02,\n",
       "                      -3.4089e-02,  2.7908e-02, -4.2415e-02, -5.2234e-02,  5.9251e-02,\n",
       "                       2.8850e-02, -3.9591e-02,  3.5477e-02,  6.0284e-02,  4.9231e-02,\n",
       "                      -4.0320e-02,  5.5642e-02, -4.1359e-02,  5.3283e-02, -3.2346e-02,\n",
       "                      -2.5523e-02,  3.4977e-02, -1.2037e-02, -4.4542e-02, -1.8543e-02,\n",
       "                      -2.7395e-02, -5.5975e-02, -6.8201e-03,  2.0810e-02, -2.9872e-02,\n",
       "                       1.4809e-02,  5.0360e-02, -1.0939e-02,  8.3209e-03, -3.1158e-02,\n",
       "                      -5.8162e-02,  4.2691e-02, -4.4397e-02, -2.1052e-03, -4.0426e-02,\n",
       "                      -3.6668e-02,  2.3674e-02, -1.1312e-02, -4.2474e-02,  5.1561e-02,\n",
       "                       1.2944e-02,  8.1561e-03, -3.3924e-02,  3.3443e-02,  7.3318e-03,\n",
       "                      -1.6678e-04,  1.5188e-02, -2.2449e-02, -2.7946e-03, -2.3235e-02,\n",
       "                       3.8829e-02, -2.9214e-02, -5.6042e-02, -5.5134e-02,  2.9674e-02,\n",
       "                       7.4345e-03, -2.2872e-03,  1.5745e-02,  2.0475e-03, -3.8547e-02,\n",
       "                       1.0186e-02, -5.6371e-02,  4.2470e-02, -1.4935e-02,  4.8705e-02,\n",
       "                      -6.0842e-02,  5.8183e-02,  4.2989e-02,  5.6290e-02,  9.4395e-03,\n",
       "                      -5.0268e-02,  2.2715e-03,  5.4448e-02,  4.5294e-03, -1.4218e-02,\n",
       "                      -4.1597e-02,  2.6691e-02, -2.9737e-03,  5.6912e-02, -1.5420e-02,\n",
       "                      -4.3281e-02,  6.6386e-03,  1.9545e-02, -7.3209e-03, -5.5072e-02,\n",
       "                       3.0271e-02, -4.6137e-02,  4.1400e-02, -1.6804e-02,  5.2175e-02,\n",
       "                       3.4671e-02,  2.1362e-03,  8.4171e-03, -2.1457e-02,  1.2540e-02,\n",
       "                      -7.3284e-03,  4.3934e-02,  5.3064e-02, -4.1908e-03,  3.5281e-02,\n",
       "                       5.6875e-02, -3.3648e-02, -9.0579e-03,  3.0650e-02,  5.5425e-05,\n",
       "                      -4.8742e-02,  6.1612e-02,  1.0756e-02, -5.0162e-02, -2.4460e-02,\n",
       "                      -4.0150e-02, -3.4435e-02, -1.5359e-02,  2.7559e-02, -3.0059e-02,\n",
       "                      -2.1002e-02,  3.4765e-02,  4.6935e-02,  2.7182e-02,  1.3217e-02,\n",
       "                       2.9987e-02,  3.4687e-02,  3.1319e-04, -4.3851e-02, -3.9346e-02,\n",
       "                       3.3970e-02, -2.1995e-02,  5.0626e-02,  1.2519e-02,  5.9215e-02,\n",
       "                       3.0338e-03, -3.8672e-03,  2.7634e-02,  4.0447e-02, -3.5210e-02,\n",
       "                       4.0141e-02, -5.9698e-02,  1.8742e-02, -7.9632e-03, -2.6730e-02,\n",
       "                       2.4952e-02, -4.3069e-02, -5.2615e-02, -7.4399e-03,  2.4076e-02,\n",
       "                      -3.4103e-02, -3.0505e-02, -3.6860e-02,  4.8020e-02,  3.9899e-02,\n",
       "                      -1.4090e-03, -5.1261e-02, -5.6159e-02,  5.3996e-02, -4.0178e-03,\n",
       "                       9.2443e-04, -3.2078e-02, -2.3836e-02, -5.4957e-02, -2.6829e-03,\n",
       "                      -2.7171e-02,  3.8816e-02,  1.3413e-02,  5.7393e-02, -8.7394e-03,\n",
       "                       2.2965e-03,  4.3714e-02,  3.5893e-02,  2.2334e-02,  3.0015e-02,\n",
       "                       2.0240e-02,  3.2463e-03, -2.0451e-02,  2.9513e-02,  6.2353e-02,\n",
       "                       1.1562e-02,  6.1806e-02, -6.2268e-02,  4.7784e-03, -1.7607e-02,\n",
       "                       4.5641e-02, -5.0422e-02, -5.3644e-02, -3.9180e-02,  3.8410e-02,\n",
       "                      -4.5801e-02, -3.1388e-03,  2.6146e-02, -1.2784e-02,  4.5335e-02,\n",
       "                       6.0592e-02, -5.5223e-02, -6.2048e-02,  4.7282e-02, -5.2201e-02,\n",
       "                      -5.8007e-02, -2.2956e-02, -1.3457e-02, -5.7033e-02,  3.4879e-02,\n",
       "                      -3.8151e-02, -5.2198e-02,  2.1081e-02, -5.8787e-02, -1.9119e-02,\n",
       "                      -1.8824e-02, -3.2405e-02, -6.0056e-02, -1.8536e-02, -3.1270e-02,\n",
       "                      -5.2891e-02, -3.9244e-02,  4.3342e-02,  3.3070e-02,  1.9584e-02,\n",
       "                      -2.4815e-02, -4.2889e-02,  1.5648e-02,  4.2121e-02,  1.2470e-02,\n",
       "                       3.1043e-02, -2.3098e-03,  4.2013e-02,  2.6619e-03,  5.1072e-02,\n",
       "                      -2.8400e-02,  1.9558e-02,  1.1947e-02,  1.5435e-04, -3.3542e-02,\n",
       "                      -2.1406e-02, -1.1249e-02,  3.8169e-02,  1.9653e-02,  4.4414e-02,\n",
       "                       3.1268e-02, -6.0540e-02, -5.5962e-02, -4.1404e-02, -5.9383e-02,\n",
       "                      -6.0592e-02,  4.7557e-02,  2.7231e-02, -5.1702e-02, -3.6556e-03,\n",
       "                      -1.2016e-03,  3.8049e-02,  2.1180e-02,  4.0787e-02, -5.8666e-02,\n",
       "                      -1.7037e-02,  1.8560e-02,  9.0474e-03,  1.0224e-02,  3.0438e-02,\n",
       "                       2.9334e-02, -2.7065e-02, -7.8777e-03,  1.1993e-02, -3.6877e-02,\n",
       "                       7.5056e-03, -5.2920e-02,  5.5724e-02,  2.8235e-02,  3.8645e-02,\n",
       "                       7.7561e-06, -1.8805e-02, -3.6190e-04, -4.6011e-03,  4.4818e-02,\n",
       "                       1.1712e-02, -5.1497e-03,  5.8673e-02,  4.1642e-02, -2.3911e-02,\n",
       "                       2.0094e-02, -5.5850e-02, -2.7427e-02,  3.8673e-02,  4.0089e-02,\n",
       "                      -6.4982e-03, -4.0477e-02, -1.9451e-02, -2.1421e-02, -1.0342e-02,\n",
       "                      -6.2341e-02,  4.3183e-02, -4.9764e-02,  4.8952e-03, -2.7630e-02,\n",
       "                      -2.5714e-02, -4.1639e-02, -1.9898e-02, -1.2352e-02,  5.0018e-02,\n",
       "                      -5.6373e-02,  5.6859e-02, -4.7243e-02, -1.7061e-02, -1.8091e-02,\n",
       "                       5.0463e-02, -4.0181e-02, -6.1104e-02, -4.7776e-02, -3.2348e-02,\n",
       "                       2.5766e-02,  2.7101e-03,  1.5793e-02, -1.8171e-02,  1.2195e-02,\n",
       "                       1.4928e-02,  3.3372e-02, -4.3934e-02, -3.7579e-02, -1.8143e-02,\n",
       "                       7.6432e-03, -9.1633e-03, -3.0971e-02,  2.6635e-02, -3.8295e-02,\n",
       "                      -5.5497e-02, -2.8273e-02])),\n",
       "             ('transformer_encoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.0248, -0.0025, -0.0097,  ..., -0.0215,  0.0388,  0.0032],\n",
       "                      [-0.0152,  0.0005,  0.0111,  ...,  0.0283,  0.0013, -0.0290],\n",
       "                      [ 0.0272, -0.0219,  0.0188,  ...,  0.0328,  0.0316,  0.0263],\n",
       "                      ...,\n",
       "                      [ 0.0342,  0.0181, -0.0238,  ...,  0.0218, -0.0220, -0.0049],\n",
       "                      [-0.0067,  0.0306, -0.0221,  ...,  0.0419,  0.0326,  0.0288],\n",
       "                      [-0.0239, -0.0256, -0.0328,  ...,  0.0159, -0.0229,  0.0298]])),\n",
       "             ('transformer_encoder.layers.0.linear2.bias',\n",
       "              tensor([-2.0566e-02, -2.2342e-02,  2.4541e-02, -2.4624e-02,  1.2683e-02,\n",
       "                       2.8690e-02,  4.2860e-02,  1.4415e-02,  2.1064e-02, -3.5754e-02,\n",
       "                      -2.8181e-02, -1.7319e-03, -8.5008e-03,  1.3609e-02, -3.4047e-02,\n",
       "                       3.3204e-02,  4.0286e-03, -3.8060e-02,  7.1814e-03, -1.1991e-02,\n",
       "                       4.1266e-02, -4.3798e-02,  3.6786e-03,  6.6793e-03, -2.4385e-02,\n",
       "                      -1.1857e-02, -1.1260e-02,  3.6932e-02,  2.6174e-02, -5.7929e-03,\n",
       "                      -4.0542e-02,  1.8132e-02,  1.4143e-03,  3.3811e-02, -6.1371e-03,\n",
       "                      -2.1685e-02,  5.6018e-03,  3.7771e-02,  1.8943e-02, -1.4011e-03,\n",
       "                       8.2846e-04, -5.0861e-03,  4.6756e-03, -3.8173e-02, -3.4029e-02,\n",
       "                      -1.0256e-02, -3.9678e-02,  1.1068e-02,  1.0516e-02,  3.8096e-02,\n",
       "                      -9.1763e-03,  3.4507e-02, -4.3812e-02, -4.3642e-03,  8.4555e-03,\n",
       "                       8.4926e-03,  3.3751e-02, -4.3581e-02, -2.4976e-02, -1.4541e-02,\n",
       "                       2.9815e-03, -3.3334e-02, -1.9061e-02,  2.2371e-02, -7.8736e-03,\n",
       "                       2.4818e-02, -3.1261e-02, -6.4667e-05, -3.7674e-02, -2.6778e-02,\n",
       "                       3.9688e-02,  3.4271e-02,  1.8167e-02,  2.5896e-04, -1.1652e-03,\n",
       "                       2.4575e-02, -3.7681e-02,  2.9240e-02, -3.6221e-02, -3.8540e-02,\n",
       "                       1.4578e-02, -7.8173e-03, -4.3229e-02, -3.7837e-02, -4.2517e-02,\n",
       "                      -5.2995e-03, -4.2013e-02, -3.7633e-02,  4.0928e-02,  1.8042e-02,\n",
       "                       1.3799e-03,  3.7498e-03,  3.7805e-03,  1.0085e-02, -4.2222e-02,\n",
       "                       1.3210e-02,  4.2748e-02, -5.9078e-03, -1.3789e-02,  4.2566e-02,\n",
       "                       2.0395e-02, -4.0609e-02, -4.3547e-02,  2.9658e-02, -1.7812e-02,\n",
       "                      -2.7653e-02, -1.6497e-02,  1.8577e-02, -2.2629e-03,  3.2640e-02,\n",
       "                       2.3112e-02,  1.6732e-02,  2.5519e-02,  2.5951e-02,  4.0509e-02,\n",
       "                       3.5295e-02,  2.2666e-03,  1.4827e-02, -3.9675e-02,  8.7583e-03,\n",
       "                      -3.3350e-02,  3.0855e-02, -1.3813e-02,  1.2049e-02,  7.0156e-03,\n",
       "                      -4.3516e-02,  1.3382e-02,  4.4452e-03,  3.4029e-02, -3.3273e-02,\n",
       "                       5.4232e-03, -1.6716e-02,  3.1401e-02,  4.3424e-02, -3.8336e-02,\n",
       "                      -2.6952e-02,  3.3533e-02,  3.7752e-02, -3.7178e-02,  4.3455e-02,\n",
       "                      -3.1173e-02,  9.9225e-03,  2.9546e-02, -1.5212e-02,  7.6285e-03,\n",
       "                       4.0701e-02,  3.4672e-02, -7.1755e-03, -3.0467e-02,  4.0098e-02,\n",
       "                      -4.2583e-02, -8.7643e-04,  3.0171e-02, -3.0880e-02, -4.2340e-02,\n",
       "                       3.4856e-02,  3.2950e-02,  2.6072e-02,  3.0105e-02, -3.4389e-02,\n",
       "                      -2.0039e-02,  1.5254e-02,  1.6630e-02,  1.7741e-02,  4.0824e-02,\n",
       "                       4.3222e-02, -6.9815e-03,  1.5749e-02, -1.7761e-02, -3.9090e-02,\n",
       "                      -4.0810e-02,  4.1009e-02, -2.2411e-02, -3.0648e-02, -2.6068e-02,\n",
       "                      -1.1641e-02,  3.9737e-02, -7.3692e-03, -2.3563e-02,  3.0582e-02,\n",
       "                      -3.5202e-02, -1.7879e-02, -1.3243e-02,  4.3509e-03,  3.2942e-02,\n",
       "                       5.8802e-03,  3.9488e-02,  3.3534e-02, -1.4965e-02,  2.8795e-02,\n",
       "                      -4.0389e-02, -3.4630e-03, -3.0528e-03, -1.0381e-02,  2.3883e-03,\n",
       "                       3.8778e-02,  3.5532e-02,  1.3535e-02,  3.7447e-02,  2.3958e-02,\n",
       "                       2.6858e-02, -2.8004e-02, -2.2561e-02, -2.1148e-02, -1.0908e-02,\n",
       "                      -2.4070e-02,  1.6248e-02, -4.0876e-02, -4.1417e-02, -2.2074e-02,\n",
       "                       1.2307e-02,  1.7956e-02, -3.9214e-02, -3.5519e-02, -2.7809e-02,\n",
       "                       1.5829e-02, -2.5140e-02,  2.9682e-02, -1.1088e-02, -3.2513e-02,\n",
       "                       2.8429e-02,  3.2992e-02, -3.9655e-02,  3.1016e-02,  3.2418e-02,\n",
       "                      -1.4125e-02,  1.4869e-02,  3.9971e-02,  1.6105e-02,  3.7250e-03,\n",
       "                       2.4235e-02,  2.3781e-02, -3.6940e-02, -1.8513e-03,  6.1039e-03,\n",
       "                      -4.2269e-02, -2.8811e-02, -1.8716e-02, -3.2051e-02, -2.0701e-02,\n",
       "                       1.3789e-02,  2.3315e-02, -4.0171e-02,  1.3528e-02,  3.0489e-02,\n",
       "                      -2.3603e-02, -1.3383e-02,  1.7639e-02,  1.6702e-02,  2.9860e-02,\n",
       "                       1.5812e-02,  1.2336e-02, -1.6027e-02, -2.7475e-02,  1.2227e-02,\n",
       "                      -2.2609e-02])),\n",
       "             ('transformer_encoder.layers.0.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.0.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[-0.0643, -0.0276, -0.0595,  ...,  0.0731, -0.0242,  0.0119],\n",
       "                      [ 0.0277, -0.0221, -0.0551,  ...,  0.0554, -0.0635,  0.0429],\n",
       "                      [ 0.0168,  0.0614, -0.0210,  ..., -0.0225,  0.0143, -0.0459],\n",
       "                      ...,\n",
       "                      [ 0.0286,  0.0429, -0.0390,  ..., -0.0174,  0.0306, -0.0509],\n",
       "                      [-0.0076, -0.0025, -0.0651,  ..., -0.0464,  0.0678,  0.0715],\n",
       "                      [-0.0406, -0.0277,  0.0219,  ..., -0.0257,  0.0024, -0.0729]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0214,  0.0569, -0.0060,  ...,  0.0077,  0.0166, -0.0269],\n",
       "                      [-0.0080,  0.0338, -0.0618,  ..., -0.0274,  0.0160,  0.0475],\n",
       "                      [ 0.0051,  0.0237, -0.0268,  ..., -0.0561, -0.0248,  0.0239],\n",
       "                      ...,\n",
       "                      [-0.0186,  0.0534,  0.0506,  ..., -0.0389,  0.0208, -0.0399],\n",
       "                      [-0.0575, -0.0364, -0.0434,  ..., -0.0431, -0.0123,  0.0082],\n",
       "                      [-0.0208,  0.0456,  0.0318,  ..., -0.0536,  0.0361,  0.0346]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.linear1.weight',\n",
       "              tensor([[-0.0609, -0.0208,  0.0555,  ..., -0.0060,  0.0151,  0.0013],\n",
       "                      [ 0.0506,  0.0276, -0.0204,  ...,  0.0048, -0.0030,  0.0299],\n",
       "                      [-0.0493, -0.0339,  0.0586,  ..., -0.0347,  0.0182, -0.0043],\n",
       "                      ...,\n",
       "                      [ 0.0558, -0.0460,  0.0092,  ..., -0.0090, -0.0385,  0.0547],\n",
       "                      [ 0.0315,  0.0346,  0.0377,  ...,  0.0174, -0.0304, -0.0128],\n",
       "                      [-0.0591, -0.0620,  0.0537,  ...,  0.0068,  0.0062,  0.0453]])),\n",
       "             ('transformer_encoder.layers.1.linear1.bias',\n",
       "              tensor([ 1.3475e-02,  4.6143e-02,  3.8564e-02, -5.2027e-03,  1.2239e-02,\n",
       "                       3.4483e-02, -1.0264e-02,  5.6808e-02, -4.1868e-02,  4.2097e-02,\n",
       "                      -3.5464e-02, -1.9108e-02, -2.3645e-02, -1.7866e-02,  3.5044e-02,\n",
       "                      -3.4195e-02,  4.1754e-02,  4.8351e-02,  6.9679e-03, -1.7341e-02,\n",
       "                      -9.6232e-03,  6.0808e-02,  1.9130e-02, -2.2069e-02, -7.4465e-03,\n",
       "                       3.5317e-02, -6.1191e-02, -3.9264e-03, -3.3832e-02, -2.6059e-02,\n",
       "                      -5.3052e-02, -4.0550e-02,  2.3351e-02, -1.1035e-03,  5.6024e-02,\n",
       "                       3.5880e-02,  8.5475e-03, -1.8777e-02, -4.1990e-02, -3.6049e-02,\n",
       "                       1.6289e-02, -8.5052e-03, -5.2961e-02,  1.0763e-02, -4.4186e-02,\n",
       "                      -5.8899e-02,  3.3914e-02,  5.7897e-02,  4.5507e-02, -1.2808e-02,\n",
       "                      -1.4992e-02,  5.0711e-02,  2.2601e-02, -4.1397e-02,  2.0754e-02,\n",
       "                       3.0033e-02,  4.3835e-02,  3.6485e-02, -5.6046e-02,  1.0335e-02,\n",
       "                      -5.0716e-02, -6.1530e-02,  5.0175e-02,  6.0741e-02,  1.5340e-02,\n",
       "                       1.9711e-02,  4.4258e-02, -2.5545e-02, -1.9775e-02, -1.2303e-03,\n",
       "                      -2.8669e-02,  8.9025e-03,  5.3787e-02, -4.3480e-02, -2.0834e-02,\n",
       "                      -4.9502e-03, -6.2638e-03, -4.6733e-02,  1.1706e-02, -1.8855e-02,\n",
       "                      -4.2745e-02,  5.8079e-02, -3.6405e-03,  5.6694e-02, -5.6389e-02,\n",
       "                      -4.7500e-02,  5.6274e-02,  2.3766e-02, -4.2603e-02, -5.6255e-02,\n",
       "                      -2.8441e-02,  4.6402e-02,  1.5506e-02,  3.3005e-02, -5.2568e-02,\n",
       "                       5.1709e-02,  9.6064e-03,  6.2452e-02, -4.8954e-02,  3.0755e-02,\n",
       "                       5.9577e-02,  3.1939e-02,  5.4467e-02, -5.2538e-02, -7.3504e-03,\n",
       "                      -4.4722e-02, -5.4724e-02, -1.0570e-02, -4.5748e-02, -2.7889e-02,\n",
       "                       2.6379e-02,  4.5236e-02,  3.0738e-02,  4.2280e-02, -2.9940e-02,\n",
       "                      -1.9995e-02, -1.7719e-02, -5.2310e-03, -1.0593e-02,  1.6376e-02,\n",
       "                       4.7628e-02,  4.1754e-02,  2.5696e-02, -3.1854e-02,  1.9078e-03,\n",
       "                      -1.8738e-02,  5.6128e-02,  4.3188e-02,  5.4035e-02, -5.7846e-02,\n",
       "                      -3.0774e-02,  4.3899e-02,  2.8966e-04, -1.9796e-02,  2.9189e-02,\n",
       "                      -9.4562e-03,  5.5769e-02, -4.6942e-02, -7.0556e-03, -2.3244e-03,\n",
       "                      -1.0361e-02,  2.4572e-02, -1.5109e-03, -5.4134e-02,  3.2441e-03,\n",
       "                      -8.3535e-03, -1.0071e-02, -1.5050e-02,  3.3209e-02,  3.4609e-02,\n",
       "                       8.3696e-03, -2.8629e-02, -5.9006e-02, -1.7901e-02, -2.0801e-02,\n",
       "                       9.0077e-03, -5.6043e-02,  3.1914e-02,  3.0524e-02, -3.5007e-02,\n",
       "                       2.2997e-02, -5.2491e-02,  5.0775e-02, -1.4250e-02, -4.5633e-02,\n",
       "                       4.4430e-02,  1.6128e-02, -3.4411e-02, -1.3960e-02,  4.1266e-02,\n",
       "                      -6.0748e-02, -5.8572e-02,  3.8092e-02, -5.3636e-02, -3.6449e-02,\n",
       "                      -3.8599e-02,  5.6054e-02,  1.9498e-02, -1.6944e-02, -4.4679e-03,\n",
       "                      -5.6575e-02, -5.4920e-02,  2.3479e-02,  1.3460e-02,  4.7699e-03,\n",
       "                       2.9977e-02,  8.1818e-03,  2.7769e-02,  3.5613e-02, -3.9432e-02,\n",
       "                      -3.4089e-02,  2.7908e-02, -4.2415e-02, -5.2234e-02,  5.9251e-02,\n",
       "                       2.8850e-02, -3.9591e-02,  3.5477e-02,  6.0284e-02,  4.9231e-02,\n",
       "                      -4.0320e-02,  5.5642e-02, -4.1359e-02,  5.3283e-02, -3.2346e-02,\n",
       "                      -2.5523e-02,  3.4977e-02, -1.2037e-02, -4.4542e-02, -1.8543e-02,\n",
       "                      -2.7395e-02, -5.5975e-02, -6.8201e-03,  2.0810e-02, -2.9872e-02,\n",
       "                       1.4809e-02,  5.0360e-02, -1.0939e-02,  8.3209e-03, -3.1158e-02,\n",
       "                      -5.8162e-02,  4.2691e-02, -4.4397e-02, -2.1052e-03, -4.0426e-02,\n",
       "                      -3.6668e-02,  2.3674e-02, -1.1312e-02, -4.2474e-02,  5.1561e-02,\n",
       "                       1.2944e-02,  8.1561e-03, -3.3924e-02,  3.3443e-02,  7.3318e-03,\n",
       "                      -1.6678e-04,  1.5188e-02, -2.2449e-02, -2.7946e-03, -2.3235e-02,\n",
       "                       3.8829e-02, -2.9214e-02, -5.6042e-02, -5.5134e-02,  2.9674e-02,\n",
       "                       7.4345e-03, -2.2872e-03,  1.5745e-02,  2.0475e-03, -3.8547e-02,\n",
       "                       1.0186e-02, -5.6371e-02,  4.2470e-02, -1.4935e-02,  4.8705e-02,\n",
       "                      -6.0842e-02,  5.8183e-02,  4.2989e-02,  5.6290e-02,  9.4395e-03,\n",
       "                      -5.0268e-02,  2.2715e-03,  5.4448e-02,  4.5294e-03, -1.4218e-02,\n",
       "                      -4.1597e-02,  2.6691e-02, -2.9737e-03,  5.6912e-02, -1.5420e-02,\n",
       "                      -4.3281e-02,  6.6386e-03,  1.9545e-02, -7.3209e-03, -5.5072e-02,\n",
       "                       3.0271e-02, -4.6137e-02,  4.1400e-02, -1.6804e-02,  5.2175e-02,\n",
       "                       3.4671e-02,  2.1362e-03,  8.4171e-03, -2.1457e-02,  1.2540e-02,\n",
       "                      -7.3284e-03,  4.3934e-02,  5.3064e-02, -4.1908e-03,  3.5281e-02,\n",
       "                       5.6875e-02, -3.3648e-02, -9.0579e-03,  3.0650e-02,  5.5425e-05,\n",
       "                      -4.8742e-02,  6.1612e-02,  1.0756e-02, -5.0162e-02, -2.4460e-02,\n",
       "                      -4.0150e-02, -3.4435e-02, -1.5359e-02,  2.7559e-02, -3.0059e-02,\n",
       "                      -2.1002e-02,  3.4765e-02,  4.6935e-02,  2.7182e-02,  1.3217e-02,\n",
       "                       2.9987e-02,  3.4687e-02,  3.1319e-04, -4.3851e-02, -3.9346e-02,\n",
       "                       3.3970e-02, -2.1995e-02,  5.0626e-02,  1.2519e-02,  5.9215e-02,\n",
       "                       3.0338e-03, -3.8672e-03,  2.7634e-02,  4.0447e-02, -3.5210e-02,\n",
       "                       4.0141e-02, -5.9698e-02,  1.8742e-02, -7.9632e-03, -2.6730e-02,\n",
       "                       2.4952e-02, -4.3069e-02, -5.2615e-02, -7.4399e-03,  2.4076e-02,\n",
       "                      -3.4103e-02, -3.0505e-02, -3.6860e-02,  4.8020e-02,  3.9899e-02,\n",
       "                      -1.4090e-03, -5.1261e-02, -5.6159e-02,  5.3996e-02, -4.0178e-03,\n",
       "                       9.2443e-04, -3.2078e-02, -2.3836e-02, -5.4957e-02, -2.6829e-03,\n",
       "                      -2.7171e-02,  3.8816e-02,  1.3413e-02,  5.7393e-02, -8.7394e-03,\n",
       "                       2.2965e-03,  4.3714e-02,  3.5893e-02,  2.2334e-02,  3.0015e-02,\n",
       "                       2.0240e-02,  3.2463e-03, -2.0451e-02,  2.9513e-02,  6.2353e-02,\n",
       "                       1.1562e-02,  6.1806e-02, -6.2268e-02,  4.7784e-03, -1.7607e-02,\n",
       "                       4.5641e-02, -5.0422e-02, -5.3644e-02, -3.9180e-02,  3.8410e-02,\n",
       "                      -4.5801e-02, -3.1388e-03,  2.6146e-02, -1.2784e-02,  4.5335e-02,\n",
       "                       6.0592e-02, -5.5223e-02, -6.2048e-02,  4.7282e-02, -5.2201e-02,\n",
       "                      -5.8007e-02, -2.2956e-02, -1.3457e-02, -5.7033e-02,  3.4879e-02,\n",
       "                      -3.8151e-02, -5.2198e-02,  2.1081e-02, -5.8787e-02, -1.9119e-02,\n",
       "                      -1.8824e-02, -3.2405e-02, -6.0056e-02, -1.8536e-02, -3.1270e-02,\n",
       "                      -5.2891e-02, -3.9244e-02,  4.3342e-02,  3.3070e-02,  1.9584e-02,\n",
       "                      -2.4815e-02, -4.2889e-02,  1.5648e-02,  4.2121e-02,  1.2470e-02,\n",
       "                       3.1043e-02, -2.3098e-03,  4.2013e-02,  2.6619e-03,  5.1072e-02,\n",
       "                      -2.8400e-02,  1.9558e-02,  1.1947e-02,  1.5435e-04, -3.3542e-02,\n",
       "                      -2.1406e-02, -1.1249e-02,  3.8169e-02,  1.9653e-02,  4.4414e-02,\n",
       "                       3.1268e-02, -6.0540e-02, -5.5962e-02, -4.1404e-02, -5.9383e-02,\n",
       "                      -6.0592e-02,  4.7557e-02,  2.7231e-02, -5.1702e-02, -3.6556e-03,\n",
       "                      -1.2016e-03,  3.8049e-02,  2.1180e-02,  4.0787e-02, -5.8666e-02,\n",
       "                      -1.7037e-02,  1.8560e-02,  9.0474e-03,  1.0224e-02,  3.0438e-02,\n",
       "                       2.9334e-02, -2.7065e-02, -7.8777e-03,  1.1993e-02, -3.6877e-02,\n",
       "                       7.5056e-03, -5.2920e-02,  5.5724e-02,  2.8235e-02,  3.8645e-02,\n",
       "                       7.7561e-06, -1.8805e-02, -3.6190e-04, -4.6011e-03,  4.4818e-02,\n",
       "                       1.1712e-02, -5.1497e-03,  5.8673e-02,  4.1642e-02, -2.3911e-02,\n",
       "                       2.0094e-02, -5.5850e-02, -2.7427e-02,  3.8673e-02,  4.0089e-02,\n",
       "                      -6.4982e-03, -4.0477e-02, -1.9451e-02, -2.1421e-02, -1.0342e-02,\n",
       "                      -6.2341e-02,  4.3183e-02, -4.9764e-02,  4.8952e-03, -2.7630e-02,\n",
       "                      -2.5714e-02, -4.1639e-02, -1.9898e-02, -1.2352e-02,  5.0018e-02,\n",
       "                      -5.6373e-02,  5.6859e-02, -4.7243e-02, -1.7061e-02, -1.8091e-02,\n",
       "                       5.0463e-02, -4.0181e-02, -6.1104e-02, -4.7776e-02, -3.2348e-02,\n",
       "                       2.5766e-02,  2.7101e-03,  1.5793e-02, -1.8171e-02,  1.2195e-02,\n",
       "                       1.4928e-02,  3.3372e-02, -4.3934e-02, -3.7579e-02, -1.8143e-02,\n",
       "                       7.6432e-03, -9.1633e-03, -3.0971e-02,  2.6635e-02, -3.8295e-02,\n",
       "                      -5.5497e-02, -2.8273e-02])),\n",
       "             ('transformer_encoder.layers.1.linear2.weight',\n",
       "              tensor([[ 0.0248, -0.0025, -0.0097,  ..., -0.0215,  0.0388,  0.0032],\n",
       "                      [-0.0152,  0.0005,  0.0111,  ...,  0.0283,  0.0013, -0.0290],\n",
       "                      [ 0.0272, -0.0219,  0.0188,  ...,  0.0328,  0.0316,  0.0263],\n",
       "                      ...,\n",
       "                      [ 0.0342,  0.0181, -0.0238,  ...,  0.0218, -0.0220, -0.0049],\n",
       "                      [-0.0067,  0.0306, -0.0221,  ...,  0.0419,  0.0326,  0.0288],\n",
       "                      [-0.0239, -0.0256, -0.0328,  ...,  0.0159, -0.0229,  0.0298]])),\n",
       "             ('transformer_encoder.layers.1.linear2.bias',\n",
       "              tensor([-2.0566e-02, -2.2342e-02,  2.4541e-02, -2.4624e-02,  1.2683e-02,\n",
       "                       2.8690e-02,  4.2860e-02,  1.4415e-02,  2.1064e-02, -3.5754e-02,\n",
       "                      -2.8181e-02, -1.7319e-03, -8.5008e-03,  1.3609e-02, -3.4047e-02,\n",
       "                       3.3204e-02,  4.0286e-03, -3.8060e-02,  7.1814e-03, -1.1991e-02,\n",
       "                       4.1266e-02, -4.3798e-02,  3.6786e-03,  6.6793e-03, -2.4385e-02,\n",
       "                      -1.1857e-02, -1.1260e-02,  3.6932e-02,  2.6174e-02, -5.7929e-03,\n",
       "                      -4.0542e-02,  1.8132e-02,  1.4143e-03,  3.3811e-02, -6.1371e-03,\n",
       "                      -2.1685e-02,  5.6018e-03,  3.7771e-02,  1.8943e-02, -1.4011e-03,\n",
       "                       8.2846e-04, -5.0861e-03,  4.6756e-03, -3.8173e-02, -3.4029e-02,\n",
       "                      -1.0256e-02, -3.9678e-02,  1.1068e-02,  1.0516e-02,  3.8096e-02,\n",
       "                      -9.1763e-03,  3.4507e-02, -4.3812e-02, -4.3642e-03,  8.4555e-03,\n",
       "                       8.4926e-03,  3.3751e-02, -4.3581e-02, -2.4976e-02, -1.4541e-02,\n",
       "                       2.9815e-03, -3.3334e-02, -1.9061e-02,  2.2371e-02, -7.8736e-03,\n",
       "                       2.4818e-02, -3.1261e-02, -6.4667e-05, -3.7674e-02, -2.6778e-02,\n",
       "                       3.9688e-02,  3.4271e-02,  1.8167e-02,  2.5896e-04, -1.1652e-03,\n",
       "                       2.4575e-02, -3.7681e-02,  2.9240e-02, -3.6221e-02, -3.8540e-02,\n",
       "                       1.4578e-02, -7.8173e-03, -4.3229e-02, -3.7837e-02, -4.2517e-02,\n",
       "                      -5.2995e-03, -4.2013e-02, -3.7633e-02,  4.0928e-02,  1.8042e-02,\n",
       "                       1.3799e-03,  3.7498e-03,  3.7805e-03,  1.0085e-02, -4.2222e-02,\n",
       "                       1.3210e-02,  4.2748e-02, -5.9078e-03, -1.3789e-02,  4.2566e-02,\n",
       "                       2.0395e-02, -4.0609e-02, -4.3547e-02,  2.9658e-02, -1.7812e-02,\n",
       "                      -2.7653e-02, -1.6497e-02,  1.8577e-02, -2.2629e-03,  3.2640e-02,\n",
       "                       2.3112e-02,  1.6732e-02,  2.5519e-02,  2.5951e-02,  4.0509e-02,\n",
       "                       3.5295e-02,  2.2666e-03,  1.4827e-02, -3.9675e-02,  8.7583e-03,\n",
       "                      -3.3350e-02,  3.0855e-02, -1.3813e-02,  1.2049e-02,  7.0156e-03,\n",
       "                      -4.3516e-02,  1.3382e-02,  4.4452e-03,  3.4029e-02, -3.3273e-02,\n",
       "                       5.4232e-03, -1.6716e-02,  3.1401e-02,  4.3424e-02, -3.8336e-02,\n",
       "                      -2.6952e-02,  3.3533e-02,  3.7752e-02, -3.7178e-02,  4.3455e-02,\n",
       "                      -3.1173e-02,  9.9225e-03,  2.9546e-02, -1.5212e-02,  7.6285e-03,\n",
       "                       4.0701e-02,  3.4672e-02, -7.1755e-03, -3.0467e-02,  4.0098e-02,\n",
       "                      -4.2583e-02, -8.7643e-04,  3.0171e-02, -3.0880e-02, -4.2340e-02,\n",
       "                       3.4856e-02,  3.2950e-02,  2.6072e-02,  3.0105e-02, -3.4389e-02,\n",
       "                      -2.0039e-02,  1.5254e-02,  1.6630e-02,  1.7741e-02,  4.0824e-02,\n",
       "                       4.3222e-02, -6.9815e-03,  1.5749e-02, -1.7761e-02, -3.9090e-02,\n",
       "                      -4.0810e-02,  4.1009e-02, -2.2411e-02, -3.0648e-02, -2.6068e-02,\n",
       "                      -1.1641e-02,  3.9737e-02, -7.3692e-03, -2.3563e-02,  3.0582e-02,\n",
       "                      -3.5202e-02, -1.7879e-02, -1.3243e-02,  4.3509e-03,  3.2942e-02,\n",
       "                       5.8802e-03,  3.9488e-02,  3.3534e-02, -1.4965e-02,  2.8795e-02,\n",
       "                      -4.0389e-02, -3.4630e-03, -3.0528e-03, -1.0381e-02,  2.3883e-03,\n",
       "                       3.8778e-02,  3.5532e-02,  1.3535e-02,  3.7447e-02,  2.3958e-02,\n",
       "                       2.6858e-02, -2.8004e-02, -2.2561e-02, -2.1148e-02, -1.0908e-02,\n",
       "                      -2.4070e-02,  1.6248e-02, -4.0876e-02, -4.1417e-02, -2.2074e-02,\n",
       "                       1.2307e-02,  1.7956e-02, -3.9214e-02, -3.5519e-02, -2.7809e-02,\n",
       "                       1.5829e-02, -2.5140e-02,  2.9682e-02, -1.1088e-02, -3.2513e-02,\n",
       "                       2.8429e-02,  3.2992e-02, -3.9655e-02,  3.1016e-02,  3.2418e-02,\n",
       "                      -1.4125e-02,  1.4869e-02,  3.9971e-02,  1.6105e-02,  3.7250e-03,\n",
       "                       2.4235e-02,  2.3781e-02, -3.6940e-02, -1.8513e-03,  6.1039e-03,\n",
       "                      -4.2269e-02, -2.8811e-02, -1.8716e-02, -3.2051e-02, -2.0701e-02,\n",
       "                       1.3789e-02,  2.3315e-02, -4.0171e-02,  1.3528e-02,  3.0489e-02,\n",
       "                      -2.3603e-02, -1.3383e-02,  1.7639e-02,  1.6702e-02,  2.9860e-02,\n",
       "                       1.5812e-02,  1.2336e-02, -1.6027e-02, -2.7475e-02,  1.2227e-02,\n",
       "                      -2.2609e-02])),\n",
       "             ('transformer_encoder.layers.1.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('transformer_encoder.layers.1.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[-2.3299e-02, -4.5930e-02,  4.9756e-02,  3.3377e-02, -3.5858e-02,\n",
       "                       -5.6234e-03, -1.9032e-02,  3.8945e-02, -8.9735e-03,  6.4448e-03,\n",
       "                        1.3776e-03, -3.7027e-02, -1.2835e-02,  4.4880e-02,  2.4007e-03,\n",
       "                        3.2642e-02,  3.9715e-02,  2.0874e-02,  4.7736e-02,  5.3175e-02,\n",
       "                        4.1221e-02, -7.0987e-03, -3.1496e-02, -3.4665e-02,  8.7635e-03,\n",
       "                       -2.2705e-02, -2.2266e-02,  4.3675e-02, -5.5548e-02, -1.8108e-02,\n",
       "                       -2.4283e-02,  6.1447e-02,  2.0193e-02,  6.0464e-02,  1.6548e-02,\n",
       "                        2.3932e-02,  4.4359e-02, -3.9639e-02,  2.1757e-02, -7.2211e-03,\n",
       "                        5.3201e-02, -3.0093e-02, -4.6467e-02, -3.4936e-02,  4.6275e-02,\n",
       "                        3.1307e-02, -4.7047e-03, -4.2211e-02, -3.8219e-02,  3.2837e-02,\n",
       "                        2.0197e-02,  3.6854e-03,  6.2483e-02, -3.1803e-02,  6.0069e-02,\n",
       "                        4.4589e-03,  2.9650e-02,  1.5570e-02,  1.8002e-02,  4.6961e-02,\n",
       "                        1.4171e-02, -5.6573e-02, -3.8005e-02, -5.7956e-02, -1.7420e-02,\n",
       "                       -3.7906e-02, -5.6040e-02, -2.5573e-02,  3.6410e-02,  5.4961e-02,\n",
       "                       -5.9449e-02,  1.6086e-02,  4.6295e-02, -5.7778e-02, -3.0574e-02,\n",
       "                        1.3255e-02,  1.9793e-02, -6.2104e-02, -4.8967e-02,  3.2347e-02,\n",
       "                       -5.0261e-02,  4.6123e-02,  3.0639e-02,  2.6639e-02, -3.8521e-02,\n",
       "                        5.6784e-02,  1.9828e-02, -1.1528e-03,  5.7790e-02,  2.2960e-02,\n",
       "                        6.0705e-03,  5.3926e-02,  2.9815e-02, -3.4226e-02,  4.6365e-02,\n",
       "                       -4.9017e-02, -5.8312e-03, -5.7950e-02, -1.5806e-02,  3.8362e-02,\n",
       "                        3.9945e-02,  3.3283e-02,  1.3281e-02,  4.2413e-02, -4.7972e-02,\n",
       "                        2.0021e-02, -2.7998e-02, -4.1113e-02, -1.3964e-02,  1.0622e-02,\n",
       "                       -8.6727e-03, -5.2557e-02, -2.3698e-02, -2.5356e-02, -3.0650e-02,\n",
       "                       -4.1990e-02,  4.8885e-02, -2.1765e-02,  5.4112e-02,  3.7302e-02,\n",
       "                       -6.0677e-02,  1.6421e-02,  5.3487e-02, -5.8185e-03, -4.0224e-02,\n",
       "                       -8.8494e-03, -1.2554e-02, -9.3528e-03,  1.5416e-02, -6.1637e-02,\n",
       "                        9.7343e-03,  1.1783e-02, -2.3152e-02, -5.0192e-02,  4.3876e-02,\n",
       "                       -1.7518e-02,  6.1334e-02,  1.8277e-02,  1.9706e-02,  3.4920e-02,\n",
       "                        4.1680e-02, -5.0858e-02,  4.8403e-02, -1.9309e-02,  2.3563e-03,\n",
       "                        3.9542e-02, -5.3677e-02,  4.9796e-02,  2.3008e-02,  3.2733e-02,\n",
       "                        1.4606e-02,  2.6095e-02,  3.4579e-02,  3.7401e-02,  2.5573e-02,\n",
       "                       -1.9615e-02, -6.6060e-03, -5.9949e-02, -2.4749e-02, -5.6992e-02,\n",
       "                        1.5317e-02, -1.4807e-02,  1.0409e-02,  3.9206e-02,  7.9229e-03,\n",
       "                        6.1969e-02,  7.9806e-03, -4.3485e-02, -4.0233e-02, -1.2339e-02,\n",
       "                       -2.3205e-02, -6.6116e-03, -5.8175e-02, -3.5827e-02, -2.0578e-02,\n",
       "                        6.1428e-02,  3.8316e-02, -5.1131e-02, -5.5819e-02,  3.8570e-02,\n",
       "                       -3.9814e-02,  2.2802e-02, -1.4440e-02, -6.8922e-03,  6.0051e-02,\n",
       "                        4.2897e-02, -1.0373e-02,  1.8809e-02, -1.4305e-02, -2.3096e-02,\n",
       "                       -5.6881e-02, -8.3466e-03, -4.7951e-02,  1.6690e-02,  3.4281e-02,\n",
       "                        6.2421e-02,  4.2701e-02,  2.1487e-04, -9.2502e-03, -2.7268e-02,\n",
       "                        2.3323e-02,  1.6770e-02,  6.0487e-02,  3.1645e-02,  5.3546e-02,\n",
       "                        3.2003e-02,  3.0135e-02,  2.9032e-02,  3.3637e-02,  2.7035e-02,\n",
       "                       -5.6965e-02, -3.6404e-02,  4.9116e-03, -1.8906e-02,  8.4432e-03,\n",
       "                       -1.4670e-02,  5.5047e-02, -5.7811e-02,  2.2972e-03,  4.8704e-02,\n",
       "                        2.1436e-02,  3.0595e-02,  8.7109e-03,  4.5949e-02,  4.8802e-02,\n",
       "                       -1.6408e-02, -3.6495e-02,  3.1250e-02,  2.6846e-02,  1.0579e-02,\n",
       "                        1.8798e-02, -3.5801e-02, -9.8204e-04, -5.8624e-02,  3.0134e-02,\n",
       "                       -2.5982e-02,  5.5228e-02, -1.4056e-02, -5.5167e-02,  2.9040e-02,\n",
       "                        2.7261e-02,  5.6633e-02,  5.6975e-02,  3.1336e-03, -1.5271e-04,\n",
       "                        8.5468e-03,  2.2490e-02,  4.1078e-02,  2.1903e-02,  2.1643e-02,\n",
       "                       -1.5061e-02, -5.1912e-02,  2.5963e-02, -4.8681e-02, -1.9646e-02,\n",
       "                       -5.5355e-03],\n",
       "                      [ 5.1116e-02, -1.5113e-02, -4.7083e-02,  4.3232e-02,  3.0063e-02,\n",
       "                       -3.9188e-02, -1.1298e-02,  2.3707e-02, -1.3402e-02, -1.1230e-02,\n",
       "                        4.5768e-02, -6.0194e-03,  7.6916e-03, -6.9235e-03,  3.9764e-02,\n",
       "                        4.9752e-02,  1.1482e-03, -3.0676e-03,  2.9900e-02, -4.2960e-02,\n",
       "                       -4.9578e-02, -2.8014e-02,  3.2721e-02, -3.0008e-02,  5.6244e-02,\n",
       "                        5.8371e-02, -2.4199e-02,  2.1754e-02, -2.4471e-02,  5.0536e-02,\n",
       "                       -1.9172e-02, -5.0125e-02,  3.6535e-02,  6.8746e-03,  1.2401e-02,\n",
       "                        5.2327e-02, -4.9005e-02,  1.0890e-02,  3.4394e-02, -3.0546e-02,\n",
       "                       -1.4896e-02, -3.3151e-02, -5.8471e-02, -1.5454e-02, -4.0580e-02,\n",
       "                        2.8141e-02,  4.8887e-02,  5.8258e-02,  4.6873e-02, -8.8235e-03,\n",
       "                       -4.9311e-02,  2.0162e-02, -6.7821e-03, -5.2824e-02, -2.2305e-03,\n",
       "                        1.9220e-02, -7.5805e-03, -2.4554e-02, -3.9360e-02, -5.1590e-02,\n",
       "                        9.4662e-03, -4.8898e-02,  5.4376e-02, -4.6559e-03,  5.2115e-02,\n",
       "                       -1.1931e-02,  1.9359e-02, -5.5922e-02, -5.6871e-02,  5.8165e-02,\n",
       "                       -3.8935e-02, -4.1368e-02,  3.7150e-02,  1.5373e-02, -5.6448e-02,\n",
       "                        1.6470e-02, -2.0052e-02,  5.2575e-02,  4.8830e-02,  2.8962e-02,\n",
       "                       -1.1807e-02,  3.6750e-02, -2.2687e-03,  3.0356e-02, -2.3822e-02,\n",
       "                       -4.6809e-03,  2.3192e-02, -4.0428e-02,  3.3266e-02, -4.4556e-02,\n",
       "                       -6.0988e-03,  2.3992e-02, -1.4218e-02,  9.0323e-03,  1.0570e-02,\n",
       "                        2.0484e-02, -1.2708e-02,  1.7574e-02, -5.7054e-02, -5.0887e-02,\n",
       "                        8.9701e-03,  2.0648e-02, -3.2165e-02, -1.0275e-02, -3.3451e-02,\n",
       "                        2.2044e-02, -2.0215e-02, -3.0335e-02, -2.9854e-02,  9.1323e-04,\n",
       "                        1.4765e-03,  4.1765e-02, -2.1523e-02,  1.9363e-02, -2.0283e-02,\n",
       "                        4.2410e-02, -9.8433e-03, -1.5692e-02, -9.2070e-03, -6.8296e-03,\n",
       "                        1.0732e-02, -3.6527e-02,  1.2681e-04,  2.3570e-02,  4.3180e-02,\n",
       "                        5.9418e-02,  2.4136e-02, -5.0742e-02, -3.9783e-02,  6.2184e-02,\n",
       "                        2.8719e-02,  4.4665e-02, -1.0390e-02, -1.1436e-02,  2.2263e-03,\n",
       "                        1.5208e-02,  5.5157e-02,  4.0362e-02, -5.2799e-02,  5.3998e-02,\n",
       "                       -1.4310e-02,  4.4231e-02, -2.9889e-02,  4.2642e-02,  7.9736e-03,\n",
       "                       -3.7093e-02, -2.0379e-02, -4.6105e-03,  1.3559e-02, -3.9253e-02,\n",
       "                        3.7782e-02,  5.9526e-02, -1.5846e-03, -1.0244e-02, -4.7863e-02,\n",
       "                       -3.4680e-02,  4.0103e-02,  2.8218e-02,  2.5447e-02,  1.5306e-02,\n",
       "                        3.8479e-02,  5.3791e-02,  5.9632e-02, -5.0914e-02, -5.7452e-02,\n",
       "                        5.0099e-02,  7.5497e-04,  5.6319e-02,  2.2058e-02,  3.2822e-02,\n",
       "                       -1.1907e-02,  4.5969e-02,  7.1451e-06, -3.5025e-02, -2.8965e-02,\n",
       "                       -2.1734e-02,  3.1690e-02,  2.1273e-02,  4.1664e-02, -2.8718e-02,\n",
       "                        3.4978e-02,  4.0093e-02,  3.9617e-02, -4.8247e-02, -4.3618e-02,\n",
       "                        5.1112e-04, -2.9431e-02,  4.2254e-02,  1.7889e-02,  3.8095e-02,\n",
       "                        9.6066e-04,  5.3163e-02, -4.4092e-02, -5.5763e-02, -6.1389e-02,\n",
       "                        3.3009e-02, -5.4875e-02, -8.9211e-03, -4.2593e-02,  2.5136e-02,\n",
       "                        5.8824e-02,  4.2966e-02,  4.2205e-02,  3.3538e-02, -2.7535e-02,\n",
       "                        1.2658e-02,  6.2011e-03,  5.3472e-02,  9.5377e-03, -2.7285e-02,\n",
       "                        6.1007e-02, -5.3275e-02, -1.1885e-02,  5.2165e-02,  2.5408e-02,\n",
       "                       -1.0492e-03,  4.7083e-02, -1.8490e-02, -3.4633e-02, -1.7472e-02,\n",
       "                       -2.3578e-02,  1.6295e-02, -2.3184e-02, -5.2305e-02,  3.1664e-02,\n",
       "                       -7.3699e-03, -5.5703e-02, -3.6331e-02,  3.9497e-03, -4.1891e-02,\n",
       "                        2.4213e-02,  2.3950e-03,  2.6079e-02, -3.9450e-02,  3.2702e-02,\n",
       "                       -6.1359e-02,  5.6928e-02, -3.5065e-02, -1.7638e-02, -5.5971e-02,\n",
       "                       -2.5237e-02, -5.8922e-02, -2.1919e-02, -2.0238e-02,  1.9191e-02,\n",
       "                       -4.7962e-02,  3.0724e-02, -7.0938e-03,  1.6729e-02,  1.8450e-02,\n",
       "                        1.9090e-02,  5.0439e-03,  1.6183e-02, -3.8761e-02,  8.7327e-03,\n",
       "                       -1.6396e-02],\n",
       "                      [-4.1591e-02,  7.2331e-03,  1.3274e-03, -6.0410e-02,  4.0196e-02,\n",
       "                       -4.0775e-02, -3.6439e-03, -4.9499e-02,  8.1050e-03, -5.5186e-02,\n",
       "                       -1.5934e-02,  4.9553e-02,  9.0951e-03,  5.6087e-02,  2.8968e-02,\n",
       "                        2.7531e-02,  9.5353e-05,  4.6725e-02, -4.9432e-02, -3.5520e-02,\n",
       "                       -3.5363e-02,  5.9440e-02, -1.9579e-02,  2.6279e-02, -2.8495e-02,\n",
       "                        5.2010e-02, -2.8239e-02, -2.9912e-03,  4.6052e-02, -5.6551e-02,\n",
       "                        4.6428e-03,  2.9937e-02,  6.2374e-02,  7.0884e-03, -5.1407e-02,\n",
       "                       -2.0703e-02, -1.1558e-02,  1.4741e-02,  2.0464e-02,  1.0241e-02,\n",
       "                       -1.4483e-02,  4.2134e-02, -2.2909e-03,  2.4590e-02,  1.7147e-02,\n",
       "                        8.5335e-03,  4.0681e-02,  4.5598e-02,  1.9565e-03, -5.3671e-02,\n",
       "                        4.2827e-02,  2.0941e-02,  5.5082e-02, -4.6825e-02,  1.2522e-02,\n",
       "                        6.6170e-03,  2.5476e-02,  2.8032e-02,  3.6230e-03, -4.1897e-02,\n",
       "                        1.5448e-02,  1.4444e-02,  8.2142e-03, -1.9933e-02,  3.1506e-03,\n",
       "                       -1.1135e-02, -5.5092e-02,  1.5037e-02, -5.1025e-02,  1.7939e-02,\n",
       "                        5.7308e-02, -5.9412e-02,  2.8799e-02, -6.8480e-03, -5.1357e-02,\n",
       "                       -3.6374e-03, -9.5202e-03,  1.8472e-02,  3.7825e-02,  1.7690e-02,\n",
       "                        4.7567e-02, -1.6935e-02,  1.9272e-03, -2.1198e-04, -5.2888e-02,\n",
       "                       -5.6020e-02, -6.3058e-03,  3.1895e-02, -4.3295e-02, -5.4515e-02,\n",
       "                       -4.5141e-02, -1.2323e-02, -6.0541e-02,  5.4994e-02, -5.0752e-02,\n",
       "                        2.6693e-02,  2.2177e-02, -3.2833e-02,  5.0650e-02,  6.5020e-03,\n",
       "                        1.9251e-04,  5.6012e-02,  4.9528e-02,  6.0932e-02, -1.2435e-02,\n",
       "                        4.7780e-02, -4.6440e-03, -1.1151e-02, -3.3408e-02, -1.9096e-02,\n",
       "                       -1.3850e-02, -4.7150e-02, -2.4093e-02, -3.1302e-02, -1.2924e-02,\n",
       "                        2.2407e-02,  1.4328e-02, -7.3923e-03,  1.3014e-02, -5.7400e-02,\n",
       "                        3.0045e-02, -4.5960e-02, -5.3622e-02, -5.9979e-02,  3.6470e-02,\n",
       "                       -4.2886e-02, -1.4930e-03, -5.5162e-02,  5.4464e-02, -5.5167e-02,\n",
       "                        5.1924e-04,  9.1460e-03, -5.9630e-02, -4.4820e-02, -1.6250e-02,\n",
       "                        3.3447e-02, -8.2802e-03, -3.3446e-02, -4.1379e-02, -8.7653e-03,\n",
       "                        5.6811e-02, -5.7774e-03,  1.1048e-02,  4.9142e-02,  5.5220e-02,\n",
       "                       -4.3097e-02, -3.1523e-02, -1.5636e-02, -5.4520e-02, -5.9803e-02,\n",
       "                       -4.2513e-02,  8.1038e-03,  4.7534e-02,  2.7400e-02,  3.0737e-02,\n",
       "                       -5.0928e-02, -2.3351e-02, -2.7562e-02,  2.9527e-03, -3.7245e-02,\n",
       "                        6.1291e-02,  5.9636e-03,  1.4986e-02,  1.8259e-02,  2.6422e-02,\n",
       "                        4.1758e-02,  2.4733e-02,  4.8101e-02,  3.8466e-02, -2.2284e-03,\n",
       "                       -2.7352e-02, -2.2907e-02, -2.9282e-02,  2.9534e-02,  1.8359e-02,\n",
       "                       -6.0967e-02, -1.5932e-02, -4.0145e-02, -5.7756e-02,  3.0061e-02,\n",
       "                       -2.3991e-02, -5.7800e-02, -1.7552e-02, -1.8968e-02, -7.6591e-03,\n",
       "                       -4.3611e-02,  6.1831e-02,  3.0582e-02,  1.0426e-02, -2.1157e-02,\n",
       "                       -2.2300e-02,  5.3062e-02, -7.6768e-03,  2.7099e-02, -7.5466e-03,\n",
       "                       -2.0926e-03,  1.9666e-02, -2.3097e-02,  5.1485e-02, -5.1740e-02,\n",
       "                        5.5876e-02,  6.9253e-04, -5.9529e-03, -2.7298e-02,  5.5123e-02,\n",
       "                       -5.0244e-02,  1.0524e-02, -6.2057e-02, -4.3218e-02,  1.4406e-04,\n",
       "                       -4.7274e-02, -4.8654e-02,  6.7418e-03,  4.6324e-02,  6.1291e-02,\n",
       "                        4.1360e-02,  3.3864e-02,  9.9377e-04,  1.2916e-02,  5.4785e-02,\n",
       "                       -1.1807e-03, -9.6975e-03,  4.6604e-03,  2.1573e-02,  4.0060e-02,\n",
       "                       -1.4267e-02,  3.4814e-02, -3.5156e-02, -4.4672e-02, -4.2859e-02,\n",
       "                       -4.6888e-02,  1.1931e-02,  5.4942e-02,  1.7380e-04, -4.6322e-02,\n",
       "                        1.8040e-02, -5.1467e-02, -3.2087e-02,  5.9349e-02,  6.0578e-02,\n",
       "                        6.7176e-03,  2.0146e-02,  5.9166e-02, -4.6062e-03,  6.1429e-02,\n",
       "                       -5.3528e-02,  2.3839e-02, -8.0630e-03, -5.1051e-02, -4.1432e-02,\n",
       "                       -5.6360e-03, -5.3517e-03, -1.5667e-02,  3.0279e-02,  3.7767e-02,\n",
       "                        3.6948e-02]])),\n",
       "             ('output_layer.bias', tensor([ 0.0189, -0.0501, -0.0592]))])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrained_state_dict(clf, \"encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.tensor([[0.2, 0.1, 0.3, 0.5, 0.1], [0.5, 0.7, 0.3, 0.8, 0.1]], requires_grad=True).cuda()\n",
    "out = torch.tensor([[0.3, 0.1, 0.2, 0.8, 0.2], [0.5, 0.6, 0.4, 0.1, 0.2]], requires_grad=True).cuda()\n",
    "criterion = torch.nn.MSELoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[True, True, False, False, False], [True, False, True, False, False]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(pred, out)\n",
    "avg_loss = torch.masked_select(loss.view(-1, 1), mask.view(-1, 1) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-9d6cc95d4066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Software\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "scaler.scale(avg_loss).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21bb49273b3bc7e970573143769dbe2f8828a1cab3d00aefeffccffd0bb6ba7c"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
